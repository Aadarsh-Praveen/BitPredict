{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PJ8MuajJMApA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "RlOX0owQPjyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/Bitcoin_data.csv\", delimiter=';')"
      ],
      "metadata": {
        "id": "B8sXC-uEPnva"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMvLjEvGOF5t",
        "outputId": "cf5f6109-b40b-4a0e-b676-05916e12d6e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5560"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "lkRCe3hJQYZb",
        "outputId": "976b4ea8-713c-4a75-cca0-b39aa5e6dd28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   timeOpen                 timeClose  \\\n",
              "0  2025-10-02T00:00:00.000Z  2025-10-02T23:59:59.999Z   \n",
              "1  2025-10-01T00:00:00.000Z  2025-10-01T23:59:59.999Z   \n",
              "2  2025-09-30T00:00:00.000Z  2025-09-30T23:59:59.999Z   \n",
              "3  2025-09-29T00:00:00.000Z  2025-09-29T23:59:59.999Z   \n",
              "4  2025-09-28T00:00:00.000Z  2025-09-28T23:59:59.999Z   \n",
              "\n",
              "                   timeHigh                   timeLow  name           open  \\\n",
              "0  2025-10-02T19:16:00.000Z  2025-10-02T06:03:00.000Z  2781  118652.385896   \n",
              "1  2025-10-01T23:59:00.000Z  2025-10-01T00:28:00.000Z  2781  114057.592183   \n",
              "2  2025-09-30T01:16:00.000Z  2025-09-30T10:04:00.000Z  2781  114396.520241   \n",
              "3  2025-09-29T20:45:00.000Z  2025-09-29T07:27:00.000Z  2781  112117.878794   \n",
              "4  2025-09-28T23:10:00.000Z  2025-09-28T12:50:00.000Z  2781  109681.947300   \n",
              "\n",
              "            high            low          close        volume     marketCap  \\\n",
              "0  121086.407241  118383.158156  120681.259723  7.141516e+10  2.404477e+12   \n",
              "1  118648.928588  113981.395969  118648.928588  7.132868e+10  2.364529e+12   \n",
              "2  114836.615425  112740.564747  114056.083647  5.898633e+10  2.272963e+12   \n",
              "3  114473.569892  111589.950680  114400.386428  6.000015e+10  2.279699e+12   \n",
              "4  112375.482143  109236.947744  112122.639151  3.337105e+10  2.234221e+12   \n",
              "\n",
              "                  timestamp  \n",
              "0  2025-10-02T23:59:59.999Z  \n",
              "1  2025-10-01T23:59:59.999Z  \n",
              "2  2025-09-30T23:59:59.999Z  \n",
              "3  2025-09-29T23:59:59.999Z  \n",
              "4  2025-09-28T23:59:59.999Z  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8f6bcae-5f28-4747-9e13-460166fce353\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timeOpen</th>\n",
              "      <th>timeClose</th>\n",
              "      <th>timeHigh</th>\n",
              "      <th>timeLow</th>\n",
              "      <th>name</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>marketCap</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-02T00:00:00.000Z</td>\n",
              "      <td>2025-10-02T23:59:59.999Z</td>\n",
              "      <td>2025-10-02T19:16:00.000Z</td>\n",
              "      <td>2025-10-02T06:03:00.000Z</td>\n",
              "      <td>2781</td>\n",
              "      <td>118652.385896</td>\n",
              "      <td>121086.407241</td>\n",
              "      <td>118383.158156</td>\n",
              "      <td>120681.259723</td>\n",
              "      <td>7.141516e+10</td>\n",
              "      <td>2.404477e+12</td>\n",
              "      <td>2025-10-02T23:59:59.999Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-10-01T00:00:00.000Z</td>\n",
              "      <td>2025-10-01T23:59:59.999Z</td>\n",
              "      <td>2025-10-01T23:59:00.000Z</td>\n",
              "      <td>2025-10-01T00:28:00.000Z</td>\n",
              "      <td>2781</td>\n",
              "      <td>114057.592183</td>\n",
              "      <td>118648.928588</td>\n",
              "      <td>113981.395969</td>\n",
              "      <td>118648.928588</td>\n",
              "      <td>7.132868e+10</td>\n",
              "      <td>2.364529e+12</td>\n",
              "      <td>2025-10-01T23:59:59.999Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-30T00:00:00.000Z</td>\n",
              "      <td>2025-09-30T23:59:59.999Z</td>\n",
              "      <td>2025-09-30T01:16:00.000Z</td>\n",
              "      <td>2025-09-30T10:04:00.000Z</td>\n",
              "      <td>2781</td>\n",
              "      <td>114396.520241</td>\n",
              "      <td>114836.615425</td>\n",
              "      <td>112740.564747</td>\n",
              "      <td>114056.083647</td>\n",
              "      <td>5.898633e+10</td>\n",
              "      <td>2.272963e+12</td>\n",
              "      <td>2025-09-30T23:59:59.999Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-29T00:00:00.000Z</td>\n",
              "      <td>2025-09-29T23:59:59.999Z</td>\n",
              "      <td>2025-09-29T20:45:00.000Z</td>\n",
              "      <td>2025-09-29T07:27:00.000Z</td>\n",
              "      <td>2781</td>\n",
              "      <td>112117.878794</td>\n",
              "      <td>114473.569892</td>\n",
              "      <td>111589.950680</td>\n",
              "      <td>114400.386428</td>\n",
              "      <td>6.000015e+10</td>\n",
              "      <td>2.279699e+12</td>\n",
              "      <td>2025-09-29T23:59:59.999Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-28T00:00:00.000Z</td>\n",
              "      <td>2025-09-28T23:59:59.999Z</td>\n",
              "      <td>2025-09-28T23:10:00.000Z</td>\n",
              "      <td>2025-09-28T12:50:00.000Z</td>\n",
              "      <td>2781</td>\n",
              "      <td>109681.947300</td>\n",
              "      <td>112375.482143</td>\n",
              "      <td>109236.947744</td>\n",
              "      <td>112122.639151</td>\n",
              "      <td>3.337105e+10</td>\n",
              "      <td>2.234221e+12</td>\n",
              "      <td>2025-09-28T23:59:59.999Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8f6bcae-5f28-4747-9e13-460166fce353')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8f6bcae-5f28-4747-9e13-460166fce353 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8f6bcae-5f28-4747-9e13-460166fce353');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ca73bc60-9ec8-459f-9c4c-9c08c57287b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca73bc60-9ec8-459f-9c4c-9c08c57287b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ca73bc60-9ec8-459f-9c4c-9c08c57287b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5560,\n  \"fields\": [\n    {\n      \"column\": \"timeOpen\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16T00:00:00.000Z\",\n          \"2014-09-27T00:00:00.000Z\",\n          \"2020-10-06T00:00:00.000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timeClose\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16T23:59:59.999Z\",\n          \"2014-09-27T23:59:59.999Z\",\n          \"2020-10-06T23:59:59.999Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timeHigh\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16T21:39:00.000Z\",\n          \"2014-09-27T06:23:59.000Z\",\n          \"2020-10-06T00:16:59.000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timeLow\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16T14:45:00.000Z\",\n          \"2014-09-27T17:38:59.000Z\",\n          \"2020-10-06T20:59:53.000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2781,\n        \"max\": 2781,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27879.30334744756,\n        \"min\": 0.05640261,\n        \"max\": 123339.3953878563,\n        \"num_unique_values\": 5553,\n        \"samples\": [\n          9145.98505502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28380.525619319702,\n        \"min\": 0.06155211,\n        \"max\": 124457.1168703663,\n        \"num_unique_values\": 5550,\n        \"samples\": [\n          9309.75486362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27363.67054770048,\n        \"min\": 0.04864654,\n        \"max\": 118959.1967856346,\n        \"num_unique_values\": 5554,\n        \"samples\": [\n          8.28107156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27911.04322599066,\n        \"min\": 0.05640216,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5543,\n        \"samples\": [\n          69.98967503\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20833538367.117264,\n        \"min\": 0.0,\n        \"max\": 350967941479.06,\n        \"num_unique_values\": 5313,\n        \"samples\": [\n          19617581340.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marketCap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 550595602837.3293,\n        \"min\": 190259.65,\n        \"max\": 2455190057730.02,\n        \"num_unique_values\": 5559,\n        \"samples\": [\n          41981211.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16T23:59:59.999Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4yWl1NsSLJ7",
        "outputId": "3d865ed9-d46d-448c-cc1a-009d03d07de8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5560 entries, 0 to 5559\n",
            "Data columns (total 12 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   timeOpen   5560 non-null   object \n",
            " 1   timeClose  5560 non-null   object \n",
            " 2   timeHigh   5560 non-null   object \n",
            " 3   timeLow    5560 non-null   object \n",
            " 4   name       5560 non-null   int64  \n",
            " 5   open       5560 non-null   float64\n",
            " 6   high       5560 non-null   float64\n",
            " 7   low        5560 non-null   float64\n",
            " 8   close      5560 non-null   float64\n",
            " 9   volume     5560 non-null   float64\n",
            " 10  marketCap  5560 non-null   float64\n",
            " 11  timestamp  5560 non-null   object \n",
            "dtypes: float64(6), int64(1), object(5)\n",
            "memory usage: 521.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "s2tMOBcvSQGB",
        "outputId": "3246da11-6e9b-41a9-cf3f-57186161f3f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "timeOpen     0\n",
              "timeClose    0\n",
              "timeHigh     0\n",
              "timeLow      0\n",
              "name         0\n",
              "open         0\n",
              "high         0\n",
              "low          0\n",
              "close        0\n",
              "volume       0\n",
              "marketCap    0\n",
              "timestamp    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>timeOpen</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timeClose</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timeHigh</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timeLow</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>open</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>close</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marketCap</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess data: Turning the dataset into univariate data"
      ],
      "metadata": {
        "id": "gtHwNzJqTQ06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"date\"] = pd.to_datetime(df[\"timeClose\"]).dt.date"
      ],
      "metadata": {
        "id": "4n6qOfkYVqmy"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bitcoin_data=df[[\"date\",\"close\"]]"
      ],
      "metadata": {
        "id": "e_7rLu5HXL7k"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bitcoin_data.set_index(\"date\", inplace=True)\n",
        "bitcoin_data.rename(columns={\"close\":\"price\"}, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gEMHUSqXoNr",
        "outputId": "e54853d4-1668-4145-cc74-e384df35f3ac"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3330979986.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  bitcoin_data.rename(columns={\"close\":\"price\"}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bitcoin_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "jrzZc3bpV0Z_",
        "outputId": "0305c69a-c0bb-43cf-eabb-a235187a0e78"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    price\n",
              "date                     \n",
              "2025-10-02  120681.259723\n",
              "2025-10-01  118648.928588\n",
              "2025-09-30  114056.083647\n",
              "2025-09-29  114400.386428\n",
              "2025-09-28  112122.639151"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e757faec-63d6-427b-b3ca-19b4d2860318\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-10-02</th>\n",
              "      <td>120681.259723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-01</th>\n",
              "      <td>118648.928588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-30</th>\n",
              "      <td>114056.083647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-29</th>\n",
              "      <td>114400.386428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-28</th>\n",
              "      <td>112122.639151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e757faec-63d6-427b-b3ca-19b4d2860318')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e757faec-63d6-427b-b3ca-19b4d2860318 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e757faec-63d6-427b-b3ca-19b4d2860318');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f2a7b7d4-7b05-4650-a7aa-dea6252a6a4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2a7b7d4-7b05-4650-a7aa-dea6252a6a4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f2a7b7d4-7b05-4650-a7aa-dea6252a6a4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bitcoin_data",
              "summary": "{\n  \"name\": \"bitcoin_data\",\n  \"rows\": 5560,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-07-14\",\n        \"max\": \"2025-10-02\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16\",\n          \"2014-09-27\",\n          \"2020-10-06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27911.04322599066,\n        \"min\": 0.05640216,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5543,\n        \"samples\": [\n          69.98967503,\n          57750.17734563,\n          5.15850195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bitcoin_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "jnr6L9dpYNHs",
        "outputId": "66f1e6bb-3b13-4605-c71e-f2cb88a7fe9b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: N-Beats"
      ],
      "metadata": {
        "id": "IZitvlhPYRFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON=1\n",
        "WINDOW_SIZE=7"
      ],
      "metadata": {
        "id": "U0a8_jIi939e"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom block layer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class NBeatsBlock(layers.Layer):\n",
        "    def __init__(self,\n",
        "                 input_size: int,\n",
        "                 theta_size: int,\n",
        "                 horizon: int,\n",
        "                 n_neurons: int,\n",
        "                 n_layers: int,\n",
        "                 **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "      self.input_size = input_size\n",
        "      self.theta_size = theta_size\n",
        "      self.horizon = horizon\n",
        "      self.n_neurons = n_neurons\n",
        "      self.n_layers = n_layers\n",
        "\n",
        "      self.hidden=[layers.Dense(n_neurons, activation=\"relu\") for _ in range(n_layers)]\n",
        "      self.theta_layer=layers.Dense(theta_size, activation=\"linear\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "      x=inputs\n",
        "      for layer in self.hidden:\n",
        "        x=layer(x)\n",
        "      theta=self.theta_layer(x)\n",
        "      backast, forecast=theta[:,:self.input_size], theta[:,-self.horizon:]\n",
        "      return backast, forecast"
      ],
      "metadata": {
        "id": "oGetXk1rYcu0"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbeats_data=bitcoin_data.copy()\n",
        "for i in range(WINDOW_SIZE):\n",
        "  nbeats_data[f\"Price+{i+1}\"]=nbeats_data[\"price\"].shift(periods=i+1)"
      ],
      "metadata": {
        "id": "mpVD1hemaJ7P"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbeats_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "rD06T0hm_Dfi",
        "outputId": "063cd1c5-1cb6-4a00-8448-f8f2df3fcf2b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    price        Price+1        Price+2        Price+3  \\\n",
              "date                                                                     \n",
              "2025-10-02  120681.259723            NaN            NaN            NaN   \n",
              "2025-10-01  118648.928588  120681.259723            NaN            NaN   \n",
              "2025-09-30  114056.083647  118648.928588  120681.259723            NaN   \n",
              "2025-09-29  114400.386428  114056.083647  118648.928588  120681.259723   \n",
              "2025-09-28  112122.639151  114400.386428  114056.083647  118648.928588   \n",
              "\n",
              "                  Price+4  Price+5  Price+6  Price+7  \n",
              "date                                                  \n",
              "2025-10-02            NaN      NaN      NaN      NaN  \n",
              "2025-10-01            NaN      NaN      NaN      NaN  \n",
              "2025-09-30            NaN      NaN      NaN      NaN  \n",
              "2025-09-29            NaN      NaN      NaN      NaN  \n",
              "2025-09-28  120681.259723      NaN      NaN      NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a422de61-a652-41b2-8d2b-745da4fb9000\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-10-02</th>\n",
              "      <td>120681.259723</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-01</th>\n",
              "      <td>118648.928588</td>\n",
              "      <td>120681.259723</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-30</th>\n",
              "      <td>114056.083647</td>\n",
              "      <td>118648.928588</td>\n",
              "      <td>120681.259723</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-29</th>\n",
              "      <td>114400.386428</td>\n",
              "      <td>114056.083647</td>\n",
              "      <td>118648.928588</td>\n",
              "      <td>120681.259723</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-28</th>\n",
              "      <td>112122.639151</td>\n",
              "      <td>114400.386428</td>\n",
              "      <td>114056.083647</td>\n",
              "      <td>118648.928588</td>\n",
              "      <td>120681.259723</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a422de61-a652-41b2-8d2b-745da4fb9000')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a422de61-a652-41b2-8d2b-745da4fb9000 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a422de61-a652-41b2-8d2b-745da4fb9000');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d15a05e-d758-4f5a-a9f2-3d72573ad401\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d15a05e-d758-4f5a-a9f2-3d72573ad401')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d15a05e-d758-4f5a-a9f2-3d72573ad401 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "nbeats_data",
              "summary": "{\n  \"name\": \"nbeats_data\",\n  \"rows\": 5560,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-07-14\",\n        \"max\": \"2025-10-02\",\n        \"num_unique_values\": 5560,\n        \"samples\": [\n          \"2024-01-16\",\n          \"2014-09-27\",\n          \"2020-10-06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27911.04322599066,\n        \"min\": 0.05640216,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5543,\n        \"samples\": [\n          69.98967503,\n          57750.17734563,\n          5.15850195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27912.46893513631,\n        \"min\": 0.05756808,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5542,\n        \"samples\": [\n          546.3200073242,\n          4.9157707,\n          439.3229980469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27913.894694173825,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5541,\n        \"samples\": [\n          0.79093751,\n          6625.56,\n          189.90842722\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27915.32050386907,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5540,\n        \"samples\": [\n          0.79093751,\n          6625.56,\n          189.90842722\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27916.746362955102,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5539,\n        \"samples\": [\n          582.6900024414,\n          6625.56,\n          121.52853964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27918.172272856547,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5538,\n        \"samples\": [\n          754.0100097656,\n          29862.9182412919,\n          8336.55527417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27919.598231352767,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5537,\n        \"samples\": [\n          101.6999969482,\n          29862.9182412919,\n          8336.55527417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price+7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27921.02423857842,\n        \"min\": 0.05887483,\n        \"max\": 123344.0598056487,\n        \"num_unique_values\": 5536,\n        \"samples\": [\n          0.06975885,\n          29862.9182412919,\n          8336.55527417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "\n",
        "X=nbeats_data.dropna().drop(\"price\", axis=1)\n",
        "y=nbeats_data.dropna()[\"price\"]\n",
        "\n",
        "split_size=int(len(X)*0.8)\n",
        "X_train, y_train=X[:split_size], y[:split_size]\n",
        "X_test, y_test=X[split_size:], y[split_size:]"
      ],
      "metadata": {
        "id": "DjJSkEGV-JjY"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TDUeF5t_Mqp",
        "outputId": "53103149-7236-4291-f59c-40a7905bdc2c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4442, 4442, 1111, 1111)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch and prefetch data\n",
        "\n",
        "train_data_feature=tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_data_label=tf.data.Dataset.from_tensor_slices(y_train)\n",
        "train_data=tf.data.Dataset.zip((train_data_feature, train_data_label))\n",
        "\n",
        "test_data_feature=tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_data_label=tf.data.Dataset.from_tensor_slices(y_test)\n",
        "test_data=tf.data.Dataset.zip((test_data_feature, test_data_label))\n",
        "\n",
        "train_data=train_data.batch(batch_size=1024).prefetch(tf.data.AUTOTUNE)\n",
        "test_data=test_data.batch(batch_size=1024).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEzE2_rd_N7Z",
        "outputId": "49cbc738-507f-4bb9-c64a-c0c08cf1d014"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>,\n",
              " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIOuhMxYfyor",
        "outputId": "25db00ef-9423-4dc6-86e8-6036c3b953ac"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for N-Beats\n",
        "\n",
        "N_LAYERS=4\n",
        "N_NUERONS=512\n",
        "N_EPOCHS=500\n",
        "N_STACKS=30\n",
        "INPUT_SIZE=WINDOW_SIZE*HORIZON\n",
        "THETA_SIZE=WINDOW_SIZE+HORIZON"
      ],
      "metadata": {
        "id": "8pZ-CHhTV_VL"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "n_beats_block=NBeatsBlock(input_size=INPUT_SIZE,\n",
        "                          theta_size=THETA_SIZE,\n",
        "                          horizon=HORIZON,\n",
        "                          n_neurons=N_NUERONS,\n",
        "                          n_layers=N_LAYERS,\n",
        "                          name=\"N_Beats_Model\")\n",
        "\n",
        "stack_input=tf.keras.layers.Input(shape=(INPUT_SIZE,), name=\"stack_input\", dtype=tf.float32)\n",
        "residuals, forecast=n_beats_block(stack_input)\n",
        "for i, _ in enumerate(range(N_STACKS-1)):\n",
        "  backast, block_forecast=n_beats_block(residuals)\n",
        "  residuals=layers.add([residuals, backast], name=f\"residuals_{i}\")\n",
        "  forecast=layers.add([forecast, block_forecast], name=f\"forecast_{i}\")\n",
        "nbeats=tf.keras.Model(inputs=stack_input, outputs=forecast, name=\"N_Beats\")"
      ],
      "metadata": {
        "id": "723Y6o3sWqex"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbeats.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tZuHsS9hbPug",
        "outputId": "e3f32a15-3816-440e-f37e-ef468130166e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"N_Beats\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"N_Beats\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ stack_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ N_Beats_Model       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m),       │    \u001b[38;5;34m796,168\u001b[0m │ stack_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNBeatsBlock\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)]        │            │ N_Beats_Model[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ residuals_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ residuals_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ residuals_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_0 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ N_Beats_Model[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m1\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_1 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m2\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_2 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m3\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_3 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m4\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_4 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m5\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_5 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m6\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_6 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m7\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_7 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m8\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_8 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m9\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_9 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m10\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_10 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m11\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_11 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m12\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_12 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m13\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_13 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m14\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_0 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ N_Beats_Model[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m1\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_14 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m15\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_1 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m2\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_2 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m3\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_15 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m16\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_3 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m4\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_4 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m5\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_16 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m17\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_5 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m6\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_6 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m7\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_17 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m18\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_7 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m8\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_8 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m9\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_18 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m19\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_9 (\u001b[38;5;33mAdd\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m10\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_10 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m11\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_19 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m20\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_11 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m12\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_12 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m13\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_20 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m21\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_13 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m14\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_14 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m15\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_21 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m22\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_15 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m16\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_16 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m17\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_22 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m23\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_17 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m18\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_18 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m19\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_23 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m24\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_19 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m20\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_20 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m21\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_24 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m25\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_21 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m22\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_22 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m23\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_25 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m26\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_23 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m24\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_24 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m25\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_26 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m27\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_25 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m26\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_26 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m27\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_27 (\u001b[38;5;33mAdd\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ residuals_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m28\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_27 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m28\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_28 (\u001b[38;5;33mAdd\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ forecast_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ N_Beats_Model[\u001b[38;5;34m29\u001b[0m… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ stack_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ N_Beats_Model       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>),       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">796,168</span> │ stack_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NBeatsBlock</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]        │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ residuals_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ residuals_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ residuals_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residuals_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ residuals_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ forecast_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ forecast_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ N_Beats_Model[<span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m796,168\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">796,168</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m796,168\u001b[0m (3.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">796,168</span> (3.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nbeats.compile(loss=\"mae\",\n",
        "               optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "               metrics=[\"mae\", \"mse\"])"
      ],
      "metadata": {
        "id": "UhM2NLdoYKL6"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "nbeats.fit(train_data,\n",
        "           epochs=N_EPOCHS,\n",
        "           validation_data=test_data,\n",
        "           callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfWz4U4gYN3A",
        "outputId": "dae56121-5b8b-464e-fdc1-5855d25806de"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 186162.0469 - mae: 186162.0469 - mse: 132603084800.0000 - val_loss: 4.5727 - val_mae: 4.5727 - val_mse: 95.5824 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 8843.2100 - mae: 8843.2100 - mse: 158536736.0000 - val_loss: 74.4750 - val_mae: 74.4750 - val_mse: 22016.3281 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 96175.1484 - mae: 96175.1484 - mse: 26712995840.0000 - val_loss: 7.9962 - val_mae: 7.9962 - val_mse: 340.4132 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 17188.4336 - mae: 17188.4336 - mse: 577149440.0000 - val_loss: 7.5247 - val_mae: 7.5247 - val_mse: 298.8871 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 12317.0117 - mae: 12317.0117 - mse: 408376544.0000 - val_loss: 4.1273 - val_mae: 4.1273 - val_mse: 49.8990 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9583.4951 - mae: 9583.4951 - mse: 253581008.0000 - val_loss: 3.3210 - val_mae: 3.3210 - val_mse: 60.1358 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5231.9707 - mae: 5231.9707 - mse: 53220320.0000 - val_loss: 2.2790 - val_mae: 2.2790 - val_mse: 44.0061 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4118.9795 - mae: 4118.9795 - mse: 35456284.0000 - val_loss: 2.4174 - val_mae: 2.4174 - val_mse: 51.3622 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4771.4785 - mae: 4771.4785 - mse: 41541740.0000 - val_loss: 12.6375 - val_mae: 12.6375 - val_mse: 647.3719 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 21457.0156 - mae: 21457.0156 - mse: 885655424.0000 - val_loss: 8.0574 - val_mae: 8.0574 - val_mse: 283.1956 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 12048.0039 - mae: 12048.0039 - mse: 325657984.0000 - val_loss: 46.5778 - val_mae: 46.5778 - val_mse: 9160.8535 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 65638.1406 - mae: 65638.1406 - mse: 11622660096.0000 - val_loss: 15.2949 - val_mae: 15.2949 - val_mse: 1002.6454 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 27916.9336 - mae: 27916.9336 - mse: 1466445952.0000 - val_loss: 15.8456 - val_mae: 15.8456 - val_mse: 1095.4576 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 28797.4883 - mae: 28797.4883 - mse: 1599656704.0000 - val_loss: 4.5638 - val_mae: 4.5638 - val_mse: 121.6727 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 13693.5703 - mae: 13693.5703 - mse: 351410368.0000 - val_loss: 6.7271 - val_mae: 6.7271 - val_mse: 231.5066 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 12181.9404 - mae: 12181.9404 - mse: 323825280.0000 - val_loss: 30.2722 - val_mae: 30.2722 - val_mse: 3014.1357 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 34824.8438 - mae: 34824.8438 - mse: 3399415296.0000 - val_loss: 13.8463 - val_mae: 13.8463 - val_mse: 901.0966 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 27405.5801 - mae: 27405.5801 - mse: 1416249728.0000 - val_loss: 14.4410 - val_mae: 14.4410 - val_mse: 1001.1649 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 28736.7773 - mae: 28736.7773 - mse: 1577336064.0000 - val_loss: 12.2340 - val_mae: 12.2340 - val_mse: 702.1889 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 23938.2578 - mae: 23938.2578 - mse: 1146505088.0000 - val_loss: 49.4678 - val_mae: 49.4678 - val_mse: 5189.5889 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 40970.3672 - mae: 40970.3672 - mse: 4411267584.0000 - val_loss: 13.8855 - val_mae: 13.8855 - val_mse: 860.8071 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 28040.4531 - mae: 28040.4531 - mse: 1491377024.0000 - val_loss: 13.5217 - val_mae: 13.5217 - val_mse: 785.5961 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 26040.3398 - mae: 26040.3398 - mse: 1334215040.0000 - val_loss: 35.3408 - val_mae: 35.3408 - val_mse: 2580.5046 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 30958.4062 - mae: 30958.4062 - mse: 2212708352.0000 - val_loss: 15.1302 - val_mae: 15.1302 - val_mse: 942.2269 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 29445.5000 - mae: 29445.5000 - mse: 1646752000.0000 - val_loss: 15.0264 - val_mae: 15.0264 - val_mse: 910.5798 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 28547.2969 - mae: 28547.2969 - mse: 1567198080.0000 - val_loss: 12.4472 - val_mae: 12.4472 - val_mse: 411.3747 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 17641.2031 - mae: 17641.2031 - mse: 667170112.0000 - val_loss: 98.8945 - val_mae: 98.8945 - val_mse: 28720.6211 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 103556.8281 - mae: 103556.8281 - mse: 31143784448.0000 - val_loss: 16.7107 - val_mae: 16.7107 - val_mse: 1129.8344 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 32551.6914 - mae: 32551.6914 - mse: 2009607040.0000 - val_loss: 16.8133 - val_mae: 16.8133 - val_mse: 1125.3762 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 31797.1035 - mae: 31797.1035 - mse: 1949800576.0000 - val_loss: 25.2585 - val_mae: 25.2585 - val_mse: 802.8416 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 13721.5127 - mae: 13721.5127 - mse: 313130368.0000 - val_loss: 17.3753 - val_mae: 17.3753 - val_mse: 1122.2072 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 32527.5098 - mae: 32527.5098 - mse: 2009570048.0000 - val_loss: 17.6472 - val_mae: 17.6472 - val_mse: 1071.9752 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 31892.9512 - mae: 31892.9512 - mse: 1950577664.0000 - val_loss: 18.8883 - val_mae: 18.8883 - val_mse: 467.8658 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 14638.1582 - mae: 14638.1582 - mse: 564700928.0000 - val_loss: 24.4984 - val_mae: 24.4984 - val_mse: 636.2977 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 10765.2275 - mae: 10765.2275 - mse: 264082272.0000 - val_loss: 20.9608 - val_mae: 20.9608 - val_mse: 477.0038 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8793.2188 - mae: 8793.2188 - mse: 171300672.0000 - val_loss: 67.2219 - val_mae: 67.2219 - val_mse: 7951.3521 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 45594.6289 - mae: 45594.6289 - mse: 5850496512.0000 - val_loss: 18.2975 - val_mae: 18.2975 - val_mse: 938.6804 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 30348.3574 - mae: 30348.3574 - mse: 1734958976.0000 - val_loss: 18.5351 - val_mae: 18.5351 - val_mse: 1093.4553 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 32657.2500 - mae: 32657.2500 - mse: 2025674112.0000 - val_loss: 18.8244 - val_mae: 18.8244 - val_mse: 1085.8356 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 32549.9082 - mae: 32549.9082 - mse: 2020720000.0000 - val_loss: 18.6512 - val_mae: 18.6512 - val_mse: 852.7263 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 27869.3887 - mae: 27869.3887 - mse: 1544805632.0000 - val_loss: 78.4686 - val_mae: 78.4686 - val_mse: 15418.4756 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 75136.7344 - mae: 75136.7344 - mse: 15185491968.0000 - val_loss: 19.6429 - val_mae: 19.6429 - val_mse: 912.9285 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 29158.0605 - mae: 29158.0605 - mse: 1644463104.0000 - val_loss: 28.1436 - val_mae: 28.1436 - val_mse: 833.0396 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 23335.9277 - mae: 23335.9277 - mse: 2425548032.0000 - val_loss: 21.3332 - val_mae: 21.3332 - val_mse: 954.1324 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 30806.0547 - mae: 30806.0547 - mse: 1789019136.0000 - val_loss: 20.7091 - val_mae: 20.7091 - val_mse: 1074.6169 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 32550.8184 - mae: 32550.8184 - mse: 2016378112.0000 - val_loss: 21.3714 - val_mae: 21.3714 - val_mse: 1025.2142 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 31599.0234 - mae: 31599.0234 - mse: 1911339776.0000 - val_loss: 24.4162 - val_mae: 24.4162 - val_mse: 802.6346 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 23578.2773 - mae: 23578.2773 - mse: 1185110912.0000 - val_loss: 172.7647 - val_mae: 172.7647 - val_mse: 56283.6914 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 124402.4062 - mae: 124402.4062 - mse: 43382845440.0000 - val_loss: 22.1724 - val_mae: 22.1724 - val_mse: 1129.1143 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 33459.1992 - mae: 33459.1992 - mse: 2128297984.0000 - val_loss: 22.5089 - val_mae: 22.5089 - val_mse: 1068.1920 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 31655.2090 - mae: 31655.2090 - mse: 1939641600.0000 - val_loss: 70.8298 - val_mae: 70.8298 - val_mse: 6025.2383 - learning_rate: 0.0010\n",
            "Epoch 52/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 30907.4141 - mae: 30907.4141 - mse: 1928290304.0000 - val_loss: 21.4874 - val_mae: 21.4874 - val_mse: 1157.2354 - learning_rate: 0.0010\n",
            "Epoch 53/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 33671.4141 - mae: 33671.4141 - mse: 2153038336.0000 - val_loss: 21.0944 - val_mae: 21.0944 - val_mse: 1168.0359 - learning_rate: 0.0010\n",
            "Epoch 54/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 33927.9727 - mae: 33927.9727 - mse: 2189099264.0000 - val_loss: 21.2240 - val_mae: 21.2240 - val_mse: 1145.5769 - learning_rate: 0.0010\n",
            "Epoch 55/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 33457.2695 - mae: 33457.2695 - mse: 2132692096.0000 - val_loss: 21.3883 - val_mae: 21.3883 - val_mse: 1054.2993 - learning_rate: 0.0010\n",
            "Epoch 56/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 31557.1895 - mae: 31557.1895 - mse: 1910693760.0000 - val_loss: 20.3041 - val_mae: 20.3041 - val_mse: 664.8019 - learning_rate: 0.0010\n",
            "Epoch 57/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 21980.2734 - mae: 21980.2734 - mse: 1033359424.0000 - val_loss: 152.3985 - val_mae: 152.3985 - val_mse: 68098.5391 - learning_rate: 0.0010\n",
            "Epoch 58/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 157933.2812 - mae: 157933.2812 - mse: 73156255744.0000 - val_loss: 21.6837 - val_mae: 21.6837 - val_mse: 1081.1763 - learning_rate: 0.0010\n",
            "Epoch 59/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 32679.5020 - mae: 32679.5020 - mse: 2021857152.0000 - val_loss: 21.6515 - val_mae: 21.6515 - val_mse: 1163.3546 - learning_rate: 0.0010\n",
            "Epoch 60/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 33659.6914 - mae: 33659.6914 - mse: 2154256384.0000 - val_loss: 23.1270 - val_mae: 23.1270 - val_mse: 1126.6285 - learning_rate: 0.0010\n",
            "Epoch 61/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 32721.2891 - mae: 32721.2891 - mse: 2052790528.0000 - val_loss: 33.9302 - val_mae: 33.9302 - val_mse: 1234.9618 - learning_rate: 0.0010\n",
            "Epoch 62/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 16275.9580 - mae: 16275.9580 - mse: 520119072.0000 - val_loss: 31.2454 - val_mae: 31.2454 - val_mse: 1047.2924 - learning_rate: 0.0010\n",
            "Epoch 63/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 20709.1992 - mae: 20709.1992 - mse: 853492032.0000 - val_loss: 75.6413 - val_mae: 75.6413 - val_mse: 6068.7637 - learning_rate: 0.0010\n",
            "Epoch 64/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 18305.8379 - mae: 18305.8379 - mse: 691539264.0000 - val_loss: 26.6570 - val_mae: 26.6570 - val_mse: 1036.9037 - learning_rate: 0.0010\n",
            "Epoch 65/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 30021.8398 - mae: 30021.8398 - mse: 1703014016.0000 - val_loss: 25.5993 - val_mae: 25.5993 - val_mse: 1090.4980 - learning_rate: 0.0010\n",
            "Epoch 66/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 31650.9297 - mae: 31650.9297 - mse: 1904788736.0000 - val_loss: 26.3286 - val_mae: 26.3286 - val_mse: 1097.8925 - learning_rate: 0.0010\n",
            "Epoch 67/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 31421.6641 - mae: 31421.6641 - mse: 1881237120.0000 - val_loss: 28.1823 - val_mae: 28.1823 - val_mse: 1101.0468 - learning_rate: 0.0010\n",
            "Epoch 68/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 30168.5195 - mae: 30168.5195 - mse: 1740539904.0000 - val_loss: 31.9974 - val_mae: 31.9974 - val_mse: 1169.4324 - learning_rate: 0.0010\n",
            "Epoch 69/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 26551.4648 - mae: 26551.4648 - mse: 1371387392.0000 - val_loss: 50.2310 - val_mae: 50.2310 - val_mse: 2654.0671 - learning_rate: 0.0010\n",
            "Epoch 70/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 10239.4258 - mae: 10239.4258 - mse: 209993456.0000 - val_loss: 74.3401 - val_mae: 74.3401 - val_mse: 5588.8521 - learning_rate: 0.0010\n",
            "Epoch 71/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8580.8594 - mae: 8580.8594 - mse: 127292096.0000 - val_loss: 34.0763 - val_mae: 34.0763 - val_mse: 1249.8020 - learning_rate: 0.0010\n",
            "Epoch 72/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 24544.7402 - mae: 24544.7402 - mse: 1142104320.0000 - val_loss: 33.3352 - val_mae: 33.3352 - val_mse: 1207.0662 - learning_rate: 0.0010\n",
            "Epoch 73/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 24489.3672 - mae: 24489.3672 - mse: 1155666944.0000 - val_loss: 37.5986 - val_mae: 37.5986 - val_mse: 1511.2742 - learning_rate: 0.0010\n",
            "Epoch 74/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 17084.5664 - mae: 17084.5664 - mse: 607702464.0000 - val_loss: 94.5073 - val_mae: 94.5073 - val_mse: 9689.4189 - learning_rate: 0.0010\n",
            "Epoch 75/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 23344.7324 - mae: 23344.7324 - mse: 1409355648.0000 - val_loss: 34.6604 - val_mae: 34.6604 - val_mse: 1284.2272 - learning_rate: 0.0010\n",
            "Epoch 76/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 24400.2988 - mae: 24400.2988 - mse: 1116238336.0000 - val_loss: 32.3914 - val_mae: 32.3914 - val_mse: 1202.1179 - learning_rate: 0.0010\n",
            "Epoch 77/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 27718.1680 - mae: 27718.1680 - mse: 1461550592.0000 - val_loss: 33.0617 - val_mae: 33.0617 - val_mse: 1230.8436 - learning_rate: 0.0010\n",
            "Epoch 78/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 27166.4766 - mae: 27166.4766 - mse: 1412683776.0000 - val_loss: 35.8643 - val_mae: 35.8643 - val_mse: 1368.1526 - learning_rate: 0.0010\n",
            "Epoch 79/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 23668.7969 - mae: 23668.7969 - mse: 1090540416.0000 - val_loss: 46.6085 - val_mae: 46.6085 - val_mse: 2326.0483 - learning_rate: 0.0010\n",
            "Epoch 80/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 10191.7969 - mae: 10191.7969 - mse: 239032240.0000 - val_loss: 176.6476 - val_mae: 176.6476 - val_mse: 40984.9531 - learning_rate: 0.0010\n",
            "Epoch 81/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 79926.3438 - mae: 79926.3438 - mse: 17402206208.0000 - val_loss: 33.8845 - val_mae: 33.8845 - val_mse: 1288.9178 - learning_rate: 0.0010\n",
            "Epoch 82/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 28358.5195 - mae: 28358.5195 - mse: 1512572160.0000 - val_loss: 31.4709 - val_mae: 31.4709 - val_mse: 1239.8450 - learning_rate: 0.0010\n",
            "Epoch 83/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 31131.0117 - mae: 31131.0117 - mse: 1840471040.0000 - val_loss: 31.6533 - val_mae: 31.6533 - val_mse: 1260.7261 - learning_rate: 0.0010\n",
            "Epoch 84/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 31559.4102 - mae: 31559.4102 - mse: 1895102464.0000 - val_loss: 33.3358 - val_mae: 33.3358 - val_mse: 1326.8486 - learning_rate: 0.0010\n",
            "Epoch 85/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 31204.9824 - mae: 31204.9824 - mse: 1856847872.0000 - val_loss: 37.5495 - val_mae: 37.5495 - val_mse: 1536.7144 - learning_rate: 0.0010\n",
            "Epoch 86/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 29348.6719 - mae: 29348.6719 - mse: 1656831104.0000 - val_loss: 53.9193 - val_mae: 53.9193 - val_mse: 3176.1648 - learning_rate: 0.0010\n",
            "Epoch 87/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 17875.4961 - mae: 17875.4961 - mse: 665812224.0000 - val_loss: 308.1879 - val_mae: 308.1879 - val_mse: 122821.4453 - learning_rate: 0.0010\n",
            "Epoch 88/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 127277.5625 - mae: 127277.5625 - mse: 46493360128.0000 - val_loss: 33.9140 - val_mae: 33.9140 - val_mse: 1395.9131 - learning_rate: 0.0010\n",
            "Epoch 89/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 32691.4395 - mae: 32691.4395 - mse: 2023986560.0000 - val_loss: 31.2071 - val_mae: 31.2071 - val_mse: 1330.5210 - learning_rate: 0.0010\n",
            "Epoch 90/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 33766.1680 - mae: 33766.1680 - mse: 2166890240.0000 - val_loss: 31.1504 - val_mae: 31.1504 - val_mse: 1335.4391 - learning_rate: 0.0010\n",
            "Epoch 91/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 33750.6797 - mae: 33750.6797 - mse: 2167438336.0000 - val_loss: 33.5872 - val_mae: 33.5872 - val_mse: 1419.0209 - learning_rate: 0.0010\n",
            "Epoch 92/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 33188.6445 - mae: 33188.6445 - mse: 2100525184.0000 - val_loss: 45.2242 - val_mae: 45.2242 - val_mse: 2157.8169 - learning_rate: 0.0010\n",
            "Epoch 93/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 29360.0762 - mae: 29360.0762 - mse: 1712409600.0000 - val_loss: 566.3384 - val_mae: 566.3384 - val_mse: 356667.0938 - learning_rate: 0.0010\n",
            "Epoch 94/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 159208.5312 - mae: 159208.5312 - mse: 68646686720.0000 - val_loss: 30.8840 - val_mae: 30.8840 - val_mse: 1350.2952 - learning_rate: 0.0010\n",
            "Epoch 95/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 34725.6094 - mae: 34725.6094 - mse: 2292311808.0000 - val_loss: 29.8640 - val_mae: 29.8640 - val_mse: 1315.5507 - learning_rate: 0.0010\n",
            "Epoch 96/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 34692.7500 - mae: 34692.7500 - mse: 2289312000.0000 - val_loss: 30.6362 - val_mae: 30.6362 - val_mse: 1330.5369 - learning_rate: 0.0010\n",
            "Epoch 97/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 34284.4961 - mae: 34284.4961 - mse: 2240094208.0000 - val_loss: 33.1718 - val_mae: 33.1718 - val_mse: 1340.2876 - learning_rate: 0.0010\n",
            "Epoch 98/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 30579.2559 - mae: 30579.2559 - mse: 1834285312.0000 - val_loss: 84.8917 - val_mae: 84.8917 - val_mse: 8905.3994 - learning_rate: 0.0010\n",
            "Epoch 99/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 35845.5977 - mae: 35845.5977 - mse: 3012284928.0000 - val_loss: 31.9387 - val_mae: 31.9387 - val_mse: 1320.7660 - learning_rate: 0.0010\n",
            "Epoch 100/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 32673.9941 - mae: 32673.9941 - mse: 2022606848.0000 - val_loss: 31.0861 - val_mae: 31.0861 - val_mse: 1319.4668 - learning_rate: 0.0010\n",
            "Epoch 101/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 33600.4258 - mae: 33600.4258 - mse: 2147685376.0000 - val_loss: 31.3827 - val_mae: 31.3827 - val_mse: 1310.4697 - learning_rate: 0.0010\n",
            "Epoch 102/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 32936.3047 - mae: 32936.3047 - mse: 2071149568.0000 - val_loss: 32.7117 - val_mae: 32.7117 - val_mse: 1220.8057 - learning_rate: 0.0010\n",
            "Epoch 103/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 26663.2578 - mae: 26663.2578 - mse: 1461507840.0000 - val_loss: 273.5010 - val_mae: 273.5010 - val_mse: 173300.2500 - learning_rate: 0.0010\n",
            "Epoch 104/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 232220.4375 - mae: 232220.4375 - mse: 154257457152.0000 - val_loss: 28.7630 - val_mae: 28.7630 - val_mse: 1271.5544 - learning_rate: 0.0010\n",
            "Epoch 105/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 33913.6602 - mae: 33913.6602 - mse: 2182740224.0000 - val_loss: 27.3597 - val_mae: 27.3597 - val_mse: 1243.6221 - learning_rate: 0.0010\n",
            "Epoch 106/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 33798.5742 - mae: 33798.5742 - mse: 2180784640.0000 - val_loss: 31.1599 - val_mae: 31.1599 - val_mse: 1148.4777 - learning_rate: 0.0010\n",
            "Epoch 107/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 27430.2188 - mae: 27430.2188 - mse: 1498626048.0000\n",
            "Epoch 107: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 25489.9883 - mae: 25489.9883 - mse: 1380761728.0000 - val_loss: 229.1654 - val_mae: 229.1654 - val_mse: 85445.9375 - learning_rate: 0.0010\n",
            "Epoch 108/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 169506.6250 - mae: 169506.6250 - mse: 60164816896.0000 - val_loss: 76.5236 - val_mae: 76.5236 - val_mse: 6436.0161 - learning_rate: 1.0000e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 20948.8066 - mae: 20948.8066 - mse: 1024449984.0000 - val_loss: 36.2735 - val_mae: 36.2735 - val_mse: 1427.7413 - learning_rate: 1.0000e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 13934.2871 - mae: 13934.2871 - mse: 355346912.0000 - val_loss: 32.2233 - val_mae: 32.2233 - val_mse: 1112.0941 - learning_rate: 1.0000e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 21376.3477 - mae: 21376.3477 - mse: 863738368.0000 - val_loss: 31.2223 - val_mae: 31.2223 - val_mse: 1075.1727 - learning_rate: 1.0000e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 23546.9023 - mae: 23546.9023 - mse: 1054493952.0000 - val_loss: 31.0055 - val_mae: 31.0055 - val_mse: 1071.1118 - learning_rate: 1.0000e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 24026.4570 - mae: 24026.4570 - mse: 1100571904.0000 - val_loss: 31.1646 - val_mae: 31.1646 - val_mse: 1075.6600 - learning_rate: 1.0000e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 23721.4395 - mae: 23721.4395 - mse: 1074610432.0000 - val_loss: 31.5675 - val_mae: 31.5675 - val_mse: 1087.7225 - learning_rate: 1.0000e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 22898.1504 - mae: 22898.1504 - mse: 1003032320.0000 - val_loss: 32.1693 - val_mae: 32.1693 - val_mse: 1111.9590 - learning_rate: 1.0000e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 21632.7246 - mae: 21632.7246 - mse: 897185280.0000 - val_loss: 32.9677 - val_mae: 32.9677 - val_mse: 1157.5690 - learning_rate: 1.0000e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 19889.9727 - mae: 19889.9727 - mse: 760923200.0000 - val_loss: 34.1215 - val_mae: 34.1215 - val_mse: 1240.6990 - learning_rate: 1.0000e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 17538.4824 - mae: 17538.4824 - mse: 594975808.0000 - val_loss: 35.8917 - val_mae: 35.8917 - val_mse: 1393.2430 - learning_rate: 1.0000e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 14319.8203 - mae: 14319.8203 - mse: 401368064.0000 - val_loss: 39.6666 - val_mae: 39.6666 - val_mse: 1685.3153 - learning_rate: 1.0000e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9696.2412 - mae: 9696.2412 - mse: 190852208.0000 - val_loss: 47.4530 - val_mae: 47.4530 - val_mse: 2294.5874 - learning_rate: 1.0000e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2825.8472 - mae: 2825.8472 - mse: 19957428.0000 - val_loss: 58.6319 - val_mae: 58.6319 - val_mse: 3506.2986 - learning_rate: 1.0000e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7021.6602 - mae: 7021.6602 - mse: 96504096.0000 - val_loss: 56.4162 - val_mae: 56.4162 - val_mse: 3231.6782 - learning_rate: 1.0000e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4595.1646 - mae: 4595.1646 - mse: 47542176.0000 - val_loss: 47.6465 - val_mae: 47.6465 - val_mse: 2311.2119 - learning_rate: 1.0000e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2978.1135 - mae: 2978.1135 - mse: 19614936.0000 - val_loss: 47.3815 - val_mae: 47.3815 - val_mse: 2286.7188 - learning_rate: 1.0000e-04\n",
            "Epoch 125/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2835.4727 - mae: 2835.4727 - mse: 19162212.0000 - val_loss: 52.1916 - val_mae: 52.1916 - val_mse: 2756.5935 - learning_rate: 1.0000e-04\n",
            "Epoch 126/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1825.7521 - mae: 1825.7521 - mse: 8184606.5000 - val_loss: 50.6371 - val_mae: 50.6371 - val_mse: 2595.2314 - learning_rate: 1.0000e-04\n",
            "Epoch 127/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1186.5941 - mae: 1186.5941 - mse: 3917715.2500 - val_loss: 48.7051 - val_mae: 48.7051 - val_mse: 2405.9895 - learning_rate: 1.0000e-04\n",
            "Epoch 128/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1648.3021 - mae: 1648.3021 - mse: 6962826.0000 - val_loss: 50.9410 - val_mae: 50.9410 - val_mse: 2626.1326 - learning_rate: 1.0000e-04\n",
            "Epoch 129/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1404.2388 - mae: 1404.2388 - mse: 5185895.0000 - val_loss: 49.3367 - val_mae: 49.3367 - val_mse: 2465.4622 - learning_rate: 1.0000e-04\n",
            "Epoch 130/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1222.7867 - mae: 1222.7867 - mse: 4050566.0000 - val_loss: 49.6390 - val_mae: 49.6390 - val_mse: 2494.7593 - learning_rate: 1.0000e-04\n",
            "Epoch 131/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1160.0413 - mae: 1160.0413 - mse: 3727298.2500 - val_loss: 49.4327 - val_mae: 49.4327 - val_mse: 2474.2009 - learning_rate: 1.0000e-04\n",
            "Epoch 132/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1155.1163 - mae: 1155.1163 - mse: 3710965.5000 - val_loss: 48.8709 - val_mae: 48.8709 - val_mse: 2419.1584 - learning_rate: 1.0000e-04\n",
            "Epoch 133/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1174.5846 - mae: 1174.5846 - mse: 3777323.0000 - val_loss: 49.2593 - val_mae: 49.2593 - val_mse: 2456.7341 - learning_rate: 1.0000e-04\n",
            "Epoch 134/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1180.5701 - mae: 1180.5701 - mse: 3842034.2500 - val_loss: 48.1288 - val_mae: 48.1288 - val_mse: 2347.4028 - learning_rate: 1.0000e-04\n",
            "Epoch 135/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1236.6798 - mae: 1236.6798 - mse: 4111097.5000 - val_loss: 49.0682 - val_mae: 49.0682 - val_mse: 2437.7102 - learning_rate: 1.0000e-04\n",
            "Epoch 136/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1238.7061 - mae: 1238.7061 - mse: 4166790.5000 - val_loss: 47.5386 - val_mae: 47.5386 - val_mse: 2291.0618 - learning_rate: 1.0000e-04\n",
            "Epoch 137/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1283.0972 - mae: 1283.0972 - mse: 4389207.5000 - val_loss: 48.6202 - val_mae: 48.6202 - val_mse: 2393.7227 - learning_rate: 1.0000e-04\n",
            "Epoch 138/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1229.9785 - mae: 1229.9785 - mse: 4108140.2500 - val_loss: 47.1913 - val_mae: 47.1913 - val_mse: 2257.8247 - learning_rate: 1.0000e-04\n",
            "Epoch 139/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1249.9620 - mae: 1249.9620 - mse: 4181947.5000 - val_loss: 48.1344 - val_mae: 48.1344 - val_mse: 2346.4934 - learning_rate: 1.0000e-04\n",
            "Epoch 140/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1209.0504 - mae: 1209.0504 - mse: 3985213.0000 - val_loss: 46.7666 - val_mae: 46.7666 - val_mse: 2217.7539 - learning_rate: 1.0000e-04\n",
            "Epoch 141/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1243.9535 - mae: 1243.9535 - mse: 4140772.2500 - val_loss: 47.7591 - val_mae: 47.7591 - val_mse: 2310.2944 - learning_rate: 1.0000e-04\n",
            "Epoch 142/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1221.1499 - mae: 1221.1499 - mse: 4053809.2500 - val_loss: 46.2795 - val_mae: 46.2795 - val_mse: 2172.4114 - learning_rate: 1.0000e-04\n",
            "Epoch 143/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1260.7382 - mae: 1260.7382 - mse: 4237037.5000 - val_loss: 47.3643 - val_mae: 47.3643 - val_mse: 2272.5393 - learning_rate: 1.0000e-04\n",
            "Epoch 144/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1228.0748 - mae: 1228.0748 - mse: 4093252.2500 - val_loss: 45.7956 - val_mae: 45.7956 - val_mse: 2127.8611 - learning_rate: 1.0000e-04\n",
            "Epoch 145/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1278.6935 - mae: 1278.6935 - mse: 4344083.5000 - val_loss: 46.9412 - val_mae: 46.9412 - val_mse: 2232.4497 - learning_rate: 1.0000e-04\n",
            "Epoch 146/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1224.8967 - mae: 1224.8967 - mse: 4070417.5000 - val_loss: 45.3793 - val_mae: 45.3793 - val_mse: 2089.7830 - learning_rate: 1.0000e-04\n",
            "Epoch 147/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1272.4878 - mae: 1272.4878 - mse: 4301179.5000 - val_loss: 46.5414 - val_mae: 46.5414 - val_mse: 2194.9065 - learning_rate: 1.0000e-04\n",
            "Epoch 148/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1228.3984 - mae: 1228.3984 - mse: 4089589.0000 - val_loss: 44.9272 - val_mae: 44.9272 - val_mse: 2048.9478 - learning_rate: 1.0000e-04\n",
            "Epoch 149/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1283.2975 - mae: 1283.2975 - mse: 4363558.0000 - val_loss: 46.1319 - val_mae: 46.1319 - val_mse: 2156.7373 - learning_rate: 1.0000e-04\n",
            "Epoch 150/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1228.6035 - mae: 1228.6035 - mse: 4088439.7500 - val_loss: 44.5065 - val_mae: 44.5065 - val_mse: 2011.2532 - learning_rate: 1.0000e-04\n",
            "Epoch 151/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1282.0464 - mae: 1282.0464 - mse: 4351299.5000 - val_loss: 45.7361 - val_mae: 45.7361 - val_mse: 2120.1243 - learning_rate: 1.0000e-04\n",
            "Epoch 152/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1233.5076 - mae: 1233.5076 - mse: 4116074.5000 - val_loss: 44.0454 - val_mae: 44.0454 - val_mse: 1970.4720 - learning_rate: 1.0000e-04\n",
            "Epoch 153/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1298.0548 - mae: 1298.0548 - mse: 4448524.0000 - val_loss: 45.3859 - val_mae: 45.3859 - val_mse: 2087.9656 - learning_rate: 1.0000e-04\n",
            "Epoch 154/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1259.0326 - mae: 1259.0326 - mse: 4268348.0000 - val_loss: 43.5771 - val_mae: 43.5771 - val_mse: 1929.5464 - learning_rate: 1.0000e-04\n",
            "Epoch 155/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1320.7758 - mae: 1320.7758 - mse: 4589037.0000 - val_loss: 44.9631 - val_mae: 44.9631 - val_mse: 2049.5779 - learning_rate: 1.0000e-04\n",
            "Epoch 156/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1255.1913 - mae: 1255.1913 - mse: 4242901.5000 - val_loss: 43.1859 - val_mae: 43.1859 - val_mse: 1895.4991 - learning_rate: 1.0000e-04\n",
            "Epoch 157/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1308.3446 - mae: 1308.3446 - mse: 4507543.0000 - val_loss: 44.5562 - val_mae: 44.5562 - val_mse: 2012.9557 - learning_rate: 1.0000e-04\n",
            "Epoch 158/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1256.7673 - mae: 1256.7673 - mse: 4252437.5000 - val_loss: 42.7530 - val_mae: 42.7530 - val_mse: 1858.3418 - learning_rate: 1.0000e-04\n",
            "Epoch 159/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1317.5604 - mae: 1317.5604 - mse: 4563177.0000 - val_loss: 44.1413 - val_mae: 44.1413 - val_mse: 1975.9904 - learning_rate: 1.0000e-04\n",
            "Epoch 160/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1254.5746 - mae: 1254.5746 - mse: 4238735.0000 - val_loss: 42.3431 - val_mae: 42.3431 - val_mse: 1823.4579 - learning_rate: 1.0000e-04\n",
            "Epoch 161/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1316.7828 - mae: 1316.7828 - mse: 4555815.5000 - val_loss: 43.7400 - val_mae: 43.7400 - val_mse: 1940.5470 - learning_rate: 1.0000e-04\n",
            "Epoch 162/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1257.3243 - mae: 1257.3243 - mse: 4255549.0000 - val_loss: 41.9300 - val_mae: 41.9300 - val_mse: 1788.6659 - learning_rate: 1.0000e-04\n",
            "Epoch 163/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1318.5061 - mae: 1318.5061 - mse: 4564979.0000 - val_loss: 43.3700 - val_mae: 43.3700 - val_mse: 1908.1299 - learning_rate: 1.0000e-04\n",
            "Epoch 164/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1274.3201 - mae: 1274.3201 - mse: 4361591.5000 - val_loss: 41.4753 - val_mae: 41.4753 - val_mse: 1750.9291 - learning_rate: 1.0000e-04\n",
            "Epoch 165/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1343.6262 - mae: 1343.6262 - mse: 4723028.5000 - val_loss: 43.0153 - val_mae: 43.0153 - val_mse: 1877.2950 - learning_rate: 1.0000e-04\n",
            "Epoch 166/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1299.4628 - mae: 1299.4628 - mse: 4519413.0000 - val_loss: 41.0070 - val_mae: 41.0070 - val_mse: 1712.5732 - learning_rate: 1.0000e-04\n",
            "Epoch 167/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1381.9382 - mae: 1381.9382 - mse: 4967978.5000 - val_loss: 42.5969 - val_mae: 42.5969 - val_mse: 1841.3246 - learning_rate: 1.0000e-04\n",
            "Epoch 168/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1291.6359 - mae: 1291.6359 - mse: 4467938.0000 - val_loss: 40.6517 - val_mae: 40.6517 - val_mse: 1683.4288 - learning_rate: 1.0000e-04\n",
            "Epoch 169/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1357.7292 - mae: 1357.7292 - mse: 4807349.5000 - val_loss: 42.1908 - val_mae: 42.1908 - val_mse: 1806.7238 - learning_rate: 1.0000e-04\n",
            "Epoch 170/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1285.7285 - mae: 1285.7285 - mse: 4433251.0000 - val_loss: 40.2273 - val_mae: 40.2273 - val_mse: 1649.2188 - learning_rate: 1.0000e-04\n",
            "Epoch 171/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1373.9022 - mae: 1373.9022 - mse: 4909348.5000 - val_loss: 41.8409 - val_mae: 41.8409 - val_mse: 1777.0422 - learning_rate: 1.0000e-04\n",
            "Epoch 172/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1309.6366 - mae: 1309.6366 - mse: 4580494.5000 - val_loss: 39.7934 - val_mae: 39.7934 - val_mse: 1614.7047 - learning_rate: 1.0000e-04\n",
            "Epoch 173/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1403.3541 - mae: 1403.3541 - mse: 5093599.0000 - val_loss: 41.4667 - val_mae: 41.4667 - val_mse: 1745.7466 - learning_rate: 1.0000e-04\n",
            "Epoch 174/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1313.7810 - mae: 1313.7810 - mse: 4606928.0000 - val_loss: 39.4260 - val_mae: 39.4260 - val_mse: 1585.5146 - learning_rate: 1.0000e-04\n",
            "Epoch 175/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1394.0210 - mae: 1394.0210 - mse: 5027482.0000 - val_loss: 41.0633 - val_mae: 41.0633 - val_mse: 1712.3033 - learning_rate: 1.0000e-04\n",
            "Epoch 176/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1298.7689 - mae: 1298.7689 - mse: 4516107.0000 - val_loss: 39.0637 - val_mae: 39.0637 - val_mse: 1556.9023 - learning_rate: 1.0000e-04\n",
            "Epoch 177/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1378.9907 - mae: 1378.9907 - mse: 4923695.0000 - val_loss: 40.7187 - val_mae: 40.7187 - val_mse: 1683.8003 - learning_rate: 1.0000e-04\n",
            "Epoch 178/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1327.4340 - mae: 1327.4340 - mse: 4699473.5000 - val_loss: 38.4985 - val_mae: 38.4985 - val_mse: 1513.8713 - learning_rate: 1.0000e-04\n",
            "Epoch 179/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1508.3142 - mae: 1508.3142 - mse: 5810544.5000 - val_loss: 40.2824 - val_mae: 40.2824 - val_mse: 1648.5720 - learning_rate: 1.0000e-04\n",
            "Epoch 180/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1288.7139 - mae: 1288.7139 - mse: 4447756.0000 - val_loss: 38.3876 - val_mae: 38.3876 - val_mse: 1504.3369 - learning_rate: 1.0000e-04\n",
            "Epoch 181/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1333.8585 - mae: 1333.8585 - mse: 4627135.0000 - val_loss: 39.9205 - val_mae: 39.9205 - val_mse: 1619.4050 - learning_rate: 1.0000e-04\n",
            "Epoch 182/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1293.4211 - mae: 1293.4211 - mse: 4488387.0000 - val_loss: 37.8131 - val_mae: 37.8131 - val_mse: 1461.4265 - learning_rate: 1.0000e-04\n",
            "Epoch 183/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1467.5157 - mae: 1467.5157 - mse: 5517320.5000 - val_loss: 39.5517 - val_mae: 39.5517 - val_mse: 1590.0046 - learning_rate: 1.0000e-04\n",
            "Epoch 184/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1300.9662 - mae: 1300.9662 - mse: 4525954.5000 - val_loss: 37.5435 - val_mae: 37.5435 - val_mse: 1440.7472 - learning_rate: 1.0000e-04\n",
            "Epoch 185/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1399.8688 - mae: 1399.8688 - mse: 5051744.0000 - val_loss: 39.1888 - val_mae: 39.1888 - val_mse: 1561.3928 - learning_rate: 1.0000e-04\n",
            "Epoch 186/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1304.0642 - mae: 1304.0642 - mse: 4552485.5000 - val_loss: 37.1140 - val_mae: 37.1140 - val_mse: 1409.0350 - learning_rate: 1.0000e-04\n",
            "Epoch 187/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1443.8973 - mae: 1443.8973 - mse: 5348692.0000 - val_loss: 38.8130 - val_mae: 38.8130 - val_mse: 1532.0166 - learning_rate: 1.0000e-04\n",
            "Epoch 188/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1301.5580 - mae: 1301.5580 - mse: 4533069.0000 - val_loss: 36.7597 - val_mae: 36.7597 - val_mse: 1382.8239 - learning_rate: 1.0000e-04\n",
            "Epoch 189/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1439.7584 - mae: 1439.7584 - mse: 5317434.5000 - val_loss: 38.4401 - val_mae: 38.4401 - val_mse: 1503.1653 - learning_rate: 1.0000e-04\n",
            "Epoch 190/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1295.7155 - mae: 1295.7155 - mse: 4495853.5000 - val_loss: 36.3957 - val_mae: 36.3957 - val_mse: 1356.2488 - learning_rate: 1.0000e-04\n",
            "Epoch 191/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1445.2618 - mae: 1445.2618 - mse: 5353874.5000 - val_loss: 38.0841 - val_mae: 38.0841 - val_mse: 1475.8778 - learning_rate: 1.0000e-04\n",
            "Epoch 192/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1298.7529 - mae: 1298.7529 - mse: 4513179.0000 - val_loss: 36.0390 - val_mae: 36.0390 - val_mse: 1330.4575 - learning_rate: 1.0000e-04\n",
            "Epoch 193/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1447.3287 - mae: 1447.3287 - mse: 5365975.5000 - val_loss: 37.7300 - val_mae: 37.7300 - val_mse: 1448.9819 - learning_rate: 1.0000e-04\n",
            "Epoch 194/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1301.2329 - mae: 1301.2329 - mse: 4527198.5000 - val_loss: 35.6736 - val_mae: 35.6736 - val_mse: 1304.3690 - learning_rate: 1.0000e-04\n",
            "Epoch 195/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1458.3585 - mae: 1458.3585 - mse: 5439705.5000 - val_loss: 37.3779 - val_mae: 37.3779 - val_mse: 1422.4849 - learning_rate: 1.0000e-04\n",
            "Epoch 196/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1302.4202 - mae: 1302.4202 - mse: 4532194.0000 - val_loss: 35.3160 - val_mae: 35.3160 - val_mse: 1279.0868 - learning_rate: 1.0000e-04\n",
            "Epoch 197/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1466.2114 - mae: 1466.2114 - mse: 5492575.0000 - val_loss: 37.0390 - val_mae: 37.0390 - val_mse: 1397.2031 - learning_rate: 1.0000e-04\n",
            "Epoch 198/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1309.7969 - mae: 1309.7969 - mse: 4575279.0000 - val_loss: 34.9286 - val_mae: 34.9286 - val_mse: 1252.2018 - learning_rate: 1.0000e-04\n",
            "Epoch 199/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1500.8881 - mae: 1500.8881 - mse: 5736135.5000 - val_loss: 36.7239 - val_mae: 36.7239 - val_mse: 1373.8918 - learning_rate: 1.0000e-04\n",
            "Epoch 200/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1333.4103 - mae: 1333.4103 - mse: 4713865.0000 - val_loss: 34.5973 - val_mae: 34.5973 - val_mse: 1229.1733 - learning_rate: 1.0000e-04\n",
            "Epoch 201/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1495.6293 - mae: 1495.6293 - mse: 5692675.0000 - val_loss: 36.3542 - val_mae: 36.3542 - val_mse: 1346.8717 - learning_rate: 1.0000e-04\n",
            "Epoch 202/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1315.7590 - mae: 1315.7590 - mse: 4599574.0000 - val_loss: 34.2494 - val_mae: 34.2494 - val_mse: 1205.3348 - learning_rate: 1.0000e-04\n",
            "Epoch 203/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1504.2104 - mae: 1504.2104 - mse: 5752215.0000 - val_loss: 36.0526 - val_mae: 36.0526 - val_mse: 1324.9674 - learning_rate: 1.0000e-04\n",
            "Epoch 204/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1347.3741 - mae: 1347.3741 - mse: 4791398.0000 - val_loss: 33.8735 - val_mae: 33.8735 - val_mse: 1180.0708 - learning_rate: 1.0000e-04\n",
            "Epoch 205/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1544.0322 - mae: 1544.0322 - mse: 6030387.0000 - val_loss: 35.6741 - val_mae: 35.6741 - val_mse: 1297.8870 - learning_rate: 1.0000e-04\n",
            "Epoch 206/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1317.8219 - mae: 1317.8219 - mse: 4596655.5000 - val_loss: 33.6253 - val_mae: 33.6253 - val_mse: 1162.9469 - learning_rate: 1.0000e-04\n",
            "Epoch 207/500\n",
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1727.4078 - mae: 1727.4078 - mse: 6634422.5000\n",
            "Epoch 207: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1477.3994 - mae: 1477.3994 - mse: 5559042.0000 - val_loss: 35.3767 - val_mae: 35.3767 - val_mse: 1276.6760 - learning_rate: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79201d656b70>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "n_beats_pred=nbeats.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXQofN7xb1ms",
        "outputId": "6eb23b81-cdca-41af-e02a-2f91a6512289"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(n_beats_pred,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51gQchVkK7E",
        "outputId": "6d16e3b1-6037-4ff7-c763-faf555ad5f0a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1111,), dtype=float32, numpy=\n",
              "array([98.269485 , 97.44167  , 95.42622  , ...,  1.5294461,  1.5301267,\n",
              "        1.5273975], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the results\n",
        "def evaluate_preds(y_true, y_pred):\n",
        "  #y_true=tf.cast(y_true, dtype=tf.float32)\n",
        "  #y_pred=tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "  mae=tf.keras.metrics.MeanAbsoluteError()(y_true, y_pred)\n",
        "  mse=tf.keras.metrics.MeanSquaredError()(y_true, y_pred)\n",
        "  rmse=np.sqrt(mse)\n",
        "  mape=tf.keras.metrics.MeanAbsolutePercentageError()(y_true, y_pred)\n",
        "\n",
        "  return {\"mae\": float(mae),\n",
        "          \"mse\":float(mse),\n",
        "          \"rmse\":float(rmse),\n",
        "          \"mape\":float(mape)}"
      ],
      "metadata": {
        "id": "ia_BPUP_cD-0"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_beats_evaluation=evaluate_preds(y_test, tf.squeeze(n_beats_pred))\n",
        "n_beats_evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO5PNoSVddzY",
        "outputId": "a8d47bd9-36e9-4a4b-eaed-b6fb4cdee1bc"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 2.2790067195892334,\n",
              " 'mse': 44.00614547729492,\n",
              " 'rmse': 6.6337127685546875,\n",
              " 'mape': 260.18157958984375}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Ensemble"
      ],
      "metadata": {
        "id": "uVhQPsrCnsRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_model(horizon=HORIZON,\n",
        "                   train_data=train_data,\n",
        "                   num_iter=5,\n",
        "                   test_data=test_data,\n",
        "                   num_epochs=1000,\n",
        "                   loss_fns=[\"mae\",\"mse\"]):\n",
        "  ensemble_models=[]\n",
        "  for i in range(num_iter):\n",
        "    for loss_fn in loss_fns:\n",
        "      model = tf.keras.Sequential([\n",
        "          layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
        "          layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
        "          layers.Dense(horizon)\n",
        "      ])\n",
        "      model.compile(loss=loss_fn,\n",
        "                             optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                             metrics=[\"mae\", \"mse\"])\n",
        "      model.fit(train_data,\n",
        "                         epochs=num_epochs,\n",
        "                         validation_data=test_data,\n",
        "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
        "                                    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])\n",
        "      ensemble_models.append(model)\n",
        "  return ensemble_models"
      ],
      "metadata": {
        "id": "HAy0EvRDnzh-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_models_bitcoin=ensemble_model(train_data=train_data,\n",
        "                                       num_iter=5,\n",
        "                                       test_data=test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwty05j7aGY2",
        "outputId": "764c30d5-d805-4b5e-94ab-d9d661a8c92e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.3232 - mae: 701.3232 - mse: 1570161.6250 - val_loss: 0.9793 - val_mae: 0.9793 - val_mse: 17.4168 - learning_rate: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 698.8194 - mae: 698.8194 - mse: 1582550.1250 - val_loss: 0.9698 - val_mae: 0.9698 - val_mse: 17.3020 - learning_rate: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 698.6754 - mae: 698.6754 - mse: 1565411.8750 - val_loss: 0.9811 - val_mae: 0.9811 - val_mse: 17.4577 - learning_rate: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 699.8808 - mae: 699.8808 - mse: 1587069.8750 - val_loss: 0.9699 - val_mae: 0.9699 - val_mse: 17.3253 - learning_rate: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 700.8392 - mae: 700.8392 - mse: 1569134.7500 - val_loss: 0.9810 - val_mae: 0.9810 - val_mse: 17.4450 - learning_rate: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 701.1599 - mae: 701.1599 - mse: 1592046.8750 - val_loss: 0.9677 - val_mae: 0.9677 - val_mse: 17.2317 - learning_rate: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 700.8041 - mae: 700.8041 - mse: 1568833.1250 - val_loss: 0.9799 - val_mae: 0.9799 - val_mse: 17.3655 - learning_rate: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 701.3210 - mae: 701.3210 - mse: 1593088.2500 - val_loss: 0.9670 - val_mae: 0.9670 - val_mse: 17.1945 - learning_rate: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.2272 - mae: 701.2272 - mse: 1569280.2500 - val_loss: 0.9793 - val_mae: 0.9793 - val_mse: 17.3751 - learning_rate: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 700.4823 - mae: 700.4823 - mse: 1590759.7500 - val_loss: 0.9666 - val_mae: 0.9666 - val_mse: 17.2324 - learning_rate: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 700.6897 - mae: 700.6897 - mse: 1567996.2500 - val_loss: 0.9785 - val_mae: 0.9785 - val_mse: 17.4161 - learning_rate: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 698.8385 - mae: 698.8385 - mse: 1585721.0000 - val_loss: 0.9664 - val_mae: 0.9664 - val_mse: 17.2826 - learning_rate: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 698.5398 - mae: 698.5398 - mse: 1563866.2500 - val_loss: 0.9786 - val_mae: 0.9786 - val_mse: 17.4453 - learning_rate: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 697.6429 - mae: 697.6429 - mse: 1582292.8750 - val_loss: 0.9669 - val_mae: 0.9669 - val_mse: 17.3072 - learning_rate: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 697.6661 - mae: 697.6661 - mse: 1562179.7500 - val_loss: 0.9785 - val_mae: 0.9785 - val_mse: 17.4454 - learning_rate: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 697.6237 - mae: 697.6237 - mse: 1582866.6250 - val_loss: 0.9656 - val_mae: 0.9656 - val_mse: 17.2858 - learning_rate: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 699.9137 - mae: 699.9137 - mse: 1565905.2500 - val_loss: 0.9810 - val_mae: 0.9810 - val_mse: 17.4780 - learning_rate: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.3515 - mae: 701.3515 - mse: 1595933.2500 - val_loss: 0.9653 - val_mae: 0.9653 - val_mse: 17.2846 - learning_rate: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 702.2473 - mae: 702.2473 - mse: 1569980.2500 - val_loss: 0.9799 - val_mae: 0.9799 - val_mse: 17.4624 - learning_rate: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 700.7225 - mae: 700.7225 - mse: 1594179.5000 - val_loss: 0.9645 - val_mae: 0.9645 - val_mse: 17.2714 - learning_rate: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 701.1793 - mae: 701.1793 - mse: 1567455.6250 - val_loss: 0.9792 - val_mae: 0.9792 - val_mse: 17.4593 - learning_rate: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 699.7366 - mae: 699.7366 - mse: 1591241.1250 - val_loss: 0.9645 - val_mae: 0.9645 - val_mse: 17.2771 - learning_rate: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 700.5005 - mae: 700.5005 - mse: 1565792.8750 - val_loss: 0.9790 - val_mae: 0.9790 - val_mse: 17.4598 - learning_rate: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 699.5826 - mae: 699.5826 - mse: 1591081.8750 - val_loss: 0.9642 - val_mae: 0.9642 - val_mse: 17.2733 - learning_rate: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 700.7515 - mae: 700.7515 - mse: 1565991.7500 - val_loss: 0.9788 - val_mae: 0.9788 - val_mse: 17.4579 - learning_rate: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 699.5355 - mae: 699.5355 - mse: 1591258.0000 - val_loss: 0.9643 - val_mae: 0.9643 - val_mse: 17.2804 - learning_rate: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 701.3190 - mae: 701.3190 - mse: 1566839.3750 - val_loss: 0.9798 - val_mae: 0.9798 - val_mse: 17.4777 - learning_rate: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 700.8962 - mae: 700.8962 - mse: 1595855.8750 - val_loss: 0.9634 - val_mae: 0.9634 - val_mse: 17.2461 - learning_rate: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 704.1421 - mae: 704.1421 - mse: 1572392.0000 - val_loss: 0.9783 - val_mae: 0.9783 - val_mse: 17.4305 - learning_rate: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 701.2658 - mae: 701.2658 - mse: 1597062.0000 - val_loss: 0.9630 - val_mae: 0.9630 - val_mse: 17.2321 - learning_rate: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 701.9761 - mae: 701.9761 - mse: 1567543.2500 - val_loss: 0.9768 - val_mae: 0.9768 - val_mse: 17.4221 - learning_rate: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 698.7761 - mae: 698.7761 - mse: 1589008.6250 - val_loss: 0.9632 - val_mae: 0.9632 - val_mse: 17.2609 - learning_rate: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 697.8015 - mae: 697.8015 - mse: 1559211.7500 - val_loss: 0.9764 - val_mae: 0.9764 - val_mse: 17.4332 - learning_rate: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 697.4255 - mae: 697.4255 - mse: 1584561.1250 - val_loss: 0.9635 - val_mae: 0.9635 - val_mse: 17.2750 - learning_rate: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 697.1923 - mae: 697.1923 - mse: 1557951.0000 - val_loss: 0.9765 - val_mae: 0.9765 - val_mse: 17.4388 - learning_rate: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 697.2614 - mae: 697.2614 - mse: 1584157.1250 - val_loss: 0.9631 - val_mae: 0.9631 - val_mse: 17.2649 - learning_rate: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 697.6667 - mae: 697.6667 - mse: 1558627.5000 - val_loss: 0.9761 - val_mae: 0.9761 - val_mse: 17.4269 - learning_rate: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 697.3222 - mae: 697.3222 - mse: 1584459.5000 - val_loss: 0.9632 - val_mae: 0.9632 - val_mse: 17.2714 - learning_rate: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 696.8351 - mae: 696.8351 - mse: 1556974.0000 - val_loss: 0.9763 - val_mae: 0.9763 - val_mse: 17.4440 - learning_rate: 1.0000e-04\n",
            "Epoch 367/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 696.4280 - mae: 696.4280 - mse: 1581393.2500 - val_loss: 0.9633 - val_mae: 0.9633 - val_mse: 17.2712 - learning_rate: 1.0000e-04\n",
            "Epoch 368/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 696.0602 - mae: 696.0602 - mse: 1555445.5000 - val_loss: 0.9752 - val_mae: 0.9752 - val_mse: 17.4136 - learning_rate: 1.0000e-04\n",
            "Epoch 369/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 696.0278 - mae: 696.0278 - mse: 1580023.8750 - val_loss: 0.9632 - val_mae: 0.9632 - val_mse: 17.2665 - learning_rate: 1.0000e-04\n",
            "Epoch 370/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 695.5002 - mae: 695.5002 - mse: 1554353.6250 - val_loss: 0.9760 - val_mae: 0.9760 - val_mse: 17.4330 - learning_rate: 1.0000e-04\n",
            "Epoch 371/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 696.0536 - mae: 696.0536 - mse: 1580267.2500 - val_loss: 0.9638 - val_mae: 0.9638 - val_mse: 17.2792 - learning_rate: 1.0000e-04\n",
            "Epoch 372/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 696.7672 - mae: 696.7672 - mse: 1556454.1250 - val_loss: 0.9770 - val_mae: 0.9770 - val_mse: 17.4368 - learning_rate: 1.0000e-04\n",
            "Epoch 373/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 697.9365 - mae: 697.9365 - mse: 1586833.0000 - val_loss: 0.9633 - val_mae: 0.9633 - val_mse: 17.2516 - learning_rate: 1.0000e-04\n",
            "Epoch 374/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.2301 - mae: 701.2301 - mse: 1564934.0000 - val_loss: 0.9793 - val_mae: 0.9793 - val_mse: 17.4679 - learning_rate: 1.0000e-04\n",
            "Epoch 375/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.6524 - mae: 701.6524 - mse: 1598989.2500 - val_loss: 0.9634 - val_mae: 0.9634 - val_mse: 17.2373 - learning_rate: 1.0000e-04\n",
            "Epoch 376/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 704.6193 - mae: 704.6193 - mse: 1572165.0000 - val_loss: 0.9766 - val_mae: 0.9766 - val_mse: 17.4173 - learning_rate: 1.0000e-04\n",
            "Epoch 377/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 698.9310 - mae: 698.9310 - mse: 1590237.2500 - val_loss: 0.9627 - val_mae: 0.9627 - val_mse: 17.2417 - learning_rate: 1.0000e-04\n",
            "Epoch 378/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 698.1450 - mae: 698.1450 - mse: 1558670.5000 - val_loss: 0.9749 - val_mae: 0.9749 - val_mse: 17.4116 - learning_rate: 1.0000e-04\n",
            "Epoch 379/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 695.6738 - mae: 695.6738 - mse: 1579183.7500 - val_loss: 0.9632 - val_mae: 0.9632 - val_mse: 17.2662 - learning_rate: 1.0000e-04\n",
            "Epoch 380/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 695.0907 - mae: 695.0907 - mse: 1552943.3750 - val_loss: 0.9753 - val_mae: 0.9753 - val_mse: 17.4117 - learning_rate: 1.0000e-04\n",
            "Epoch 381/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 696.3754 - mae: 696.3754 - mse: 1581855.0000 - val_loss: 0.9628 - val_mae: 0.9628 - val_mse: 17.2489 - learning_rate: 1.0000e-04\n",
            "Epoch 382/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 697.4894 - mae: 697.4894 - mse: 1557133.0000 - val_loss: 0.9760 - val_mae: 0.9760 - val_mse: 17.4251 - learning_rate: 1.0000e-04\n",
            "Epoch 383/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 696.9359 - mae: 696.9359 - mse: 1583905.8750 - val_loss: 0.9633 - val_mae: 0.9633 - val_mse: 17.2559 - learning_rate: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 699.5106 - mae: 699.5106 - mse: 1560937.1250 - val_loss: 0.9780 - val_mae: 0.9780 - val_mse: 17.4519 - learning_rate: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 699.9000 - mae: 699.9000 - mse: 1593873.2500 - val_loss: 0.9642 - val_mae: 0.9642 - val_mse: 17.2465 - learning_rate: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 705.3543 - mae: 705.3543 - mse: 1573524.0000 - val_loss: 0.9775 - val_mae: 0.9775 - val_mse: 17.4463 - learning_rate: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 699.2516 - mae: 699.2516 - mse: 1591827.8750 - val_loss: 0.9640 - val_mae: 0.9640 - val_mse: 17.2704 - learning_rate: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 700.4493 - mae: 700.4493 - mse: 1562625.6250 - val_loss: 0.9779 - val_mae: 0.9779 - val_mse: 17.4643 - learning_rate: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 699.0648 - mae: 699.0648 - mse: 1591368.5000 - val_loss: 0.9632 - val_mae: 0.9632 - val_mse: 17.2377 - learning_rate: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 701.3203 - mae: 701.3203 - mse: 1564329.6250 - val_loss: 0.9765 - val_mae: 0.9765 - val_mse: 17.4126 - learning_rate: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 699.2713 - mae: 699.2713 - mse: 1592183.7500 - val_loss: 0.9631 - val_mae: 0.9631 - val_mse: 17.2198 - learning_rate: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 703.1062 - mae: 703.1062 - mse: 1568175.1250 - val_loss: 0.9765 - val_mae: 0.9765 - val_mse: 17.4180 - learning_rate: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 698.7984 - mae: 698.7984 - mse: 1590722.5000 - val_loss: 0.9635 - val_mae: 0.9635 - val_mse: 17.2499 - learning_rate: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 699.3904 - mae: 699.3904 - mse: 1560320.7500 - val_loss: 0.9773 - val_mae: 0.9773 - val_mse: 17.4453 - learning_rate: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 698.7243 - mae: 698.7243 - mse: 1590705.6250 - val_loss: 0.9639 - val_mae: 0.9639 - val_mse: 17.2394 - learning_rate: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 702.3631 - mae: 702.3631 - mse: 1566493.1250 - val_loss: 0.9772 - val_mae: 0.9772 - val_mse: 17.4316 - learning_rate: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 699.2899 - mae: 699.2899 - mse: 1592626.1250 - val_loss: 0.9644 - val_mae: 0.9644 - val_mse: 17.2529 - learning_rate: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 701.6722 - mae: 701.6722 - mse: 1564997.2500 - val_loss: 0.9774 - val_mae: 0.9774 - val_mse: 17.4458 - learning_rate: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 698.5649 - mae: 698.5649 - mse: 1590433.5000 - val_loss: 0.9641 - val_mae: 0.9641 - val_mse: 17.2385 - learning_rate: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 701.5510 - mae: 701.5510 - mse: 1564711.1250 - val_loss: 0.9771 - val_mae: 0.9771 - val_mse: 17.4261 - learning_rate: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 698.9708 - mae: 698.9708 - mse: 1591909.2500 - val_loss: 0.9648 - val_mae: 0.9648 - val_mse: 17.2453 - learning_rate: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 702.9675 - mae: 702.9675 - mse: 1567870.6250 - val_loss: 0.9778 - val_mae: 0.9778 - val_mse: 17.4436 - learning_rate: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 699.2570 - mae: 699.2570 - mse: 1593047.0000 - val_loss: 0.9637 - val_mae: 0.9637 - val_mse: 17.2130 - learning_rate: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 702.1754 - mae: 702.1754 - mse: 1566129.2500 - val_loss: 0.9767 - val_mae: 0.9767 - val_mse: 17.3932 - learning_rate: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 699.8057 - mae: 699.8057 - mse: 1595044.6250 - val_loss: 0.9637 - val_mae: 0.9637 - val_mse: 17.2014 - learning_rate: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 703.1320 - mae: 703.1320 - mse: 1568296.2500 - val_loss: 0.9767 - val_mae: 0.9767 - val_mse: 17.4094 - learning_rate: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 698.5625 - mae: 698.5625 - mse: 1591229.6250 - val_loss: 0.9647 - val_mae: 0.9647 - val_mse: 17.2478 - learning_rate: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 700.1087 - mae: 700.1087 - mse: 1561714.5000 - val_loss: 0.9788 - val_mae: 0.9788 - val_mse: 17.4589 - learning_rate: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 700.2413 - mae: 700.2413 - mse: 1596858.1250 - val_loss: 0.9649 - val_mae: 0.9649 - val_mse: 17.2186 - learning_rate: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 704.9797 - mae: 704.9797 - mse: 1572663.1250 - val_loss: 0.9769 - val_mae: 0.9769 - val_mse: 17.4013 - learning_rate: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 699.3270 - mae: 699.3270 - mse: 1593987.7500 - val_loss: 0.9641 - val_mae: 0.9641 - val_mse: 17.2132 - learning_rate: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 701.6069 - mae: 701.6069 - mse: 1564963.2500 - val_loss: 0.9774 - val_mae: 0.9774 - val_mse: 17.4246 - learning_rate: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 698.6347 - mae: 698.6347 - mse: 1591984.2500 - val_loss: 0.9656 - val_mae: 0.9656 - val_mse: 17.2502 - learning_rate: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 702.7680 - mae: 702.7680 - mse: 1567553.7500 - val_loss: 0.9796 - val_mae: 0.9796 - val_mse: 17.4724 - learning_rate: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 700.6594 - mae: 700.6594 - mse: 1598624.3750 - val_loss: 0.9658 - val_mae: 0.9658 - val_mse: 17.2250 - learning_rate: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 706.3362 - mae: 706.3362 - mse: 1575984.0000 - val_loss: 0.9781 - val_mae: 0.9781 - val_mse: 17.4185 - learning_rate: 1.0000e-04\n",
            "Epoch 417/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 700.8168 - mae: 700.8168 - mse: 1599278.6250 - val_loss: 0.9649 - val_mae: 0.9649 - val_mse: 17.2157 - learning_rate: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 703.7332 - mae: 703.7332 - mse: 1569737.3750 - val_loss: 0.9778 - val_mae: 0.9778 - val_mse: 17.4336 - learning_rate: 1.0000e-04\n",
            "Epoch 419/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 699.0211 - mae: 699.0211 - mse: 1593609.0000 - val_loss: 0.9650 - val_mae: 0.9650 - val_mse: 17.2358 - learning_rate: 1.0000e-04\n",
            "Epoch 420/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 701.0716 - mae: 701.0716 - mse: 1563745.0000 - val_loss: 0.9776 - val_mae: 0.9776 - val_mse: 17.4257 - learning_rate: 1.0000e-04\n",
            "Epoch 421/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 699.0545 - mae: 699.0545 - mse: 1593859.6250 - val_loss: 0.9651 - val_mae: 0.9651 - val_mse: 17.2268 - learning_rate: 1.0000e-04\n",
            "Epoch 422/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 702.5486 - mae: 702.5486 - mse: 1567026.7500 - val_loss: 0.9790 - val_mae: 0.9790 - val_mse: 17.4525 - learning_rate: 1.0000e-04\n",
            "Epoch 423/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 700.8169 - mae: 700.8169 - mse: 1599671.7500 - val_loss: 0.9660 - val_mae: 0.9660 - val_mse: 17.2186 - learning_rate: 1.0000e-04\n",
            "Epoch 424/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 706.3264 - mae: 706.3264 - mse: 1575933.7500 - val_loss: 0.9795 - val_mae: 0.9795 - val_mse: 17.4365 - learning_rate: 1.0000e-04\n",
            "Epoch 425/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 703.6860 - mae: 703.6860 - mse: 1608740.5000 - val_loss: 0.9674 - val_mae: 0.9674 - val_mse: 17.2150 - learning_rate: 1.0000e-04\n",
            "Epoch 426/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 711.6251 - mae: 711.6251 - mse: 1589097.7500 - val_loss: 0.9803 - val_mae: 0.9803 - val_mse: 17.4724 - learning_rate: 1.0000e-04\n",
            "Epoch 427/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 702.9203 - mae: 702.9203 - mse: 1606301.6250 - val_loss: 0.9663 - val_mae: 0.9663 - val_mse: 17.2273 - learning_rate: 1.0000e-04\n",
            "Epoch 428/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 706.6430 - mae: 706.6430 - mse: 1576546.7500 - val_loss: 0.9799 - val_mae: 0.9799 - val_mse: 17.4498 - learning_rate: 1.0000e-04\n",
            "Epoch 429/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 703.1771 - mae: 703.1771 - mse: 1607193.7500 - val_loss: 0.9676 - val_mae: 0.9676 - val_mse: 17.2240 - learning_rate: 1.0000e-04\n",
            "Epoch 430/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 710.7790 - mae: 710.7790 - mse: 1586877.7500 - val_loss: 0.9800 - val_mae: 0.9800 - val_mse: 17.4594 - learning_rate: 1.0000e-04\n",
            "Epoch 431/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 702.7070 - mae: 702.7070 - mse: 1605714.1250 - val_loss: 0.9661 - val_mae: 0.9661 - val_mse: 17.2115 - learning_rate: 1.0000e-04\n",
            "Epoch 432/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 707.1886 - mae: 707.1886 - mse: 1577862.5000 - val_loss: 0.9801 - val_mae: 0.9801 - val_mse: 17.4497 - learning_rate: 1.0000e-04\n",
            "Epoch 433/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 703.3735 - mae: 703.3735 - mse: 1607891.0000 - val_loss: 0.9679 - val_mae: 0.9679 - val_mse: 17.2315 - learning_rate: 1.0000e-04\n",
            "Epoch 434/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 710.9664 - mae: 710.9664 - mse: 1587392.3750 - val_loss: 0.9809 - val_mae: 0.9809 - val_mse: 17.4807 - learning_rate: 1.0000e-04\n",
            "Epoch 435/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 703.2481 - mae: 703.2481 - mse: 1607490.0000 - val_loss: 0.9665 - val_mae: 0.9665 - val_mse: 17.2140 - learning_rate: 1.0000e-04\n",
            "Epoch 436/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 707.8914 - mae: 707.8914 - mse: 1579595.2500 - val_loss: 0.9801 - val_mae: 0.9801 - val_mse: 17.4389 - learning_rate: 1.0000e-04\n",
            "Epoch 437/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 703.9584 - mae: 703.9584 - mse: 1609744.7500 - val_loss: 0.9674 - val_mae: 0.9674 - val_mse: 17.2126 - learning_rate: 1.0000e-04\n",
            "Epoch 438/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 710.6578 - mae: 710.6578 - mse: 1586611.0000 - val_loss: 0.9806 - val_mae: 0.9806 - val_mse: 17.4733 - learning_rate: 1.0000e-04\n",
            "Epoch 439/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 702.6459 - mae: 702.6459 - mse: 1605630.6250 - val_loss: 0.9670 - val_mae: 0.9670 - val_mse: 17.2315 - learning_rate: 1.0000e-04\n",
            "Epoch 440/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 707.0995 - mae: 707.0995 - mse: 1577693.2500 - val_loss: 0.9809 - val_mae: 0.9809 - val_mse: 17.4665 - learning_rate: 1.0000e-04\n",
            "Epoch 441/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 703.2510 - mae: 703.2510 - mse: 1607562.1250 - val_loss: 0.9677 - val_mae: 0.9677 - val_mse: 17.2209 - learning_rate: 1.0000e-04\n",
            "Epoch 442/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 710.1369 - mae: 710.1369 - mse: 1585296.0000 - val_loss: 0.9807 - val_mae: 0.9807 - val_mse: 17.4541 - learning_rate: 1.0000e-04\n",
            "Epoch 443/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 703.2762 - mae: 703.2762 - mse: 1607644.5000 - val_loss: 0.9673 - val_mae: 0.9673 - val_mse: 17.2243 - learning_rate: 1.0000e-04\n",
            "Epoch 444/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 708.2890 - mae: 708.2890 - mse: 1580657.3750 - val_loss: 0.9811 - val_mae: 0.9811 - val_mse: 17.4675 - learning_rate: 1.0000e-04\n",
            "Epoch 445/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 703.3621 - mae: 703.3621 - mse: 1607988.3750 - val_loss: 0.9675 - val_mae: 0.9675 - val_mse: 17.2176 - learning_rate: 1.0000e-04\n",
            "Epoch 446/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 709.3501 - mae: 709.3501 - mse: 1583406.1250 - val_loss: 0.9812 - val_mae: 0.9812 - val_mse: 17.4626 - learning_rate: 1.0000e-04\n",
            "Epoch 447/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 703.4966 - mae: 703.4966 - mse: 1608422.5000 - val_loss: 0.9678 - val_mae: 0.9678 - val_mse: 17.2277 - learning_rate: 1.0000e-04\n",
            "Epoch 448/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 708.7505 - mae: 708.7505 - mse: 1581894.1250 - val_loss: 0.9812 - val_mae: 0.9812 - val_mse: 17.4606 - learning_rate: 1.0000e-04\n",
            "Epoch 449/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 703.3110 - mae: 703.3110 - mse: 1607820.7500 - val_loss: 0.9678 - val_mae: 0.9678 - val_mse: 17.2280 - learning_rate: 1.0000e-04\n",
            "Epoch 450/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 708.7810 - mae: 708.7810 - mse: 1582033.5000 - val_loss: 0.9817 - val_mae: 0.9817 - val_mse: 17.4732 - learning_rate: 1.0000e-04\n",
            "Epoch 451/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 703.4860 - mae: 703.4860 - mse: 1608407.5000 - val_loss: 0.9683 - val_mae: 0.9683 - val_mse: 17.2450 - learning_rate: 1.0000e-04\n",
            "Epoch 452/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 708.6470 - mae: 708.6470 - mse: 1581767.6250 - val_loss: 0.9825 - val_mae: 0.9825 - val_mse: 17.4980 - learning_rate: 1.0000e-04\n",
            "Epoch 453/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 703.6375 - mae: 703.6375 - mse: 1608952.2500 - val_loss: 0.9684 - val_mae: 0.9684 - val_mse: 17.2254 - learning_rate: 1.0000e-04\n",
            "Epoch 454/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 710.6420 - mae: 710.6420 - mse: 1586941.5000 - val_loss: 0.9821 - val_mae: 0.9821 - val_mse: 17.4625 - learning_rate: 1.0000e-04\n",
            "Epoch 455/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 705.1093 - mae: 705.1093 - mse: 1613627.0000 - val_loss: 0.9685 - val_mae: 0.9685 - val_mse: 17.2296 - learning_rate: 1.0000e-04\n",
            "Epoch 456/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 710.2288 - mae: 710.2288 - mse: 1585969.8750 - val_loss: 0.9832 - val_mae: 0.9832 - val_mse: 17.5036 - learning_rate: 1.0000e-04\n",
            "Epoch 457/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 704.4920 - mae: 704.4920 - mse: 1611639.5000 - val_loss: 0.9690 - val_mae: 0.9690 - val_mse: 17.2446 - learning_rate: 1.0000e-04\n",
            "Epoch 458/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 709.9513 - mae: 709.9513 - mse: 1585182.1250 - val_loss: 0.9828 - val_mae: 0.9828 - val_mse: 17.4903 - learning_rate: 1.0000e-04\n",
            "Epoch 459/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 703.5503 - mae: 703.5503 - mse: 1608625.1250 - val_loss: 0.9688 - val_mae: 0.9688 - val_mse: 17.2403 - learning_rate: 1.0000e-04\n",
            "Epoch 460/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 708.9134 - mae: 708.9134 - mse: 1582605.7500 - val_loss: 0.9834 - val_mae: 0.9834 - val_mse: 17.5001 - learning_rate: 1.0000e-04\n",
            "Epoch 461/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 704.0311 - mae: 704.0311 - mse: 1610258.5000 - val_loss: 0.9688 - val_mae: 0.9688 - val_mse: 17.2167 - learning_rate: 1.0000e-04\n",
            "Epoch 462/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 710.5327 - mae: 710.5327 - mse: 1586861.8750 - val_loss: 0.9832 - val_mae: 0.9832 - val_mse: 17.4525 - learning_rate: 1.0000e-04\n",
            "Epoch 463/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 706.4821 - mae: 706.4821 - mse: 1618051.7500 - val_loss: 0.9699 - val_mae: 0.9699 - val_mse: 17.2012 - learning_rate: 1.0000e-04\n",
            "Epoch 464/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 715.3185 - mae: 715.3185 - mse: 1599365.2500 - val_loss: 0.9873 - val_mae: 0.9873 - val_mse: 17.5184 - learning_rate: 1.0000e-04\n",
            "Epoch 465/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 712.2217 - mae: 712.2217 - mse: 1636199.5000 - val_loss: 0.9724 - val_mae: 0.9724 - val_mse: 17.2330 - learning_rate: 1.0000e-04\n",
            "Epoch 466/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 719.2417 - mae: 719.2417 - mse: 1609941.2500 - val_loss: 0.9885 - val_mae: 0.9885 - val_mse: 17.5381 - learning_rate: 1.0000e-04\n",
            "Epoch 467/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 713.4511 - mae: 713.4511 - mse: 1639962.3750 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.2016 - learning_rate: 1.0000e-04\n",
            "Epoch 468/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 718.5488 - mae: 718.5488 - mse: 1607985.0000 - val_loss: 0.9867 - val_mae: 0.9867 - val_mse: 17.4846 - learning_rate: 1.0000e-04\n",
            "Epoch 469/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 711.4417 - mae: 711.4417 - mse: 1633415.5000 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.2094 - learning_rate: 1.0000e-04\n",
            "Epoch 470/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 715.1518 - mae: 715.1518 - mse: 1598898.6250 - val_loss: 0.9876 - val_mae: 0.9876 - val_mse: 17.5300 - learning_rate: 1.0000e-04\n",
            "Epoch 471/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 710.2969 - mae: 710.2969 - mse: 1629799.0000 - val_loss: 0.9713 - val_mae: 0.9713 - val_mse: 17.2144 - learning_rate: 1.0000e-04\n",
            "Epoch 472/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 716.7808 - mae: 716.7808 - mse: 1603365.1250 - val_loss: 0.9877 - val_mae: 0.9877 - val_mse: 17.5002 - learning_rate: 1.0000e-04\n",
            "Epoch 473/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 712.4272 - mae: 712.4272 - mse: 1636737.0000 - val_loss: 0.9727 - val_mae: 0.9727 - val_mse: 17.2165 - learning_rate: 1.0000e-04\n",
            "Epoch 474/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 721.0902 - mae: 721.0902 - mse: 1615087.7500 - val_loss: 0.9902 - val_mae: 0.9902 - val_mse: 17.5581 - learning_rate: 1.0000e-04\n",
            "Epoch 475/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 715.1768 - mae: 715.1768 - mse: 1645309.7500 - val_loss: 0.9725 - val_mae: 0.9725 - val_mse: 17.2149 - learning_rate: 1.0000e-04\n",
            "Epoch 476/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 720.7691 - mae: 720.7691 - mse: 1614119.1250 - val_loss: 0.9881 - val_mae: 0.9881 - val_mse: 17.5015 - learning_rate: 1.0000e-04\n",
            "Epoch 477/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1083.8533 - mae: 1083.8533 - mse: 2726661.0000\n",
            "Epoch 477: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 712.6659 - mae: 712.6659 - mse: 1637264.1250 - val_loss: 0.9720 - val_mae: 0.9720 - val_mse: 17.2146 - learning_rate: 1.0000e-04\n",
            "Epoch 478/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 722.3817 - mae: 722.3817 - mse: 1616604.5000 - val_loss: 0.9685 - val_mae: 0.9685 - val_mse: 17.2266 - learning_rate: 1.0000e-05\n",
            "Epoch 479/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 707.4211 - mae: 707.4211 - mse: 1578847.2500 - val_loss: 0.9665 - val_mae: 0.9665 - val_mse: 17.2686 - learning_rate: 1.0000e-05\n",
            "Epoch 480/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 689.4922 - mae: 689.4922 - mse: 1540740.5000 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3302 - learning_rate: 1.0000e-05\n",
            "Epoch 481/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.3666 - mae: 685.3666 - mse: 1540014.1250 - val_loss: 0.9737 - val_mae: 0.9737 - val_mse: 17.3749 - learning_rate: 1.0000e-05\n",
            "Epoch 482/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 687.5883 - mae: 687.5883 - mse: 1552280.3750 - val_loss: 0.9744 - val_mae: 0.9744 - val_mse: 17.3855 - learning_rate: 1.0000e-05\n",
            "Epoch 483/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 687.9810 - mae: 687.9810 - mse: 1554445.2500 - val_loss: 0.9728 - val_mae: 0.9728 - val_mse: 17.3715 - learning_rate: 1.0000e-05\n",
            "Epoch 484/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 686.4607 - mae: 686.4607 - mse: 1547421.2500 - val_loss: 0.9709 - val_mae: 0.9709 - val_mse: 17.3495 - learning_rate: 1.0000e-05\n",
            "Epoch 485/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.2975 - mae: 685.2975 - mse: 1540484.5000 - val_loss: 0.9696 - val_mae: 0.9696 - val_mse: 17.3323 - learning_rate: 1.0000e-05\n",
            "Epoch 486/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.2662 - mae: 685.2662 - mse: 1537547.3750 - val_loss: 0.9690 - val_mae: 0.9690 - val_mse: 17.3242 - learning_rate: 1.0000e-05\n",
            "Epoch 487/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 685.5081 - mae: 685.5081 - mse: 1536953.2500 - val_loss: 0.9690 - val_mae: 0.9690 - val_mse: 17.3238 - learning_rate: 1.0000e-05\n",
            "Epoch 488/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.4834 - mae: 685.4834 - mse: 1536972.5000 - val_loss: 0.9694 - val_mae: 0.9694 - val_mse: 17.3297 - learning_rate: 1.0000e-05\n",
            "Epoch 489/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 685.3070 - mae: 685.3070 - mse: 1537349.6250 - val_loss: 0.9699 - val_mae: 0.9699 - val_mse: 17.3389 - learning_rate: 1.0000e-05\n",
            "Epoch 490/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.2065 - mae: 685.2065 - mse: 1538126.7500 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3452 - learning_rate: 1.0000e-05\n",
            "Epoch 491/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1882 - mae: 685.1882 - mse: 1538843.7500 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3469 - learning_rate: 1.0000e-05\n",
            "Epoch 492/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1924 - mae: 685.1924 - mse: 1539118.6250 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3455 - learning_rate: 1.0000e-05\n",
            "Epoch 493/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1844 - mae: 685.1844 - mse: 1539029.7500 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3444 - learning_rate: 1.0000e-05\n",
            "Epoch 494/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1748 - mae: 685.1748 - mse: 1538737.2500 - val_loss: 0.9701 - val_mae: 0.9701 - val_mse: 17.3435 - learning_rate: 1.0000e-05\n",
            "Epoch 495/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.1766 - mae: 685.1766 - mse: 1538501.7500 - val_loss: 0.9701 - val_mae: 0.9701 - val_mse: 17.3443 - learning_rate: 1.0000e-05\n",
            "Epoch 496/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.1786 - mae: 685.1786 - mse: 1538388.8750 - val_loss: 0.9701 - val_mae: 0.9701 - val_mse: 17.3452 - learning_rate: 1.0000e-05\n",
            "Epoch 497/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1768 - mae: 685.1768 - mse: 1538390.0000 - val_loss: 0.9701 - val_mae: 0.9701 - val_mse: 17.3455 - learning_rate: 1.0000e-05\n",
            "Epoch 498/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 685.1718 - mae: 685.1718 - mse: 1538465.2500 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3467 - learning_rate: 1.0000e-05\n",
            "Epoch 499/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1667 - mae: 685.1667 - mse: 1538541.5000 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3479 - learning_rate: 1.0000e-05\n",
            "Epoch 500/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1624 - mae: 685.1624 - mse: 1538610.8750 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3479 - learning_rate: 1.0000e-05\n",
            "Epoch 501/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1588 - mae: 685.1588 - mse: 1538667.6250 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3491 - learning_rate: 1.0000e-05\n",
            "Epoch 502/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.1550 - mae: 685.1550 - mse: 1538709.5000 - val_loss: 0.9702 - val_mae: 0.9702 - val_mse: 17.3497 - learning_rate: 1.0000e-05\n",
            "Epoch 503/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1522 - mae: 685.1522 - mse: 1538707.8750 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3510 - learning_rate: 1.0000e-05\n",
            "Epoch 504/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 685.1498 - mae: 685.1498 - mse: 1538678.8750 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3519 - learning_rate: 1.0000e-05\n",
            "Epoch 505/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.1482 - mae: 685.1482 - mse: 1538653.8750 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3516 - learning_rate: 1.0000e-05\n",
            "Epoch 506/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.1452 - mae: 685.1452 - mse: 1538650.2500 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3527 - learning_rate: 1.0000e-05\n",
            "Epoch 507/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.1423 - mae: 685.1423 - mse: 1538663.3750 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3536 - learning_rate: 1.0000e-05\n",
            "Epoch 508/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1387 - mae: 685.1387 - mse: 1538684.1250 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3531 - learning_rate: 1.0000e-05\n",
            "Epoch 509/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.1362 - mae: 685.1362 - mse: 1538670.5000 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3539 - learning_rate: 1.0000e-05\n",
            "Epoch 510/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.1339 - mae: 685.1339 - mse: 1538655.0000 - val_loss: 0.9703 - val_mae: 0.9703 - val_mse: 17.3546 - learning_rate: 1.0000e-05\n",
            "Epoch 511/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.1315 - mae: 685.1315 - mse: 1538661.2500 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3562 - learning_rate: 1.0000e-05\n",
            "Epoch 512/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 685.1278 - mae: 685.1278 - mse: 1538678.6250 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3572 - learning_rate: 1.0000e-05\n",
            "Epoch 513/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 685.1252 - mae: 685.1252 - mse: 1538673.7500 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3570 - learning_rate: 1.0000e-05\n",
            "Epoch 514/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 685.1224 - mae: 685.1224 - mse: 1538661.5000 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3579 - learning_rate: 1.0000e-05\n",
            "Epoch 515/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.1194 - mae: 685.1194 - mse: 1538670.2500 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3587 - learning_rate: 1.0000e-05\n",
            "Epoch 516/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.1165 - mae: 685.1165 - mse: 1538674.3750 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3585 - learning_rate: 1.0000e-05\n",
            "Epoch 517/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 685.1135 - mae: 685.1135 - mse: 1538672.1250 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3595 - learning_rate: 1.0000e-05\n",
            "Epoch 518/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 685.1107 - mae: 685.1107 - mse: 1538668.1250 - val_loss: 0.9704 - val_mae: 0.9704 - val_mse: 17.3600 - learning_rate: 1.0000e-05\n",
            "Epoch 519/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 685.1079 - mae: 685.1079 - mse: 1538660.6250 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3612 - learning_rate: 1.0000e-05\n",
            "Epoch 520/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 685.1054 - mae: 685.1054 - mse: 1538653.7500 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3622 - learning_rate: 1.0000e-05\n",
            "Epoch 521/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 685.1021 - mae: 685.1021 - mse: 1538665.5000 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3621 - learning_rate: 1.0000e-05\n",
            "Epoch 522/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 685.0990 - mae: 685.0990 - mse: 1538672.0000 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3614 - learning_rate: 1.0000e-05\n",
            "Epoch 523/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 685.0966 - mae: 685.0966 - mse: 1538672.2500 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3622 - learning_rate: 1.0000e-05\n",
            "Epoch 524/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 685.0935 - mae: 685.0935 - mse: 1538668.0000 - val_loss: 0.9705 - val_mae: 0.9705 - val_mse: 17.3644 - learning_rate: 1.0000e-05\n",
            "Epoch 525/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 685.0904 - mae: 685.0904 - mse: 1538660.0000 - val_loss: 0.9706 - val_mae: 0.9706 - val_mse: 17.3658 - learning_rate: 1.0000e-05\n",
            "Epoch 526/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 685.0876 - mae: 685.0876 - mse: 1538653.0000 - val_loss: 0.9706 - val_mae: 0.9706 - val_mse: 17.3659 - learning_rate: 1.0000e-05\n",
            "Epoch 527/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 685.0847 - mae: 685.0847 - mse: 1538667.3750 - val_loss: 0.9706 - val_mae: 0.9706 - val_mse: 17.3652 - learning_rate: 1.0000e-05\n",
            "Epoch 528/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 685.0815 - mae: 685.0815 - mse: 1538673.5000 - val_loss: 0.9706 - val_mae: 0.9706 - val_mse: 17.3659 - learning_rate: 1.0000e-05\n",
            "Epoch 529/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 685.0793 - mae: 685.0793 - mse: 1538651.0000 - val_loss: 0.9706 - val_mae: 0.9706 - val_mse: 17.3685 - learning_rate: 1.0000e-05\n",
            "Epoch 530/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 685.0764 - mae: 685.0764 - mse: 1538654.5000 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3700 - learning_rate: 1.0000e-05\n",
            "Epoch 531/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 685.0734 - mae: 685.0734 - mse: 1538655.6250 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3701 - learning_rate: 1.0000e-05\n",
            "Epoch 532/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 685.0706 - mae: 685.0706 - mse: 1538654.3750 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3696 - learning_rate: 1.0000e-05\n",
            "Epoch 533/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 685.0676 - mae: 685.0676 - mse: 1538648.1250 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3702 - learning_rate: 1.0000e-05\n",
            "Epoch 534/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 685.0652 - mae: 685.0652 - mse: 1538642.5000 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3707 - learning_rate: 1.0000e-05\n",
            "Epoch 535/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 685.0627 - mae: 685.0627 - mse: 1538635.3750 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3705 - learning_rate: 1.0000e-05\n",
            "Epoch 536/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 685.0597 - mae: 685.0597 - mse: 1538648.2500 - val_loss: 0.9707 - val_mae: 0.9707 - val_mse: 17.3713 - learning_rate: 1.0000e-05\n",
            "Epoch 537/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 685.0563 - mae: 685.0563 - mse: 1538657.6250 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3737 - learning_rate: 1.0000e-05\n",
            "Epoch 538/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 685.0536 - mae: 685.0536 - mse: 1538660.8750 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3754 - learning_rate: 1.0000e-05\n",
            "Epoch 539/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 685.0505 - mae: 685.0505 - mse: 1538658.1250 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3755 - learning_rate: 1.0000e-05\n",
            "Epoch 540/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 685.0477 - mae: 685.0477 - mse: 1538652.8750 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3749 - learning_rate: 1.0000e-05\n",
            "Epoch 541/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 685.0452 - mae: 685.0452 - mse: 1538648.3750 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3756 - learning_rate: 1.0000e-05\n",
            "Epoch 542/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0421 - mae: 685.0421 - mse: 1538648.2500 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3760 - learning_rate: 1.0000e-05\n",
            "Epoch 543/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0392 - mae: 685.0392 - mse: 1538655.1250 - val_loss: 0.9708 - val_mae: 0.9708 - val_mse: 17.3756 - learning_rate: 1.0000e-05\n",
            "Epoch 544/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0359 - mae: 685.0359 - mse: 1538658.8750 - val_loss: 0.9709 - val_mae: 0.9709 - val_mse: 17.3765 - learning_rate: 1.0000e-05\n",
            "Epoch 545/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.0331 - mae: 685.0331 - mse: 1538646.8750 - val_loss: 0.9709 - val_mae: 0.9709 - val_mse: 17.3790 - learning_rate: 1.0000e-05\n",
            "Epoch 546/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.0303 - mae: 685.0303 - mse: 1538642.3750 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3805 - learning_rate: 1.0000e-05\n",
            "Epoch 547/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 685.0272 - mae: 685.0272 - mse: 1538640.2500 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3804 - learning_rate: 1.0000e-05\n",
            "Epoch 548/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.0239 - mae: 685.0239 - mse: 1538641.2500 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3796 - learning_rate: 1.0000e-05\n",
            "Epoch 549/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.0211 - mae: 685.0211 - mse: 1538639.5000 - val_loss: 0.9709 - val_mae: 0.9709 - val_mse: 17.3786 - learning_rate: 1.0000e-05\n",
            "Epoch 550/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 685.0189 - mae: 685.0189 - mse: 1538635.1250 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3791 - learning_rate: 1.0000e-05\n",
            "Epoch 551/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.0161 - mae: 685.0161 - mse: 1538633.2500 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3815 - learning_rate: 1.0000e-05\n",
            "Epoch 552/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0130 - mae: 685.0130 - mse: 1538634.5000 - val_loss: 0.9711 - val_mae: 0.9711 - val_mse: 17.3829 - learning_rate: 1.0000e-05\n",
            "Epoch 553/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.0096 - mae: 685.0096 - mse: 1538636.5000 - val_loss: 0.9711 - val_mae: 0.9711 - val_mse: 17.3830 - learning_rate: 1.0000e-05\n",
            "Epoch 554/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0067 - mae: 685.0067 - mse: 1538638.1250 - val_loss: 0.9710 - val_mae: 0.9710 - val_mse: 17.3819 - learning_rate: 1.0000e-05\n",
            "Epoch 555/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 685.0051 - mae: 685.0051 - mse: 1538584.7500 - val_loss: 0.9711 - val_mae: 0.9711 - val_mse: 17.3823 - learning_rate: 1.0000e-05\n",
            "Epoch 556/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 685.0033 - mae: 685.0033 - mse: 1538558.2500 - val_loss: 0.9711 - val_mae: 0.9711 - val_mse: 17.3845 - learning_rate: 1.0000e-05\n",
            "Epoch 557/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 685.0004 - mae: 685.0004 - mse: 1538547.2500 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3862 - learning_rate: 1.0000e-05\n",
            "Epoch 558/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9976 - mae: 684.9976 - mse: 1538542.8750 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3862 - learning_rate: 1.0000e-05\n",
            "Epoch 559/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 684.9949 - mae: 684.9949 - mse: 1538541.2500 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3857 - learning_rate: 1.0000e-05\n",
            "Epoch 560/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 684.9924 - mae: 684.9924 - mse: 1538538.1250 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3864 - learning_rate: 1.0000e-05\n",
            "Epoch 561/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9900 - mae: 684.9900 - mse: 1538538.3750 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3868 - learning_rate: 1.0000e-05\n",
            "Epoch 562/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9868 - mae: 684.9868 - mse: 1538544.0000 - val_loss: 0.9713 - val_mae: 0.9713 - val_mse: 17.3882 - learning_rate: 1.0000e-05\n",
            "Epoch 563/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 684.9835 - mae: 684.9835 - mse: 1538547.5000 - val_loss: 0.9713 - val_mae: 0.9713 - val_mse: 17.3893 - learning_rate: 1.0000e-05\n",
            "Epoch 564/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 684.9806 - mae: 684.9806 - mse: 1538547.0000 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3872 - learning_rate: 1.0000e-05\n",
            "Epoch 565/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 684.9785 - mae: 684.9785 - mse: 1538537.8750 - val_loss: 0.9712 - val_mae: 0.9712 - val_mse: 17.3868 - learning_rate: 1.0000e-05\n",
            "Epoch 566/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 684.9758 - mae: 684.9758 - mse: 1538535.3750 - val_loss: 0.9713 - val_mae: 0.9713 - val_mse: 17.3885 - learning_rate: 1.0000e-05\n",
            "Epoch 567/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 684.9725 - mae: 684.9725 - mse: 1538538.8750 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3912 - learning_rate: 1.0000e-05\n",
            "Epoch 568/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 684.9697 - mae: 684.9697 - mse: 1538544.8750 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3913 - learning_rate: 1.0000e-05\n",
            "Epoch 569/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 684.9671 - mae: 684.9671 - mse: 1538544.0000 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3922 - learning_rate: 1.0000e-05\n",
            "Epoch 570/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 684.9644 - mae: 684.9644 - mse: 1538544.7500 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3908 - learning_rate: 1.0000e-05\n",
            "Epoch 571/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 684.9621 - mae: 684.9621 - mse: 1538539.7500 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3908 - learning_rate: 1.0000e-05\n",
            "Epoch 572/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 684.9592 - mae: 684.9592 - mse: 1538530.6250 - val_loss: 0.9714 - val_mae: 0.9714 - val_mse: 17.3928 - learning_rate: 1.0000e-05\n",
            "Epoch 573/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9561 - mae: 684.9561 - mse: 1538525.7500 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 17.3942 - learning_rate: 1.0000e-05\n",
            "Epoch 574/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9534 - mae: 684.9534 - mse: 1538523.2500 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 17.3946 - learning_rate: 1.0000e-05\n",
            "Epoch 575/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9505 - mae: 684.9505 - mse: 1538514.1250 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 17.3945 - learning_rate: 1.0000e-05\n",
            "Epoch 576/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 684.9480 - mae: 684.9480 - mse: 1538501.7500 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 17.3960 - learning_rate: 1.0000e-05\n",
            "Epoch 577/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1021.7721 - mae: 1021.7721 - mse: 2502355.5000\n",
            "Epoch 577: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 684.9453 - mae: 684.9453 - mse: 1538495.3750 - val_loss: 0.9715 - val_mae: 0.9715 - val_mse: 17.3954 - learning_rate: 1.0000e-05\n",
            "Epoch 1/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 396ms/step - loss: 305166624.0000 - mae: 13127.5723 - mse: 305166624.0000 - val_loss: 2583.2954 - val_mae: 24.8116 - val_mse: 2583.2954 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3581127936.0000 - mae: 41382.1953 - mse: 3581127936.0000 - val_loss: 151.8894 - val_mae: 5.2616 - val_mse: 151.8894 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 153227136.0000 - mae: 9447.1045 - mse: 153227136.0000 - val_loss: 993.2924 - val_mae: 15.2501 - val_mse: 993.2924 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1253826304.0000 - mae: 25048.7832 - mse: 1253826304.0000 - val_loss: 131.8521 - val_mae: 4.7335 - val_mse: 131.8521 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 85612576.0000 - mae: 5914.4639 - mse: 85612576.0000 - val_loss: 218.0513 - val_mae: 6.4993 - val_mse: 218.0513 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 283647552.0000 - mae: 12105.2324 - mse: 283647552.0000 - val_loss: 156.1287 - val_mae: 5.2828 - val_mse: 156.1287 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 173709840.0000 - mae: 8960.6045 - mse: 173709840.0000 - val_loss: 71.6954 - val_mae: 2.9654 - val_mse: 71.6954 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 27387208.0000 - mae: 3688.1980 - mse: 27387208.0000 - val_loss: 134.6744 - val_mae: 4.8454 - val_mse: 134.6744 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 100115376.0000 - mae: 6891.3716 - mse: 100115376.0000 - val_loss: 53.2871 - val_mae: 2.0229 - val_mse: 53.2871 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4700908.5000 - mae: 1318.7893 - mse: 4700908.5000 - val_loss: 69.8570 - val_mae: 2.8791 - val_mse: 69.8570 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 40306228.0000 - mae: 4295.4648 - mse: 40306228.0000 - val_loss: 51.7792 - val_mae: 1.9825 - val_mse: 51.7792 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5806349.5000 - mae: 1457.2568 - mse: 5806349.5000 - val_loss: 65.4443 - val_mae: 2.6866 - val_mse: 65.4443 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16882758.0000 - mae: 2681.4229 - mse: 16882758.0000 - val_loss: 52.8845 - val_mae: 2.0945 - val_mse: 52.8845 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5270739.0000 - mae: 1370.2834 - mse: 5270739.0000 - val_loss: 48.7809 - val_mae: 1.9973 - val_mse: 48.7809 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8690776.0000 - mae: 1849.9978 - mse: 8690776.0000 - val_loss: 46.3744 - val_mae: 1.8621 - val_mse: 46.3744 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4007746.5000 - mae: 1190.5284 - mse: 4007746.5000 - val_loss: 48.2774 - val_mae: 2.0527 - val_mse: 48.2774 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6179815.0000 - mae: 1524.1216 - mse: 6179815.0000 - val_loss: 41.8420 - val_mae: 1.7565 - val_mse: 41.8420 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3798432.0000 - mae: 1154.9852 - mse: 3798432.0000 - val_loss: 40.4781 - val_mae: 1.7323 - val_mse: 40.4781 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3884220.5000 - mae: 1170.1392 - mse: 3884220.5000 - val_loss: 40.6923 - val_mae: 1.7697 - val_mse: 40.6923 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3763686.0000 - mae: 1146.8105 - mse: 3763686.0000 - val_loss: 37.4637 - val_mae: 1.6566 - val_mse: 37.4637 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3277032.5000 - mae: 1062.4608 - mse: 3277032.5000 - val_loss: 33.9934 - val_mae: 1.5328 - val_mse: 33.9934 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3088480.2500 - mae: 1030.5850 - mse: 3088480.2500 - val_loss: 33.3789 - val_mae: 1.4912 - val_mse: 33.3789 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2774983.5000 - mae: 971.1065 - mse: 2774983.5000 - val_loss: 30.5912 - val_mae: 1.3846 - val_mse: 30.5912 - learning_rate: 0.0010\n",
            "Epoch 24/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3721954.2500 - mae: 1166.8618 - mse: 3721954.2500 - val_loss: 35.7963 - val_mae: 1.7220 - val_mse: 35.7963 - learning_rate: 0.0010\n",
            "Epoch 25/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5529439.0000 - mae: 1456.7362 - mse: 5529439.0000 - val_loss: 30.8265 - val_mae: 1.4731 - val_mse: 30.8265 - learning_rate: 0.0010\n",
            "Epoch 26/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5789941.0000 - mae: 1497.5391 - mse: 5789941.0000 - val_loss: 33.2840 - val_mae: 1.5484 - val_mse: 33.2840 - learning_rate: 0.0010\n",
            "Epoch 27/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3339140.5000 - mae: 1089.1897 - mse: 3339140.5000 - val_loss: 31.7139 - val_mae: 1.4462 - val_mse: 31.7139 - learning_rate: 0.0010\n",
            "Epoch 28/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2589969.5000 - mae: 934.4911 - mse: 2589969.5000 - val_loss: 30.5665 - val_mae: 1.4022 - val_mse: 30.5665 - learning_rate: 0.0010\n",
            "Epoch 29/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3046245.2500 - mae: 1041.1968 - mse: 3046245.2500 - val_loss: 32.2462 - val_mae: 1.4931 - val_mse: 32.2462 - learning_rate: 0.0010\n",
            "Epoch 30/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2881312.5000 - mae: 994.1556 - mse: 2881312.5000 - val_loss: 30.4067 - val_mae: 1.3913 - val_mse: 30.4067 - learning_rate: 0.0010\n",
            "Epoch 31/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2584784.2500 - mae: 943.1688 - mse: 2584784.2500 - val_loss: 30.3798 - val_mae: 1.3901 - val_mse: 30.3798 - learning_rate: 0.0010\n",
            "Epoch 32/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2484925.7500 - mae: 919.9904 - mse: 2484925.7500 - val_loss: 30.5680 - val_mae: 1.4033 - val_mse: 30.5680 - learning_rate: 0.0010\n",
            "Epoch 33/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2498291.2500 - mae: 919.0845 - mse: 2498291.2500 - val_loss: 29.5703 - val_mae: 1.3563 - val_mse: 29.5703 - learning_rate: 0.0010\n",
            "Epoch 34/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2522103.7500 - mae: 931.9080 - mse: 2522103.7500 - val_loss: 30.0962 - val_mae: 1.3846 - val_mse: 30.0962 - learning_rate: 0.0010\n",
            "Epoch 35/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2476291.2500 - mae: 915.7739 - mse: 2476291.2500 - val_loss: 29.1784 - val_mae: 1.3418 - val_mse: 29.1784 - learning_rate: 0.0010\n",
            "Epoch 36/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2460397.0000 - mae: 919.0631 - mse: 2460397.0000 - val_loss: 29.6231 - val_mae: 1.3623 - val_mse: 29.6231 - learning_rate: 0.0010\n",
            "Epoch 37/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2424444.7500 - mae: 906.3253 - mse: 2424444.7500 - val_loss: 29.0861 - val_mae: 1.3388 - val_mse: 29.0861 - learning_rate: 0.0010\n",
            "Epoch 38/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2422793.2500 - mae: 911.1337 - mse: 2422793.2500 - val_loss: 29.5368 - val_mae: 1.3646 - val_mse: 29.5368 - learning_rate: 0.0010\n",
            "Epoch 39/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2404494.7500 - mae: 902.1825 - mse: 2404494.7500 - val_loss: 28.6517 - val_mae: 1.3265 - val_mse: 28.6517 - learning_rate: 0.0010\n",
            "Epoch 40/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2427795.7500 - mae: 913.7347 - mse: 2427795.7500 - val_loss: 29.3725 - val_mae: 1.3671 - val_mse: 29.3725 - learning_rate: 0.0010\n",
            "Epoch 41/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2440921.2500 - mae: 909.0447 - mse: 2440921.2500 - val_loss: 28.1650 - val_mae: 1.3145 - val_mse: 28.1650 - learning_rate: 0.0010\n",
            "Epoch 42/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2560734.5000 - mae: 945.4662 - mse: 2560734.5000 - val_loss: 29.9402 - val_mae: 1.4213 - val_mse: 29.9402 - learning_rate: 0.0010\n",
            "Epoch 43/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2750415.0000 - mae: 973.6210 - mse: 2750415.0000 - val_loss: 27.7782 - val_mae: 1.3260 - val_mse: 27.7782 - learning_rate: 0.0010\n",
            "Epoch 44/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3382544.0000 - mae: 1115.9436 - mse: 3382544.0000 - val_loss: 32.6103 - val_mae: 1.6298 - val_mse: 32.6103 - learning_rate: 0.0010\n",
            "Epoch 45/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4622125.0000 - mae: 1313.0540 - mse: 4622125.0000 - val_loss: 29.0562 - val_mae: 1.5064 - val_mse: 29.0562 - learning_rate: 0.0010\n",
            "Epoch 46/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7509845.5000 - mae: 1708.4921 - mse: 7509845.5000 - val_loss: 40.5793 - val_mae: 2.1298 - val_mse: 40.5793 - learning_rate: 0.0010\n",
            "Epoch 47/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11769672.0000 - mae: 2188.3447 - mse: 11769672.0000 - val_loss: 34.4051 - val_mae: 1.9178 - val_mse: 34.4051 - learning_rate: 0.0010\n",
            "Epoch 48/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17413490.0000 - mae: 2676.9998 - mse: 17413490.0000 - val_loss: 50.3190 - val_mae: 2.6042 - val_mse: 50.3190 - learning_rate: 0.0010\n",
            "Epoch 49/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20786908.0000 - mae: 2978.3655 - mse: 20786908.0000 - val_loss: 37.4659 - val_mae: 2.0967 - val_mse: 37.4659 - learning_rate: 0.0010\n",
            "Epoch 50/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23009868.0000 - mae: 3106.6721 - mse: 23009868.0000 - val_loss: 51.6058 - val_mae: 2.6470 - val_mse: 51.6058 - learning_rate: 0.0010\n",
            "Epoch 51/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21320784.0000 - mae: 3033.1675 - mse: 21320784.0000 - val_loss: 35.7327 - val_mae: 1.9798 - val_mse: 35.7327 - learning_rate: 0.0010\n",
            "Epoch 52/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 19653928.0000 - mae: 2866.5630 - mse: 19653928.0000 - val_loss: 46.4650 - val_mae: 2.4174 - val_mse: 46.4650 - learning_rate: 0.0010\n",
            "Epoch 53/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 16596563.0000 - mae: 2659.4307 - mse: 16596563.0000 - val_loss: 33.5429 - val_mae: 1.8169 - val_mse: 33.5429 - learning_rate: 0.0010\n",
            "Epoch 54/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 14955044.0000 - mae: 2483.5403 - mse: 14955044.0000 - val_loss: 42.7908 - val_mae: 2.2399 - val_mse: 42.7908 - learning_rate: 0.0010\n",
            "Epoch 55/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 13213143.0000 - mae: 2351.8774 - mse: 13213143.0000 - val_loss: 32.7289 - val_mae: 1.7497 - val_mse: 32.7289 - learning_rate: 0.0010\n",
            "Epoch 56/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 13122357.0000 - mae: 2314.6558 - mse: 13122357.0000 - val_loss: 42.5311 - val_mae: 2.2366 - val_mse: 42.5311 - learning_rate: 0.0010\n",
            "Epoch 57/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13236506.0000 - mae: 2348.3711 - mse: 13236506.0000 - val_loss: 34.0283 - val_mae: 1.8423 - val_mse: 34.0283 - learning_rate: 0.0010\n",
            "Epoch 58/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 15294275.0000 - mae: 2502.8535 - mse: 15294275.0000 - val_loss: 46.9331 - val_mae: 2.4683 - val_mse: 46.9331 - learning_rate: 0.0010\n",
            "Epoch 59/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 18126878.0000 - mae: 2764.7690 - mse: 18126878.0000 - val_loss: 39.6177 - val_mae: 2.1984 - val_mse: 39.6177 - learning_rate: 0.0010\n",
            "Epoch 60/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24435732.0000 - mae: 3184.5381 - mse: 24435732.0000 - val_loss: 61.0201 - val_mae: 3.0782 - val_mse: 61.0201 - learning_rate: 0.0010\n",
            "Epoch 61/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 33493940.0000 - mae: 3789.4766 - mse: 33493940.0000 - val_loss: 55.7465 - val_mae: 2.9634 - val_mse: 55.7465 - learning_rate: 0.0010\n",
            "Epoch 62/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 50363452.0000 - mae: 4613.1582 - mse: 50363452.0000 - val_loss: 97.4797 - val_mae: 4.2423 - val_mse: 97.4797 - learning_rate: 0.0010\n",
            "Epoch 63/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 74789488.0000 - mae: 5695.1045 - mse: 74789488.0000 - val_loss: 98.7266 - val_mae: 4.3305 - val_mse: 98.7266 - learning_rate: 0.0010\n",
            "Epoch 64/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 115114856.0000 - mae: 7032.3750 - mse: 115114856.0000 - val_loss: 174.3356 - val_mae: 6.0107 - val_mse: 174.3356 - learning_rate: 0.0010\n",
            "Epoch 65/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 166912640.0000 - mae: 8553.4443 - mse: 166912640.0000 - val_loss: 178.8694 - val_mae: 6.1807 - val_mse: 178.8694 - learning_rate: 0.0010\n",
            "Epoch 66/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 232062976.0000 - mae: 10075.7236 - mse: 232062976.0000 - val_loss: 264.7448 - val_mae: 7.6069 - val_mse: 264.7448 - learning_rate: 0.0010\n",
            "Epoch 67/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 280362048.0000 - mae: 11187.1309 - mse: 280362048.0000 - val_loss: 218.0687 - val_mae: 6.9033 - val_mse: 218.0687 - learning_rate: 0.0010\n",
            "Epoch 68/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 289190656.0000 - mae: 11384.8320 - mse: 289190656.0000 - val_loss: 223.7654 - val_mae: 6.9239 - val_mse: 223.7654 - learning_rate: 0.0010\n",
            "Epoch 69/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 231689792.0000 - mae: 10290.8320 - mse: 231689792.0000 - val_loss: 116.2366 - val_mae: 4.7551 - val_mse: 116.2366 - learning_rate: 0.0010\n",
            "Epoch 70/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 143974240.0000 - mae: 8084.9775 - mse: 143974240.0000 - val_loss: 88.1418 - val_mae: 3.9220 - val_mse: 88.1418 - learning_rate: 0.0010\n",
            "Epoch 71/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 63759708.0000 - mae: 5419.2363 - mse: 63759708.0000 - val_loss: 37.0997 - val_mae: 1.9734 - val_mse: 37.0997 - learning_rate: 0.0010\n",
            "Epoch 72/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 18840312.0000 - mae: 2864.4961 - mse: 18840312.0000 - val_loss: 33.5375 - val_mae: 1.6035 - val_mse: 33.5375 - learning_rate: 0.0010\n",
            "Epoch 73/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3730763.5000 - mae: 1157.0742 - mse: 3730763.5000 - val_loss: 34.0936 - val_mae: 1.6457 - val_mse: 34.0936 - learning_rate: 0.0010\n",
            "Epoch 74/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3978730.5000 - mae: 1188.0774 - mse: 3978730.5000 - val_loss: 31.6716 - val_mae: 1.5681 - val_mse: 31.6716 - learning_rate: 0.0010\n",
            "Epoch 75/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7152137.0000 - mae: 1663.6525 - mse: 7152137.0000 - val_loss: 38.9977 - val_mae: 1.9635 - val_mse: 38.9977 - learning_rate: 0.0010\n",
            "Epoch 76/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8339184.5000 - mae: 1806.2941 - mse: 8339184.5000 - val_loss: 31.9121 - val_mae: 1.5854 - val_mse: 31.9121 - learning_rate: 0.0010\n",
            "Epoch 77/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7787314.0000 - mae: 1752.0703 - mse: 7787314.0000 - val_loss: 36.4582 - val_mae: 1.8146 - val_mse: 36.4582 - learning_rate: 0.0010\n",
            "Epoch 78/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6397782.0000 - mae: 1561.3600 - mse: 6397782.0000 - val_loss: 30.8201 - val_mae: 1.4810 - val_mse: 30.8201 - learning_rate: 0.0010\n",
            "Epoch 79/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5174098.0000 - mae: 1402.2782 - mse: 5174098.0000 - val_loss: 33.5689 - val_mae: 1.6303 - val_mse: 33.5689 - learning_rate: 0.0010\n",
            "Epoch 80/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4240450.5000 - mae: 1238.0648 - mse: 4240450.5000 - val_loss: 30.3365 - val_mae: 1.4188 - val_mse: 30.3365 - learning_rate: 0.0010\n",
            "Epoch 81/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3684241.0000 - mae: 1159.2433 - mse: 3684241.0000 - val_loss: 32.2633 - val_mae: 1.5323 - val_mse: 32.2633 - learning_rate: 0.0010\n",
            "Epoch 82/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3339078.5000 - mae: 1080.0952 - mse: 3339078.5000 - val_loss: 30.1886 - val_mae: 1.4004 - val_mse: 30.1886 - learning_rate: 0.0010\n",
            "Epoch 83/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3164234.7500 - mae: 1061.2090 - mse: 3164234.7500 - val_loss: 31.8299 - val_mae: 1.4966 - val_mse: 31.8299 - learning_rate: 0.0010\n",
            "Epoch 84/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3067012.5000 - mae: 1030.1425 - mse: 3067012.5000 - val_loss: 30.0313 - val_mae: 1.3899 - val_mse: 30.0313 - learning_rate: 0.0010\n",
            "Epoch 85/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3056832.5000 - mae: 1041.4501 - mse: 3056832.5000 - val_loss: 31.8164 - val_mae: 1.4980 - val_mse: 31.8164 - learning_rate: 0.0010\n",
            "Epoch 86/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3091856.2500 - mae: 1035.8925 - mse: 3091856.2500 - val_loss: 29.7910 - val_mae: 1.3872 - val_mse: 29.7910 - learning_rate: 0.0010\n",
            "Epoch 87/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3233235.5000 - mae: 1079.4531 - mse: 3233235.5000 - val_loss: 32.3199 - val_mae: 1.5421 - val_mse: 32.3199 - learning_rate: 0.0010\n",
            "Epoch 88/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3473337.0000 - mae: 1109.3728 - mse: 3473337.0000 - val_loss: 29.6287 - val_mae: 1.4083 - val_mse: 29.6287 - learning_rate: 0.0010\n",
            "Epoch 89/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3974934.7500 - mae: 1215.7955 - mse: 3974934.7500 - val_loss: 33.8962 - val_mae: 1.6642 - val_mse: 33.8962 - learning_rate: 0.0010\n",
            "Epoch 90/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4843561.0000 - mae: 1339.2361 - mse: 4843561.0000 - val_loss: 30.3423 - val_mae: 1.5342 - val_mse: 30.3423 - learning_rate: 0.0010\n",
            "Epoch 91/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6623950.5000 - mae: 1605.4020 - mse: 6623950.5000 - val_loss: 39.4581 - val_mae: 2.0300 - val_mse: 39.4581 - learning_rate: 0.0010\n",
            "Epoch 92/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9999662.0000 - mae: 2000.7120 - mse: 9999662.0000 - val_loss: 35.8929 - val_mae: 2.0138 - val_mse: 35.8929 - learning_rate: 0.0010\n",
            "Epoch 93/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 17185584.0000 - mae: 2645.9080 - mse: 17185584.0000 - val_loss: 60.6966 - val_mae: 3.0106 - val_mse: 60.6966 - learning_rate: 0.0010\n",
            "Epoch 94/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31680322.0000 - mae: 3652.9426 - mse: 31680322.0000 - val_loss: 64.9996 - val_mae: 3.3429 - val_mse: 64.9996 - learning_rate: 0.0010\n",
            "Epoch 95/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 62921608.0000 - mae: 5137.6353 - mse: 62921608.0000 - val_loss: 141.4079 - val_mae: 5.2710 - val_mse: 141.4079 - learning_rate: 0.0010\n",
            "Epoch 96/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 123533320.0000 - mae: 7276.2134 - mse: 123533320.0000 - val_loss: 187.7329 - val_mae: 6.3898 - val_mse: 187.7329 - learning_rate: 0.0010\n",
            "Epoch 97/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 242839984.0000 - mae: 10194.8066 - mse: 242839984.0000 - val_loss: 395.3810 - val_mae: 9.4251 - val_mse: 395.3810 - learning_rate: 0.0010\n",
            "Epoch 98/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 436590208.0000 - mae: 13787.2227 - mse: 436590208.0000 - val_loss: 488.6774 - val_mae: 10.7382 - val_mse: 488.6774 - learning_rate: 0.0010\n",
            "Epoch 99/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 674960192.0000 - mae: 17261.4434 - mse: 674960192.0000 - val_loss: 643.0649 - val_mae: 12.1846 - val_mse: 643.0649 - learning_rate: 0.0010\n",
            "Epoch 100/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 752581120.0000 - mae: 18506.6055 - mse: 752581120.0000 - val_loss: 367.7753 - val_mae: 9.1985 - val_mse: 367.7753 - learning_rate: 0.0010\n",
            "Epoch 101/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 518909952.0000 - mae: 15571.3301 - mse: 518909952.0000 - val_loss: 164.5415 - val_mae: 5.7414 - val_mse: 164.5415 - learning_rate: 0.0010\n",
            "Epoch 102/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 156452640.0000 - mae: 8727.8477 - mse: 156452640.0000 - val_loss: 32.9261 - val_mae: 1.6012 - val_mse: 32.9261 - learning_rate: 0.0010\n",
            "Epoch 103/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5344394.0000 - mae: 1483.0275 - mse: 5344394.0000 - val_loss: 50.7814 - val_mae: 2.6032 - val_mse: 50.7814 - learning_rate: 0.0010\n",
            "Epoch 104/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 38524044.0000 - mae: 4002.0461 - mse: 38524044.0000 - val_loss: 88.2989 - val_mae: 3.8556 - val_mse: 88.2989 - learning_rate: 0.0010\n",
            "Epoch 105/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 60298448.0000 - mae: 5190.4272 - mse: 60298448.0000 - val_loss: 44.9910 - val_mae: 2.3596 - val_mse: 44.9910 - learning_rate: 0.0010\n",
            "Epoch 106/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30796904.0000 - mae: 3692.5420 - mse: 30796904.0000 - val_loss: 37.7703 - val_mae: 1.8613 - val_mse: 37.7703 - learning_rate: 0.0010\n",
            "Epoch 107/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6022517.0000 - mae: 1516.9783 - mse: 6022517.0000 - val_loss: 36.7505 - val_mae: 1.7968 - val_mse: 36.7505 - learning_rate: 0.0010\n",
            "Epoch 108/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4818856.0000 - mae: 1312.8604 - mse: 4818856.0000 - val_loss: 32.9823 - val_mae: 1.7006 - val_mse: 32.9823 - learning_rate: 0.0010\n",
            "Epoch 109/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8815784.0000 - mae: 1860.3396 - mse: 8815784.0000 - val_loss: 45.4321 - val_mae: 2.1102 - val_mse: 45.4321 - learning_rate: 0.0010\n",
            "Epoch 110/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8931156.0000 - mae: 1886.2529 - mse: 8931156.0000 - val_loss: 32.2136 - val_mae: 1.6431 - val_mse: 32.2136 - learning_rate: 0.0010\n",
            "Epoch 111/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7780516.0000 - mae: 1747.6212 - mse: 7780516.0000 - val_loss: 38.6629 - val_mae: 1.8881 - val_mse: 38.6629 - learning_rate: 0.0010\n",
            "Epoch 112/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6474859.5000 - mae: 1576.1823 - mse: 6474859.5000 - val_loss: 31.0624 - val_mae: 1.6101 - val_mse: 31.0624 - learning_rate: 0.0010\n",
            "Epoch 113/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7457312.5000 - mae: 1706.2729 - mse: 7457312.5000 - val_loss: 37.8658 - val_mae: 1.8585 - val_mse: 37.8658 - learning_rate: 0.0010\n",
            "Epoch 114/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6139946.0000 - mae: 1515.0161 - mse: 6139946.0000 - val_loss: 30.6878 - val_mae: 1.5100 - val_mse: 30.6878 - learning_rate: 0.0010\n",
            "Epoch 115/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3956392.2500 - mae: 1206.9519 - mse: 3956392.2500 - val_loss: 32.0985 - val_mae: 1.5399 - val_mse: 32.0985 - learning_rate: 0.0010\n",
            "Epoch 116/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2937964.0000 - mae: 1009.9788 - mse: 2937964.0000 - val_loss: 32.1824 - val_mae: 1.5345 - val_mse: 32.1824 - learning_rate: 0.0010\n",
            "Epoch 117/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2910516.5000 - mae: 1003.5849 - mse: 2910516.5000 - val_loss: 30.5935 - val_mae: 1.4555 - val_mse: 30.5935 - learning_rate: 0.0010\n",
            "Epoch 118/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2994416.5000 - mae: 1026.6708 - mse: 2994416.5000 - val_loss: 33.2157 - val_mae: 1.5956 - val_mse: 33.2157 - learning_rate: 0.0010\n",
            "Epoch 119/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3667968.0000 - mae: 1141.2473 - mse: 3667968.0000 - val_loss: 30.6352 - val_mae: 1.5643 - val_mse: 30.6352 - learning_rate: 0.0010\n",
            "Epoch 120/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6780492.0000 - mae: 1621.5100 - mse: 6780492.0000 - val_loss: 41.6484 - val_mae: 2.0387 - val_mse: 41.6484 - learning_rate: 0.0010\n",
            "Epoch 121/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9405832.0000 - mae: 1941.2417 - mse: 9405832.0000 - val_loss: 32.5648 - val_mae: 1.7450 - val_mse: 32.5648 - learning_rate: 0.0010\n",
            "Epoch 122/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10669108.0000 - mae: 2082.8003 - mse: 10669108.0000 - val_loss: 41.2086 - val_mae: 2.0113 - val_mse: 41.2086 - learning_rate: 0.0010\n",
            "Epoch 123/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9279703.0000 - mae: 1931.3746 - mse: 9279703.0000 - val_loss: 31.1016 - val_mae: 1.5717 - val_mse: 31.1016 - learning_rate: 0.0010\n",
            "Epoch 124/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6779018.5000 - mae: 1635.0741 - mse: 6779018.5000 - val_loss: 35.5220 - val_mae: 1.6711 - val_mse: 35.5220 - learning_rate: 0.0010\n",
            "Epoch 125/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4596347.0000 - mae: 1299.9824 - mse: 4596347.0000 - val_loss: 30.4667 - val_mae: 1.4175 - val_mse: 30.4667 - learning_rate: 0.0010\n",
            "Epoch 126/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3274144.2500 - mae: 1086.6555 - mse: 3274144.2500 - val_loss: 32.4591 - val_mae: 1.4640 - val_mse: 32.4591 - learning_rate: 0.0010\n",
            "Epoch 127/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2647190.7500 - mae: 950.1713 - mse: 2647190.7500 - val_loss: 31.1557 - val_mae: 1.3952 - val_mse: 31.1557 - learning_rate: 0.0010\n",
            "Epoch 128/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2407683.7500 - mae: 900.7097 - mse: 2407683.7500 - val_loss: 31.4384 - val_mae: 1.3928 - val_mse: 31.4384 - learning_rate: 0.0010\n",
            "Epoch 129/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2321043.2500 - mae: 879.7811 - mse: 2321043.2500 - val_loss: 31.6405 - val_mae: 1.3904 - val_mse: 31.6405 - learning_rate: 0.0010\n",
            "Epoch 130/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2289844.5000 - mae: 872.6576 - mse: 2289844.5000 - val_loss: 31.1079 - val_mae: 1.3631 - val_mse: 31.1079 - learning_rate: 0.0010\n",
            "Epoch 131/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2282506.0000 - mae: 874.3308 - mse: 2282506.0000 - val_loss: 31.9434 - val_mae: 1.3872 - val_mse: 31.9434 - learning_rate: 0.0010\n",
            "Epoch 132/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2285725.2500 - mae: 871.0502 - mse: 2285725.2500 - val_loss: 30.7393 - val_mae: 1.3475 - val_mse: 30.7393 - learning_rate: 0.0010\n",
            "Epoch 133/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2334609.0000 - mae: 890.0957 - mse: 2334609.0000 - val_loss: 32.4634 - val_mae: 1.4081 - val_mse: 32.4634 - learning_rate: 0.0010\n",
            "Epoch 134/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2428704.0000 - mae: 904.1089 - mse: 2428704.0000 - val_loss: 29.9842 - val_mae: 1.3476 - val_mse: 29.9842 - learning_rate: 0.0010\n",
            "Epoch 135/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2756100.2500 - mae: 986.1885 - mse: 2756100.2500 - val_loss: 34.4695 - val_mae: 1.5420 - val_mse: 34.4695 - learning_rate: 0.0010\n",
            "Epoch 136/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3454591.0000 - mae: 1114.4114 - mse: 3454591.0000 - val_loss: 29.5047 - val_mae: 1.4749 - val_mse: 29.5047 - learning_rate: 0.0010\n",
            "Epoch 137/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5394743.5000 - mae: 1433.9086 - mse: 5394743.5000 - val_loss: 42.5405 - val_mae: 2.0464 - val_mse: 42.5405 - learning_rate: 0.0010\n",
            "Epoch 138/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9517984.0000 - mae: 1951.9700 - mse: 9517984.0000 - val_loss: 34.3863 - val_mae: 2.0249 - val_mse: 34.3863 - learning_rate: 0.0010\n",
            "Epoch 139/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17730920.0000 - mae: 2690.7288 - mse: 17730920.0000 - val_loss: 64.0878 - val_mae: 3.0170 - val_mse: 64.0878 - learning_rate: 0.0010\n",
            "Epoch 140/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29488440.0000 - mae: 3546.6567 - mse: 29488440.0000 - val_loss: 49.9276 - val_mae: 2.8555 - val_mse: 49.9276 - learning_rate: 0.0010\n",
            "Epoch 141/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 46520112.0000 - mae: 4438.0176 - mse: 46520112.0000 - val_loss: 96.6954 - val_mae: 4.0720 - val_mse: 96.6954 - learning_rate: 0.0010\n",
            "Epoch 142/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 63814672.0000 - mae: 5281.6660 - mse: 63814672.0000 - val_loss: 72.8620 - val_mae: 3.6969 - val_mse: 72.8620 - learning_rate: 0.0010\n",
            "Epoch 143/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 189153856.0000 - mae: 12074.7715 - mse: 189153856.0000\n",
            "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 84670176.0000 - mae: 6042.8555 - mse: 84670176.0000 - val_loss: 131.0026 - val_mae: 4.9660 - val_mse: 131.0026 - learning_rate: 0.0010\n",
            "Epoch 144/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 112748056.0000 - mae: 7600.6406 - mse: 112748056.0000 - val_loss: 93.4493 - val_mae: 4.0008 - val_mse: 93.4493 - learning_rate: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 65740888.0000 - mae: 5694.0610 - mse: 65740888.0000 - val_loss: 47.8348 - val_mae: 2.3814 - val_mse: 47.8348 - learning_rate: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15154772.0000 - mae: 2568.3088 - mse: 15154772.0000 - val_loss: 29.9135 - val_mae: 1.4407 - val_mse: 29.9135 - learning_rate: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2643911.5000 - mae: 971.4717 - mse: 2643911.5000 - val_loss: 29.4416 - val_mae: 1.6048 - val_mse: 29.4416 - learning_rate: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8974740.0000 - mae: 1969.0576 - mse: 8974740.0000 - val_loss: 30.1077 - val_mae: 1.6824 - val_mse: 30.1077 - learning_rate: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 10987565.0000 - mae: 2182.5134 - mse: 10987565.0000 - val_loss: 28.9664 - val_mae: 1.5357 - val_mse: 28.9664 - learning_rate: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6755465.0000 - mae: 1651.4596 - mse: 6755465.0000 - val_loss: 29.0943 - val_mae: 1.4290 - val_mse: 29.0943 - learning_rate: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3136983.0000 - mae: 1065.0212 - mse: 3136983.0000 - val_loss: 30.9096 - val_mae: 1.4765 - val_mse: 30.9096 - learning_rate: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2552221.7500 - mae: 930.0374 - mse: 2552221.7500 - val_loss: 32.4211 - val_mae: 1.5526 - val_mse: 32.4211 - learning_rate: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3070734.7500 - mae: 1035.1702 - mse: 3070734.7500 - val_loss: 32.4907 - val_mae: 1.5566 - val_mse: 32.4907 - learning_rate: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3088465.0000 - mae: 1037.5071 - mse: 3088465.0000 - val_loss: 31.5966 - val_mae: 1.5086 - val_mse: 31.5966 - learning_rate: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2711474.0000 - mae: 959.8569 - mse: 2711474.0000 - val_loss: 30.6309 - val_mae: 1.4619 - val_mse: 30.6309 - learning_rate: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2480960.5000 - mae: 915.1289 - mse: 2480960.5000 - val_loss: 30.0278 - val_mae: 1.4381 - val_mse: 30.0278 - learning_rate: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2480922.7500 - mae: 921.5450 - mse: 2480922.7500 - val_loss: 29.7982 - val_mae: 1.4297 - val_mse: 29.7982 - learning_rate: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2521061.2500 - mae: 932.4957 - mse: 2521061.2500 - val_loss: 29.8272 - val_mae: 1.4297 - val_mse: 29.8272 - learning_rate: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2504608.2500 - mae: 928.1861 - mse: 2504608.2500 - val_loss: 29.9971 - val_mae: 1.4345 - val_mse: 29.9971 - learning_rate: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2465661.2500 - mae: 917.5327 - mse: 2465661.2500 - val_loss: 30.1928 - val_mae: 1.4409 - val_mse: 30.1928 - learning_rate: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2445278.0000 - mae: 910.5024 - mse: 2445278.0000 - val_loss: 30.3221 - val_mae: 1.4451 - val_mse: 30.3221 - learning_rate: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2441451.7500 - mae: 908.1135 - mse: 2441451.7500 - val_loss: 30.3494 - val_mae: 1.4455 - val_mse: 30.3494 - learning_rate: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2438393.5000 - mae: 907.0526 - mse: 2438393.5000 - val_loss: 30.2973 - val_mae: 1.4426 - val_mse: 30.2973 - learning_rate: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2431909.2500 - mae: 906.0166 - mse: 2431909.2500 - val_loss: 30.2135 - val_mae: 1.4386 - val_mse: 30.2135 - learning_rate: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2425685.0000 - mae: 905.3629 - mse: 2425685.0000 - val_loss: 30.1388 - val_mae: 1.4348 - val_mse: 30.1388 - learning_rate: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2421323.0000 - mae: 905.0233 - mse: 2421323.0000 - val_loss: 30.0929 - val_mae: 1.4322 - val_mse: 30.0929 - learning_rate: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2417481.5000 - mae: 904.5515 - mse: 2417481.5000 - val_loss: 30.0764 - val_mae: 1.4307 - val_mse: 30.0764 - learning_rate: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2412920.2500 - mae: 903.5298 - mse: 2412920.2500 - val_loss: 30.0784 - val_mae: 1.4300 - val_mse: 30.0784 - learning_rate: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2407824.7500 - mae: 902.1575 - mse: 2407824.7500 - val_loss: 30.0847 - val_mae: 1.4294 - val_mse: 30.0847 - learning_rate: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2402706.7500 - mae: 900.7241 - mse: 2402706.7500 - val_loss: 30.0857 - val_mae: 1.4286 - val_mse: 30.0857 - learning_rate: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2397801.5000 - mae: 899.4705 - mse: 2397801.5000 - val_loss: 30.0776 - val_mae: 1.4275 - val_mse: 30.0776 - learning_rate: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2393038.2500 - mae: 898.3671 - mse: 2393038.2500 - val_loss: 30.0620 - val_mae: 1.4260 - val_mse: 30.0620 - learning_rate: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2388333.2500 - mae: 897.3538 - mse: 2388333.2500 - val_loss: 30.0430 - val_mae: 1.4244 - val_mse: 30.0430 - learning_rate: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2383678.7500 - mae: 896.3925 - mse: 2383678.7500 - val_loss: 30.0243 - val_mae: 1.4227 - val_mse: 30.0243 - learning_rate: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2379001.7500 - mae: 895.4365 - mse: 2379001.7500 - val_loss: 30.0082 - val_mae: 1.4212 - val_mse: 30.0082 - learning_rate: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2374286.5000 - mae: 894.4375 - mse: 2374286.5000 - val_loss: 29.9950 - val_mae: 1.4198 - val_mse: 29.9950 - learning_rate: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2369543.0000 - mae: 893.4051 - mse: 2369543.0000 - val_loss: 29.9837 - val_mae: 1.4185 - val_mse: 29.9837 - learning_rate: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2364812.5000 - mae: 892.3434 - mse: 2364812.5000 - val_loss: 29.9728 - val_mae: 1.4172 - val_mse: 29.9728 - learning_rate: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2360018.5000 - mae: 891.2601 - mse: 2360018.5000 - val_loss: 29.9615 - val_mae: 1.4158 - val_mse: 29.9615 - learning_rate: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2355224.7500 - mae: 890.1849 - mse: 2355224.7500 - val_loss: 29.9493 - val_mae: 1.4144 - val_mse: 29.9493 - learning_rate: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2350440.5000 - mae: 889.1097 - mse: 2350440.5000 - val_loss: 29.9365 - val_mae: 1.4130 - val_mse: 29.9365 - learning_rate: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2345675.2500 - mae: 888.0419 - mse: 2345675.2500 - val_loss: 29.9234 - val_mae: 1.4116 - val_mse: 29.9234 - learning_rate: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2340941.5000 - mae: 886.9695 - mse: 2340941.5000 - val_loss: 29.9102 - val_mae: 1.4102 - val_mse: 29.9102 - learning_rate: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2336133.5000 - mae: 885.8728 - mse: 2336133.5000 - val_loss: 29.8971 - val_mae: 1.4087 - val_mse: 29.8971 - learning_rate: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2331216.7500 - mae: 884.7521 - mse: 2331216.7500 - val_loss: 29.8840 - val_mae: 1.4073 - val_mse: 29.8840 - learning_rate: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2326245.7500 - mae: 883.6199 - mse: 2326245.7500 - val_loss: 29.8708 - val_mae: 1.4058 - val_mse: 29.8708 - learning_rate: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2321170.0000 - mae: 882.4803 - mse: 2321170.0000 - val_loss: 29.8574 - val_mae: 1.4043 - val_mse: 29.8574 - learning_rate: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2316067.0000 - mae: 881.3314 - mse: 2316067.0000 - val_loss: 29.8438 - val_mae: 1.4028 - val_mse: 29.8438 - learning_rate: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2310955.2500 - mae: 880.1703 - mse: 2310955.2500 - val_loss: 29.8300 - val_mae: 1.4013 - val_mse: 29.8300 - learning_rate: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2305866.2500 - mae: 879.0083 - mse: 2305866.2500 - val_loss: 29.8161 - val_mae: 1.3998 - val_mse: 29.8161 - learning_rate: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2300681.7500 - mae: 877.8198 - mse: 2300681.7500 - val_loss: 29.8020 - val_mae: 1.3982 - val_mse: 29.8020 - learning_rate: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2295504.0000 - mae: 876.6286 - mse: 2295504.0000 - val_loss: 29.7873 - val_mae: 1.3967 - val_mse: 29.7873 - learning_rate: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2290324.5000 - mae: 875.4379 - mse: 2290324.5000 - val_loss: 29.7727 - val_mae: 1.3952 - val_mse: 29.7727 - learning_rate: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2285066.0000 - mae: 874.2488 - mse: 2285066.0000 - val_loss: 29.7581 - val_mae: 1.3936 - val_mse: 29.7581 - learning_rate: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2279880.7500 - mae: 873.0834 - mse: 2279880.7500 - val_loss: 29.7435 - val_mae: 1.3921 - val_mse: 29.7435 - learning_rate: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2274768.5000 - mae: 871.9390 - mse: 2274768.5000 - val_loss: 29.7289 - val_mae: 1.3906 - val_mse: 29.7289 - learning_rate: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2269793.5000 - mae: 870.8344 - mse: 2269793.5000 - val_loss: 29.7139 - val_mae: 1.3891 - val_mse: 29.7139 - learning_rate: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2264979.7500 - mae: 869.7597 - mse: 2264979.7500 - val_loss: 29.6978 - val_mae: 1.3876 - val_mse: 29.6978 - learning_rate: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2260214.7500 - mae: 868.7121 - mse: 2260214.7500 - val_loss: 29.6823 - val_mae: 1.3861 - val_mse: 29.6823 - learning_rate: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2255548.2500 - mae: 867.7170 - mse: 2255548.2500 - val_loss: 29.6669 - val_mae: 1.3846 - val_mse: 29.6669 - learning_rate: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2250840.5000 - mae: 866.7291 - mse: 2250840.5000 - val_loss: 29.6515 - val_mae: 1.3831 - val_mse: 29.6515 - learning_rate: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2246087.2500 - mae: 865.7366 - mse: 2246087.2500 - val_loss: 29.6357 - val_mae: 1.3816 - val_mse: 29.6357 - learning_rate: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2241325.2500 - mae: 864.7388 - mse: 2241325.2500 - val_loss: 29.6195 - val_mae: 1.3801 - val_mse: 29.6195 - learning_rate: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2236538.7500 - mae: 863.7302 - mse: 2236538.7500 - val_loss: 29.6031 - val_mae: 1.3786 - val_mse: 29.6031 - learning_rate: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2231655.5000 - mae: 862.7050 - mse: 2231655.5000 - val_loss: 29.5863 - val_mae: 1.3770 - val_mse: 29.5863 - learning_rate: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2226763.7500 - mae: 861.6721 - mse: 2226763.7500 - val_loss: 29.5692 - val_mae: 1.3755 - val_mse: 29.5692 - learning_rate: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2221919.0000 - mae: 860.6436 - mse: 2221919.0000 - val_loss: 29.5518 - val_mae: 1.3740 - val_mse: 29.5518 - learning_rate: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2217122.5000 - mae: 859.6182 - mse: 2217122.5000 - val_loss: 29.5345 - val_mae: 1.3724 - val_mse: 29.5345 - learning_rate: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2212353.2500 - mae: 858.5890 - mse: 2212353.2500 - val_loss: 29.5170 - val_mae: 1.3709 - val_mse: 29.5170 - learning_rate: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2207582.5000 - mae: 857.5432 - mse: 2207582.5000 - val_loss: 29.4994 - val_mae: 1.3693 - val_mse: 29.4994 - learning_rate: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2202774.0000 - mae: 856.4909 - mse: 2202774.0000 - val_loss: 29.4817 - val_mae: 1.3678 - val_mse: 29.4817 - learning_rate: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2197955.5000 - mae: 855.4464 - mse: 2197955.5000 - val_loss: 29.4640 - val_mae: 1.3663 - val_mse: 29.4640 - learning_rate: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2193137.7500 - mae: 854.4116 - mse: 2193137.7500 - val_loss: 29.4461 - val_mae: 1.3647 - val_mse: 29.4461 - learning_rate: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2188294.0000 - mae: 853.3768 - mse: 2188294.0000 - val_loss: 29.4281 - val_mae: 1.3632 - val_mse: 29.4281 - learning_rate: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2183367.2500 - mae: 852.3489 - mse: 2183367.2500 - val_loss: 29.4096 - val_mae: 1.3617 - val_mse: 29.4096 - learning_rate: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2178298.5000 - mae: 851.2916 - mse: 2178298.5000 - val_loss: 29.3905 - val_mae: 1.3603 - val_mse: 29.3905 - learning_rate: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2173118.7500 - mae: 850.1906 - mse: 2173118.7500 - val_loss: 29.3714 - val_mae: 1.3588 - val_mse: 29.3714 - learning_rate: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2167864.7500 - mae: 849.0590 - mse: 2167864.7500 - val_loss: 29.3520 - val_mae: 1.3574 - val_mse: 29.3520 - learning_rate: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2162583.0000 - mae: 847.9090 - mse: 2162583.0000 - val_loss: 29.3322 - val_mae: 1.3559 - val_mse: 29.3322 - learning_rate: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2157332.2500 - mae: 846.7731 - mse: 2157332.2500 - val_loss: 29.3117 - val_mae: 1.3544 - val_mse: 29.3117 - learning_rate: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2152130.5000 - mae: 845.6602 - mse: 2152130.5000 - val_loss: 29.2907 - val_mae: 1.3528 - val_mse: 29.2907 - learning_rate: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2146961.2500 - mae: 844.5472 - mse: 2146961.2500 - val_loss: 29.2694 - val_mae: 1.3513 - val_mse: 29.2694 - learning_rate: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2141767.0000 - mae: 843.4205 - mse: 2141767.0000 - val_loss: 29.2480 - val_mae: 1.3498 - val_mse: 29.2480 - learning_rate: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2136515.0000 - mae: 842.2773 - mse: 2136515.0000 - val_loss: 29.2267 - val_mae: 1.3483 - val_mse: 29.2267 - learning_rate: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2131253.2500 - mae: 841.1276 - mse: 2131253.2500 - val_loss: 29.2048 - val_mae: 1.3468 - val_mse: 29.2048 - learning_rate: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2125954.7500 - mae: 839.9626 - mse: 2125954.7500 - val_loss: 29.1825 - val_mae: 1.3453 - val_mse: 29.1825 - learning_rate: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2120593.7500 - mae: 838.7732 - mse: 2120593.7500 - val_loss: 29.1595 - val_mae: 1.3438 - val_mse: 29.1595 - learning_rate: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2115276.2500 - mae: 837.6119 - mse: 2115276.2500 - val_loss: 29.1361 - val_mae: 1.3423 - val_mse: 29.1361 - learning_rate: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2109981.2500 - mae: 836.4629 - mse: 2109981.2500 - val_loss: 29.1120 - val_mae: 1.3408 - val_mse: 29.1120 - learning_rate: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2104613.0000 - mae: 835.3077 - mse: 2104613.0000 - val_loss: 29.0877 - val_mae: 1.3393 - val_mse: 29.0877 - learning_rate: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2099012.2500 - mae: 834.1109 - mse: 2099012.2500 - val_loss: 29.0630 - val_mae: 1.3378 - val_mse: 29.0630 - learning_rate: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2093341.0000 - mae: 832.8954 - mse: 2093341.0000 - val_loss: 29.0377 - val_mae: 1.3363 - val_mse: 29.0377 - learning_rate: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2087585.7500 - mae: 831.6949 - mse: 2087585.7500 - val_loss: 29.0114 - val_mae: 1.3348 - val_mse: 29.0114 - learning_rate: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2081714.0000 - mae: 830.4915 - mse: 2081714.0000 - val_loss: 28.9844 - val_mae: 1.3332 - val_mse: 28.9844 - learning_rate: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2075791.1250 - mae: 829.2823 - mse: 2075791.1250 - val_loss: 28.9567 - val_mae: 1.3316 - val_mse: 28.9567 - learning_rate: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2069790.2500 - mae: 828.0405 - mse: 2069790.2500 - val_loss: 28.9289 - val_mae: 1.3300 - val_mse: 28.9289 - learning_rate: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2063709.2500 - mae: 826.7684 - mse: 2063709.2500 - val_loss: 28.9007 - val_mae: 1.3284 - val_mse: 28.9007 - learning_rate: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2057634.3750 - mae: 825.5002 - mse: 2057634.3750 - val_loss: 28.8721 - val_mae: 1.3268 - val_mse: 28.8721 - learning_rate: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2051556.6250 - mae: 824.2308 - mse: 2051556.6250 - val_loss: 28.8434 - val_mae: 1.3252 - val_mse: 28.8434 - learning_rate: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2045500.8750 - mae: 822.9615 - mse: 2045500.8750 - val_loss: 28.8142 - val_mae: 1.3236 - val_mse: 28.8142 - learning_rate: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2039362.6250 - mae: 821.6834 - mse: 2039362.6250 - val_loss: 28.7842 - val_mae: 1.3220 - val_mse: 28.7842 - learning_rate: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2033314.7500 - mae: 820.4521 - mse: 2033314.7500 - val_loss: 28.7536 - val_mae: 1.3204 - val_mse: 28.7536 - learning_rate: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3275853.7500 - mae: 1217.2207 - mse: 3275853.7500\n",
            "Epoch 243: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2027226.2500 - mae: 819.2186 - mse: 2027226.2500 - val_loss: 28.7223 - val_mae: 1.3189 - val_mse: 28.7223 - learning_rate: 1.0000e-04\n",
            "Epoch 1/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 606ms/step - loss: 11227.8857 - mae: 11227.8857 - mse: 308907968.0000 - val_loss: 9.7683 - val_mae: 9.7683 - val_mse: 428.0449 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 15352.5820 - mae: 15352.5820 - mse: 507847680.0000 - val_loss: 6.8523 - val_mae: 6.8523 - val_mse: 234.7262 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11874.3447 - mae: 11874.3447 - mse: 281687872.0000 - val_loss: 2.0828 - val_mae: 2.0828 - val_mse: 56.0601 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1900.4229 - mae: 1900.4229 - mse: 8368448.5000 - val_loss: 5.0449 - val_mae: 5.0449 - val_mse: 146.0005 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7001.0864 - mae: 7001.0864 - mse: 112055184.0000 - val_loss: 5.4314 - val_mae: 5.4314 - val_mse: 163.7294 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9624.8174 - mae: 9624.8174 - mse: 188790112.0000 - val_loss: 2.1979 - val_mae: 2.1979 - val_mse: 55.0454 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1740.7501 - mae: 1740.7501 - mse: 8093004.0000 - val_loss: 2.2982 - val_mae: 2.2982 - val_mse: 55.1886 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2584.3872 - mae: 2584.3872 - mse: 17127850.0000 - val_loss: 4.9108 - val_mae: 4.9108 - val_mse: 132.9679 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7050.0767 - mae: 7050.0767 - mse: 109977432.0000 - val_loss: 4.2444 - val_mae: 4.2444 - val_mse: 109.0028 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7398.5864 - mae: 7398.5864 - mse: 114631904.0000 - val_loss: 2.6206 - val_mae: 2.6206 - val_mse: 56.3569 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2871.9558 - mae: 2871.9558 - mse: 20248020.0000 - val_loss: 3.2609 - val_mae: 3.2609 - val_mse: 71.8655 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5071.9941 - mae: 5071.9941 - mse: 59292176.0000 - val_loss: 4.9977 - val_mae: 4.9977 - val_mse: 131.5727 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7684.7568 - mae: 7684.7568 - mse: 123361960.0000 - val_loss: 2.1724 - val_mae: 2.1724 - val_mse: 43.5184 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2956.2515 - mae: 2956.2515 - mse: 21094934.0000 - val_loss: 3.6988 - val_mae: 3.6988 - val_mse: 86.5624 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4915.6934 - mae: 4915.6934 - mse: 55118108.0000 - val_loss: 3.8219 - val_mae: 3.8219 - val_mse: 83.5739 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6679.3350 - mae: 6679.3350 - mse: 94149136.0000 - val_loss: 2.9037 - val_mae: 2.9037 - val_mse: 67.9906 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3331.7329 - mae: 3331.7329 - mse: 26224812.0000 - val_loss: 2.8978 - val_mae: 2.8978 - val_mse: 56.0948 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4742.3438 - mae: 4742.3438 - mse: 51711300.0000 - val_loss: 4.4192 - val_mae: 4.4192 - val_mse: 121.0947 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5873.3716 - mae: 5873.3716 - mse: 73775656.0000 - val_loss: 2.5380 - val_mae: 2.5380 - val_mse: 47.7074 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4007.7739 - mae: 4007.7739 - mse: 37175176.0000 - val_loss: 3.7641 - val_mae: 3.7641 - val_mse: 96.3590 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4682.0571 - mae: 4682.0571 - mse: 49160564.0000 - val_loss: 3.2048 - val_mae: 3.2048 - val_mse: 62.6047 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5595.8691 - mae: 5595.8691 - mse: 68201224.0000 - val_loss: 3.2914 - val_mae: 3.2914 - val_mse: 80.6809 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3913.3569 - mae: 3913.3569 - mse: 34918972.0000 - val_loss: 2.9154 - val_mae: 2.9154 - val_mse: 55.0412 - learning_rate: 0.0010\n",
            "Epoch 24/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4922.6377 - mae: 4922.6377 - mse: 54402924.0000 - val_loss: 3.8794 - val_mae: 3.8794 - val_mse: 99.1388 - learning_rate: 0.0010\n",
            "Epoch 25/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4984.2812 - mae: 4984.2812 - mse: 54138984.0000 - val_loss: 2.6951 - val_mae: 2.6951 - val_mse: 49.8304 - learning_rate: 0.0010\n",
            "Epoch 26/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4483.3735 - mae: 4483.3735 - mse: 45297680.0000 - val_loss: 3.6653 - val_mae: 3.6653 - val_mse: 91.4394 - learning_rate: 0.0010\n",
            "Epoch 27/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4588.3477 - mae: 4588.3477 - mse: 46725408.0000 - val_loss: 2.9340 - val_mae: 2.9340 - val_mse: 54.7432 - learning_rate: 0.0010\n",
            "Epoch 28/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5030.2754 - mae: 5030.2754 - mse: 55812876.0000 - val_loss: 3.4867 - val_mae: 3.4867 - val_mse: 85.3878 - learning_rate: 0.0010\n",
            "Epoch 29/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4287.9741 - mae: 4287.9741 - mse: 41066892.0000 - val_loss: 2.8548 - val_mae: 2.8548 - val_mse: 52.8788 - learning_rate: 0.0010\n",
            "Epoch 30/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4863.3896 - mae: 4863.3896 - mse: 52747072.0000 - val_loss: 3.5976 - val_mae: 3.5976 - val_mse: 88.5511 - learning_rate: 0.0010\n",
            "Epoch 31/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4490.9785 - mae: 4490.9785 - mse: 44643252.0000 - val_loss: 2.7763 - val_mae: 2.7763 - val_mse: 51.0052 - learning_rate: 0.0010\n",
            "Epoch 32/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4705.8613 - mae: 4705.8613 - mse: 49555528.0000 - val_loss: 3.5477 - val_mae: 3.5477 - val_mse: 86.4203 - learning_rate: 0.0010\n",
            "Epoch 33/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4412.1313 - mae: 4412.1313 - mse: 43255984.0000 - val_loss: 2.7993 - val_mae: 2.7993 - val_mse: 51.3005 - learning_rate: 0.0010\n",
            "Epoch 34/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4760.3135 - mae: 4760.3135 - mse: 50530256.0000 - val_loss: 3.5151 - val_mae: 3.5151 - val_mse: 84.8494 - learning_rate: 0.0010\n",
            "Epoch 35/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4375.5059 - mae: 4375.5059 - mse: 42520536.0000 - val_loss: 2.7570 - val_mae: 2.7570 - val_mse: 50.2545 - learning_rate: 0.0010\n",
            "Epoch 36/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4676.0967 - mae: 4676.0967 - mse: 48921036.0000 - val_loss: 3.5029 - val_mae: 3.5029 - val_mse: 84.0399 - learning_rate: 0.0010\n",
            "Epoch 37/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4360.9438 - mae: 4360.9438 - mse: 42248752.0000 - val_loss: 2.7462 - val_mae: 2.7462 - val_mse: 49.8527 - learning_rate: 0.0010\n",
            "Epoch 38/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4662.4790 - mae: 4662.4790 - mse: 48608200.0000 - val_loss: 3.4663 - val_mae: 3.4663 - val_mse: 82.4012 - learning_rate: 0.0010\n",
            "Epoch 39/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4307.6689 - mae: 4307.6689 - mse: 41279464.0000 - val_loss: 2.7353 - val_mae: 2.7353 - val_mse: 49.4559 - learning_rate: 0.0010\n",
            "Epoch 40/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4643.8018 - mae: 4643.8018 - mse: 48212484.0000 - val_loss: 3.4526 - val_mae: 3.4526 - val_mse: 81.5511 - learning_rate: 0.0010\n",
            "Epoch 41/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4295.4932 - mae: 4295.4932 - mse: 41030936.0000 - val_loss: 2.7071 - val_mae: 2.7071 - val_mse: 48.7242 - learning_rate: 0.0010\n",
            "Epoch 42/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4587.9370 - mae: 4587.9370 - mse: 47131900.0000 - val_loss: 3.4460 - val_mae: 3.4460 - val_mse: 81.0015 - learning_rate: 0.0010\n",
            "Epoch 43/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4292.2104 - mae: 4292.2104 - mse: 40953244.0000 - val_loss: 2.6861 - val_mae: 2.6861 - val_mse: 48.1405 - learning_rate: 0.0010\n",
            "Epoch 44/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4548.8311 - mae: 4548.8311 - mse: 46366796.0000 - val_loss: 3.4223 - val_mae: 3.4223 - val_mse: 79.9430 - learning_rate: 0.0010\n",
            "Epoch 45/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4256.6987 - mae: 4256.6987 - mse: 40319656.0000 - val_loss: 2.6795 - val_mae: 2.6795 - val_mse: 47.8650 - learning_rate: 0.0010\n",
            "Epoch 46/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4541.5059 - mae: 4541.5059 - mse: 46195188.0000 - val_loss: 3.3952 - val_mae: 3.3952 - val_mse: 78.7938 - learning_rate: 0.0010\n",
            "Epoch 47/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4216.2427 - mae: 4216.2427 - mse: 39593332.0000 - val_loss: 2.6677 - val_mae: 2.6677 - val_mse: 47.4851 - learning_rate: 0.0010\n",
            "Epoch 48/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4523.4658 - mae: 4523.4658 - mse: 45837624.0000 - val_loss: 3.3787 - val_mae: 3.3787 - val_mse: 78.0044 - learning_rate: 0.0010\n",
            "Epoch 49/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4193.4883 - mae: 4193.4883 - mse: 39173152.0000 - val_loss: 2.6505 - val_mae: 2.6505 - val_mse: 47.0010 - learning_rate: 0.0010\n",
            "Epoch 50/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4493.9277 - mae: 4493.9277 - mse: 45268584.0000 - val_loss: 3.3587 - val_mae: 3.3587 - val_mse: 77.1012 - learning_rate: 0.0010\n",
            "Epoch 51/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4161.8662 - mae: 4161.8662 - mse: 38609680.0000 - val_loss: 2.6422 - val_mae: 2.6422 - val_mse: 46.6930 - learning_rate: 0.0010\n",
            "Epoch 52/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4486.3599 - mae: 4486.3599 - mse: 45102264.0000 - val_loss: 3.3420 - val_mae: 3.3420 - val_mse: 76.3031 - learning_rate: 0.0010\n",
            "Epoch 53/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4135.0674 - mae: 4135.0674 - mse: 38113172.0000 - val_loss: 2.6231 - val_mae: 2.6231 - val_mse: 46.1820 - learning_rate: 0.0010\n",
            "Epoch 54/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4454.7529 - mae: 4454.7529 - mse: 44516828.0000 - val_loss: 3.3325 - val_mae: 3.3325 - val_mse: 75.7074 - learning_rate: 0.0010\n",
            "Epoch 55/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4122.2256 - mae: 4122.2256 - mse: 37863068.0000 - val_loss: 2.6090 - val_mae: 2.6090 - val_mse: 45.7662 - learning_rate: 0.0010\n",
            "Epoch 56/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4433.2871 - mae: 4433.2871 - mse: 44091580.0000 - val_loss: 3.3107 - val_mae: 3.3107 - val_mse: 74.7357 - learning_rate: 0.0010\n",
            "Epoch 57/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4087.8145 - mae: 4087.8145 - mse: 37256432.0000 - val_loss: 2.5928 - val_mae: 2.5928 - val_mse: 45.3211 - learning_rate: 0.0010\n",
            "Epoch 58/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4405.4800 - mae: 4405.4800 - mse: 43581432.0000 - val_loss: 3.3063 - val_mae: 3.3063 - val_mse: 74.3072 - learning_rate: 0.0010\n",
            "Epoch 59/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4084.9143 - mae: 4084.9143 - mse: 37172700.0000 - val_loss: 2.5705 - val_mae: 2.5705 - val_mse: 44.7354 - learning_rate: 0.0010\n",
            "Epoch 60/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4363.1011 - mae: 4363.1011 - mse: 42800708.0000 - val_loss: 3.2979 - val_mae: 3.2979 - val_mse: 73.7862 - learning_rate: 0.0010\n",
            "Epoch 61/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4075.2363 - mae: 4075.2363 - mse: 36988232.0000 - val_loss: 2.5589 - val_mae: 2.5589 - val_mse: 44.3945 - learning_rate: 0.0010\n",
            "Epoch 62/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4339.6104 - mae: 4339.6104 - mse: 42354708.0000 - val_loss: 3.2781 - val_mae: 3.2781 - val_mse: 72.8135 - learning_rate: 0.0010\n",
            "Epoch 63/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4046.9814 - mae: 4046.9814 - mse: 36498836.0000 - val_loss: 2.5525 - val_mae: 2.5525 - val_mse: 44.1923 - learning_rate: 0.0010\n",
            "Epoch 64/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4324.0342 - mae: 4324.0342 - mse: 42058428.0000 - val_loss: 3.2643 - val_mae: 3.2643 - val_mse: 72.2373 - learning_rate: 0.0010\n",
            "Epoch 65/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4027.7866 - mae: 4027.7866 - mse: 36155248.0000 - val_loss: 2.5290 - val_mae: 2.5290 - val_mse: 43.5727 - learning_rate: 0.0010\n",
            "Epoch 66/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4279.8887 - mae: 4279.8887 - mse: 41275740.0000 - val_loss: 3.2605 - val_mae: 3.2605 - val_mse: 71.9781 - learning_rate: 0.0010\n",
            "Epoch 67/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4029.6870 - mae: 4029.6870 - mse: 36171008.0000 - val_loss: 2.5177 - val_mae: 2.5177 - val_mse: 43.2608 - learning_rate: 0.0010\n",
            "Epoch 68/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4253.2241 - mae: 4253.2241 - mse: 40767780.0000 - val_loss: 3.2370 - val_mae: 3.2370 - val_mse: 70.8957 - learning_rate: 0.0010\n",
            "Epoch 69/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3997.6526 - mae: 3997.6526 - mse: 35637516.0000 - val_loss: 2.5033 - val_mae: 2.5033 - val_mse: 42.9137 - learning_rate: 0.0010\n",
            "Epoch 70/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4221.9141 - mae: 4221.9141 - mse: 40219560.0000 - val_loss: 3.2193 - val_mae: 3.2193 - val_mse: 70.1136 - learning_rate: 0.0010\n",
            "Epoch 71/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3972.3164 - mae: 3972.3164 - mse: 35217140.0000 - val_loss: 2.4889 - val_mae: 2.4889 - val_mse: 42.5354 - learning_rate: 0.0010\n",
            "Epoch 72/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4195.8403 - mae: 4195.8403 - mse: 39774168.0000 - val_loss: 3.1969 - val_mae: 3.1969 - val_mse: 69.2351 - learning_rate: 0.0010\n",
            "Epoch 73/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3936.5503 - mae: 3936.5503 - mse: 34622772.0000 - val_loss: 2.4832 - val_mae: 2.4832 - val_mse: 42.2895 - learning_rate: 0.0010\n",
            "Epoch 74/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4187.3877 - mae: 4187.3877 - mse: 39615392.0000 - val_loss: 3.1806 - val_mae: 3.1806 - val_mse: 68.5013 - learning_rate: 0.0010\n",
            "Epoch 75/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3916.1707 - mae: 3916.1707 - mse: 34268196.0000 - val_loss: 2.4658 - val_mae: 2.4658 - val_mse: 41.8137 - learning_rate: 0.0010\n",
            "Epoch 76/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4151.2373 - mae: 4151.2373 - mse: 38981668.0000 - val_loss: 3.1661 - val_mae: 3.1661 - val_mse: 67.7628 - learning_rate: 0.0010\n",
            "Epoch 77/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3897.5159 - mae: 3897.5159 - mse: 33960012.0000 - val_loss: 2.4645 - val_mae: 2.4645 - val_mse: 41.7292 - learning_rate: 0.0010\n",
            "Epoch 78/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4148.1572 - mae: 4148.1572 - mse: 38912252.0000 - val_loss: 3.1511 - val_mae: 3.1511 - val_mse: 67.0363 - learning_rate: 0.0010\n",
            "Epoch 79/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3880.5317 - mae: 3880.5317 - mse: 33664176.0000 - val_loss: 2.4480 - val_mae: 2.4480 - val_mse: 41.3093 - learning_rate: 0.0010\n",
            "Epoch 80/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4111.5918 - mae: 4111.5918 - mse: 38274736.0000 - val_loss: 3.1356 - val_mae: 3.1356 - val_mse: 66.3867 - learning_rate: 0.0010\n",
            "Epoch 81/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3861.0278 - mae: 3861.0278 - mse: 33350504.0000 - val_loss: 2.4468 - val_mae: 2.4468 - val_mse: 41.1773 - learning_rate: 0.0010\n",
            "Epoch 82/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4111.4624 - mae: 4111.4624 - mse: 38245248.0000 - val_loss: 3.1105 - val_mae: 3.1105 - val_mse: 65.4657 - learning_rate: 0.0010\n",
            "Epoch 83/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3824.1731 - mae: 3824.1731 - mse: 32755966.0000 - val_loss: 2.4430 - val_mae: 2.4430 - val_mse: 41.0069 - learning_rate: 0.0010\n",
            "Epoch 84/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4105.7280 - mae: 4105.7280 - mse: 38133284.0000 - val_loss: 3.0912 - val_mae: 3.0912 - val_mse: 64.7028 - learning_rate: 0.0010\n",
            "Epoch 85/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3798.7354 - mae: 3798.7354 - mse: 32344416.0000 - val_loss: 2.4351 - val_mae: 2.4351 - val_mse: 40.7700 - learning_rate: 0.0010\n",
            "Epoch 86/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4089.2229 - mae: 4089.2229 - mse: 37835232.0000 - val_loss: 3.0760 - val_mae: 3.0760 - val_mse: 64.0540 - learning_rate: 0.0010\n",
            "Epoch 87/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3780.6912 - mae: 3780.6912 - mse: 32051080.0000 - val_loss: 2.4256 - val_mae: 2.4256 - val_mse: 40.5233 - learning_rate: 0.0010\n",
            "Epoch 88/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4070.3479 - mae: 4070.3479 - mse: 37502960.0000 - val_loss: 3.0588 - val_mae: 3.0588 - val_mse: 63.3435 - learning_rate: 0.0010\n",
            "Epoch 89/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3761.7744 - mae: 3761.7744 - mse: 31721666.0000 - val_loss: 2.3995 - val_mae: 2.3995 - val_mse: 39.9650 - learning_rate: 0.0010\n",
            "Epoch 90/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4010.1650 - mae: 4010.1650 - mse: 36497092.0000 - val_loss: 3.0678 - val_mae: 3.0678 - val_mse: 63.3475 - learning_rate: 0.0010\n",
            "Epoch 91/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3787.1843 - mae: 3787.1843 - mse: 32128706.0000 - val_loss: 2.3991 - val_mae: 2.3991 - val_mse: 39.9210 - learning_rate: 0.0010\n",
            "Epoch 92/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4012.5300 - mae: 4012.5300 - mse: 36498104.0000 - val_loss: 3.0285 - val_mae: 3.0285 - val_mse: 62.0907 - learning_rate: 0.0010\n",
            "Epoch 93/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3726.0317 - mae: 3726.0317 - mse: 31144764.0000 - val_loss: 2.3809 - val_mae: 2.3809 - val_mse: 39.4610 - learning_rate: 0.0010\n",
            "Epoch 94/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3971.7314 - mae: 3971.7314 - mse: 35834152.0000 - val_loss: 3.0279 - val_mae: 3.0279 - val_mse: 61.8055 - learning_rate: 0.0010\n",
            "Epoch 95/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3734.4543 - mae: 3734.4543 - mse: 31278856.0000 - val_loss: 2.3794 - val_mae: 2.3794 - val_mse: 39.4211 - learning_rate: 0.0010\n",
            "Epoch 96/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3960.6213 - mae: 3960.6213 - mse: 35617988.0000 - val_loss: 3.0058 - val_mae: 3.0058 - val_mse: 60.9752 - learning_rate: 0.0010\n",
            "Epoch 97/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3704.2292 - mae: 3704.2292 - mse: 30794648.0000 - val_loss: 2.3674 - val_mae: 2.3674 - val_mse: 39.1514 - learning_rate: 0.0010\n",
            "Epoch 98/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3931.2754 - mae: 3931.2754 - mse: 35132312.0000 - val_loss: 2.9905 - val_mae: 2.9905 - val_mse: 60.4653 - learning_rate: 0.0010\n",
            "Epoch 99/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3681.7356 - mae: 3681.7356 - mse: 30451474.0000 - val_loss: 2.3651 - val_mae: 2.3651 - val_mse: 39.1074 - learning_rate: 0.0010\n",
            "Epoch 100/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3924.3123 - mae: 3924.3123 - mse: 34999568.0000 - val_loss: 2.9774 - val_mae: 2.9774 - val_mse: 60.0758 - learning_rate: 0.0010\n",
            "Epoch 101/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3663.5034 - mae: 3663.5034 - mse: 30161602.0000 - val_loss: 2.3481 - val_mae: 2.3481 - val_mse: 38.7241 - learning_rate: 0.0010\n",
            "Epoch 102/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3887.5071 - mae: 3887.5071 - mse: 34403628.0000 - val_loss: 2.9720 - val_mae: 2.9720 - val_mse: 59.9076 - learning_rate: 0.0010\n",
            "Epoch 103/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6831.0630 - mae: 6831.0630 - mse: 63419324.0000\n",
            "Epoch 103: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3656.9182 - mae: 3656.9182 - mse: 30053216.0000 - val_loss: 2.3409 - val_mae: 2.3409 - val_mse: 38.4693 - learning_rate: 0.0010\n",
            "Epoch 104/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4135.7715 - mae: 4135.7715 - mse: 35843556.0000 - val_loss: 1.9834 - val_mae: 1.9834 - val_mse: 32.4779 - learning_rate: 1.0000e-04\n",
            "Epoch 105/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3210.7805 - mae: 3210.7805 - mse: 23132246.0000 - val_loss: 1.4154 - val_mae: 1.4154 - val_mse: 26.2617 - learning_rate: 1.0000e-04\n",
            "Epoch 106/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1495.7367 - mae: 1495.7367 - mse: 5962614.0000 - val_loss: 1.6244 - val_mae: 1.6244 - val_mse: 31.3930 - learning_rate: 1.0000e-04\n",
            "Epoch 107/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1279.0050 - mae: 1279.0050 - mse: 4388829.0000 - val_loss: 1.7801 - val_mae: 1.7801 - val_mse: 33.9150 - learning_rate: 1.0000e-04\n",
            "Epoch 108/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1529.3916 - mae: 1529.3916 - mse: 6033763.0000 - val_loss: 1.4942 - val_mae: 1.4942 - val_mse: 29.1631 - learning_rate: 1.0000e-04\n",
            "Epoch 109/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1043.6819 - mae: 1043.6819 - mse: 3175079.5000 - val_loss: 1.3504 - val_mae: 1.3504 - val_mse: 26.2708 - learning_rate: 1.0000e-04\n",
            "Epoch 110/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1110.2531 - mae: 1110.2531 - mse: 3387279.7500 - val_loss: 1.3403 - val_mae: 1.3403 - val_mse: 26.0474 - learning_rate: 1.0000e-04\n",
            "Epoch 111/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1100.0398 - mae: 1100.0398 - mse: 3354608.5000 - val_loss: 1.3717 - val_mae: 1.3717 - val_mse: 26.9926 - learning_rate: 1.0000e-04\n",
            "Epoch 112/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 975.8641 - mae: 975.8641 - mse: 2737257.0000 - val_loss: 1.4204 - val_mae: 1.4204 - val_mse: 27.7286 - learning_rate: 1.0000e-04\n",
            "Epoch 113/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 992.0275 - mae: 992.0275 - mse: 2858919.7500 - val_loss: 1.3576 - val_mae: 1.3576 - val_mse: 26.6943 - learning_rate: 1.0000e-04\n",
            "Epoch 114/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 938.9258 - mae: 938.9258 - mse: 2577770.0000 - val_loss: 1.3050 - val_mae: 1.3050 - val_mse: 25.6745 - learning_rate: 1.0000e-04\n",
            "Epoch 115/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 932.8033 - mae: 932.8033 - mse: 2519965.2500 - val_loss: 1.2932 - val_mae: 1.2932 - val_mse: 25.4530 - learning_rate: 1.0000e-04\n",
            "Epoch 116/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 917.1130 - mae: 917.1130 - mse: 2446612.2500 - val_loss: 1.3065 - val_mae: 1.3065 - val_mse: 25.6973 - learning_rate: 1.0000e-04\n",
            "Epoch 117/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 891.1339 - mae: 891.1339 - mse: 2336573.7500 - val_loss: 1.3065 - val_mae: 1.3065 - val_mse: 25.6252 - learning_rate: 1.0000e-04\n",
            "Epoch 118/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 879.5499 - mae: 879.5499 - mse: 2291391.5000 - val_loss: 1.2764 - val_mae: 1.2764 - val_mse: 24.9964 - learning_rate: 1.0000e-04\n",
            "Epoch 119/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 872.9385 - mae: 872.9385 - mse: 2247232.5000 - val_loss: 1.2737 - val_mae: 1.2737 - val_mse: 24.8727 - learning_rate: 1.0000e-04\n",
            "Epoch 120/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 866.1224 - mae: 866.1224 - mse: 2222050.5000 - val_loss: 1.2828 - val_mae: 1.2828 - val_mse: 24.9937 - learning_rate: 1.0000e-04\n",
            "Epoch 121/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 862.2535 - mae: 862.2535 - mse: 2212340.7500 - val_loss: 1.2651 - val_mae: 1.2651 - val_mse: 24.5419 - learning_rate: 1.0000e-04\n",
            "Epoch 122/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 857.3472 - mae: 857.3472 - mse: 2187719.0000 - val_loss: 1.2603 - val_mae: 1.2603 - val_mse: 24.3517 - learning_rate: 1.0000e-04\n",
            "Epoch 123/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 856.0805 - mae: 856.0805 - mse: 2181181.2500 - val_loss: 1.2651 - val_mae: 1.2651 - val_mse: 24.4194 - learning_rate: 1.0000e-04\n",
            "Epoch 124/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 851.6388 - mae: 851.6388 - mse: 2168446.7500 - val_loss: 1.2581 - val_mae: 1.2581 - val_mse: 24.1858 - learning_rate: 1.0000e-04\n",
            "Epoch 125/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 849.3401 - mae: 849.3401 - mse: 2157358.2500 - val_loss: 1.2554 - val_mae: 1.2554 - val_mse: 24.0626 - learning_rate: 1.0000e-04\n",
            "Epoch 126/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 847.3276 - mae: 847.3276 - mse: 2149858.5000 - val_loss: 1.2541 - val_mae: 1.2541 - val_mse: 23.9822 - learning_rate: 1.0000e-04\n",
            "Epoch 127/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 845.5040 - mae: 845.5040 - mse: 2142515.7500 - val_loss: 1.2496 - val_mae: 1.2496 - val_mse: 23.8224 - learning_rate: 1.0000e-04\n",
            "Epoch 128/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 845.2623 - mae: 845.2623 - mse: 2138656.7500 - val_loss: 1.2492 - val_mae: 1.2492 - val_mse: 23.7791 - learning_rate: 1.0000e-04\n",
            "Epoch 129/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 843.9497 - mae: 843.9497 - mse: 2132659.0000 - val_loss: 1.2492 - val_mae: 1.2492 - val_mse: 23.7494 - learning_rate: 1.0000e-04\n",
            "Epoch 130/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 842.7907 - mae: 842.7907 - mse: 2128010.0000 - val_loss: 1.2455 - val_mae: 1.2455 - val_mse: 23.6216 - learning_rate: 1.0000e-04\n",
            "Epoch 131/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 842.3497 - mae: 842.3497 - mse: 2124408.0000 - val_loss: 1.2433 - val_mae: 1.2433 - val_mse: 23.5381 - learning_rate: 1.0000e-04\n",
            "Epoch 132/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 841.7913 - mae: 841.7913 - mse: 2121298.5000 - val_loss: 1.2422 - val_mae: 1.2422 - val_mse: 23.4888 - learning_rate: 1.0000e-04\n",
            "Epoch 133/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 840.9612 - mae: 840.9612 - mse: 2117598.7500 - val_loss: 1.2419 - val_mae: 1.2419 - val_mse: 23.4588 - learning_rate: 1.0000e-04\n",
            "Epoch 134/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 839.8858 - mae: 839.8858 - mse: 2113783.0000 - val_loss: 1.2395 - val_mae: 1.2395 - val_mse: 23.3752 - learning_rate: 1.0000e-04\n",
            "Epoch 135/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 839.3082 - mae: 839.3082 - mse: 2110603.2500 - val_loss: 1.2381 - val_mae: 1.2381 - val_mse: 23.3200 - learning_rate: 1.0000e-04\n",
            "Epoch 136/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 838.5223 - mae: 838.5223 - mse: 2107306.2500 - val_loss: 1.2369 - val_mae: 1.2369 - val_mse: 23.2711 - learning_rate: 1.0000e-04\n",
            "Epoch 137/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 837.6686 - mae: 837.6686 - mse: 2103868.7500 - val_loss: 1.2349 - val_mae: 1.2349 - val_mse: 23.2063 - learning_rate: 1.0000e-04\n",
            "Epoch 138/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 836.9533 - mae: 836.9533 - mse: 2100638.0000 - val_loss: 1.2332 - val_mae: 1.2332 - val_mse: 23.1443 - learning_rate: 1.0000e-04\n",
            "Epoch 139/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 836.2253 - mae: 836.2253 - mse: 2097481.0000 - val_loss: 1.2320 - val_mae: 1.2320 - val_mse: 23.0919 - learning_rate: 1.0000e-04\n",
            "Epoch 140/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 835.3817 - mae: 835.3817 - mse: 2093924.7500 - val_loss: 1.2306 - val_mae: 1.2306 - val_mse: 23.0374 - learning_rate: 1.0000e-04\n",
            "Epoch 141/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 834.6149 - mae: 834.6149 - mse: 2090651.3750 - val_loss: 1.2294 - val_mae: 1.2294 - val_mse: 22.9891 - learning_rate: 1.0000e-04\n",
            "Epoch 142/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 833.7807 - mae: 833.7807 - mse: 2087293.6250 - val_loss: 1.2279 - val_mae: 1.2279 - val_mse: 22.9314 - learning_rate: 1.0000e-04\n",
            "Epoch 143/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 833.0889 - mae: 833.0889 - mse: 2084464.7500 - val_loss: 1.2268 - val_mae: 1.2268 - val_mse: 22.8892 - learning_rate: 1.0000e-04\n",
            "Epoch 144/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 832.2136 - mae: 832.2136 - mse: 2081174.5000 - val_loss: 1.2255 - val_mae: 1.2255 - val_mse: 22.8401 - learning_rate: 1.0000e-04\n",
            "Epoch 145/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 831.3647 - mae: 831.3647 - mse: 2077930.5000 - val_loss: 1.2240 - val_mae: 1.2240 - val_mse: 22.7852 - learning_rate: 1.0000e-04\n",
            "Epoch 146/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 830.5757 - mae: 830.5757 - mse: 2074753.6250 - val_loss: 1.2224 - val_mae: 1.2224 - val_mse: 22.7326 - learning_rate: 1.0000e-04\n",
            "Epoch 147/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 829.7192 - mae: 829.7192 - mse: 2071333.8750 - val_loss: 1.2207 - val_mae: 1.2207 - val_mse: 22.6828 - learning_rate: 1.0000e-04\n",
            "Epoch 148/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 828.6650 - mae: 828.6650 - mse: 2067042.5000 - val_loss: 1.2173 - val_mae: 1.2173 - val_mse: 22.5816 - learning_rate: 1.0000e-04\n",
            "Epoch 149/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 827.5767 - mae: 827.5767 - mse: 2061971.2500 - val_loss: 1.2145 - val_mae: 1.2145 - val_mse: 22.4839 - learning_rate: 1.0000e-04\n",
            "Epoch 150/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 824.1556 - mae: 824.1556 - mse: 2049172.5000 - val_loss: 1.2112 - val_mae: 1.2112 - val_mse: 22.3554 - learning_rate: 1.0000e-04\n",
            "Epoch 151/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 818.6268 - mae: 818.6268 - mse: 2027642.3750 - val_loss: 1.2098 - val_mae: 1.2098 - val_mse: 22.2682 - learning_rate: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.7108 - mae: 811.7108 - mse: 1996296.0000 - val_loss: 1.2070 - val_mae: 1.2070 - val_mse: 22.0865 - learning_rate: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 806.2717 - mae: 806.2717 - mse: 1967840.2500 - val_loss: 1.2079 - val_mae: 1.2079 - val_mse: 22.0254 - learning_rate: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.9933 - mae: 802.9933 - mse: 1950883.7500 - val_loss: 1.2100 - val_mae: 1.2100 - val_mse: 22.0209 - learning_rate: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.2775 - mae: 801.2775 - mse: 1938319.7500 - val_loss: 1.2058 - val_mae: 1.2058 - val_mse: 21.8213 - learning_rate: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.6339 - mae: 803.6339 - mse: 1939837.2500 - val_loss: 1.2162 - val_mae: 1.2162 - val_mse: 22.0942 - learning_rate: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 807.0999 - mae: 807.0999 - mse: 1955676.1250 - val_loss: 1.2015 - val_mae: 1.2015 - val_mse: 21.5635 - learning_rate: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 814.9953 - mae: 814.9953 - mse: 1972760.0000 - val_loss: 1.2132 - val_mae: 1.2132 - val_mse: 21.9502 - learning_rate: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 805.0066 - mae: 805.0066 - mse: 1946690.2500 - val_loss: 1.1997 - val_mae: 1.1997 - val_mse: 21.5279 - learning_rate: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.6643 - mae: 799.6643 - mse: 1919818.2500 - val_loss: 1.2035 - val_mae: 1.2035 - val_mse: 21.6469 - learning_rate: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.4437 - mae: 794.4437 - mse: 1905251.5000 - val_loss: 1.1983 - val_mae: 1.1983 - val_mse: 21.4703 - learning_rate: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 792.9799 - mae: 792.9799 - mse: 1897293.7500 - val_loss: 1.1988 - val_mae: 1.1988 - val_mse: 21.4664 - learning_rate: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 791.1436 - mae: 791.1436 - mse: 1891752.3750 - val_loss: 1.1957 - val_mae: 1.1957 - val_mse: 21.3433 - learning_rate: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.3015 - mae: 791.3015 - mse: 1889306.8750 - val_loss: 1.1984 - val_mae: 1.1984 - val_mse: 21.4101 - learning_rate: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 789.8527 - mae: 789.8527 - mse: 1888302.8750 - val_loss: 1.1926 - val_mae: 1.1926 - val_mse: 21.1839 - learning_rate: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 791.7435 - mae: 791.7435 - mse: 1887745.5000 - val_loss: 1.1957 - val_mae: 1.1957 - val_mse: 21.2910 - learning_rate: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 787.7891 - mae: 787.7891 - mse: 1880030.2500 - val_loss: 1.1921 - val_mae: 1.1921 - val_mse: 21.1228 - learning_rate: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 787.6969 - mae: 787.6969 - mse: 1874409.1250 - val_loss: 1.1934 - val_mae: 1.1934 - val_mse: 21.1662 - learning_rate: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 785.4016 - mae: 785.4016 - mse: 1870428.6250 - val_loss: 1.1909 - val_mae: 1.1909 - val_mse: 21.0102 - learning_rate: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 786.4330 - mae: 786.4330 - mse: 1868784.6250 - val_loss: 1.1922 - val_mae: 1.1922 - val_mse: 21.0737 - learning_rate: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 783.8313 - mae: 783.8313 - mse: 1864206.3750 - val_loss: 1.1900 - val_mae: 1.1900 - val_mse: 20.9094 - learning_rate: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 785.1963 - mae: 785.1963 - mse: 1863726.2500 - val_loss: 1.1913 - val_mae: 1.1913 - val_mse: 20.9891 - learning_rate: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 782.5992 - mae: 782.5992 - mse: 1858879.1250 - val_loss: 1.1892 - val_mae: 1.1892 - val_mse: 20.8348 - learning_rate: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 783.1785 - mae: 783.1785 - mse: 1856483.1250 - val_loss: 1.1900 - val_mae: 1.1900 - val_mse: 20.8923 - learning_rate: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 780.8218 - mae: 780.8218 - mse: 1851029.6250 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 20.7785 - learning_rate: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 781.0566 - mae: 781.0566 - mse: 1848971.7500 - val_loss: 1.1888 - val_mae: 1.1888 - val_mse: 20.8113 - learning_rate: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 779.3657 - mae: 779.3657 - mse: 1844475.2500 - val_loss: 1.1875 - val_mae: 1.1875 - val_mse: 20.7197 - learning_rate: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 779.5519 - mae: 779.5519 - mse: 1843026.7500 - val_loss: 1.1877 - val_mae: 1.1877 - val_mse: 20.7486 - learning_rate: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 778.1378 - mae: 778.1378 - mse: 1838965.8750 - val_loss: 1.1867 - val_mae: 1.1867 - val_mse: 20.6817 - learning_rate: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 777.8640 - mae: 777.8640 - mse: 1836467.5000 - val_loss: 1.1865 - val_mae: 1.1865 - val_mse: 20.6730 - learning_rate: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 777.0506 - mae: 777.0506 - mse: 1833419.5000 - val_loss: 1.1859 - val_mae: 1.1859 - val_mse: 20.6474 - learning_rate: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 776.4372 - mae: 776.4372 - mse: 1830889.0000 - val_loss: 1.1853 - val_mae: 1.1853 - val_mse: 20.6168 - learning_rate: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 775.9440 - mae: 775.9440 - mse: 1828695.7500 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 20.6057 - learning_rate: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 775.1673 - mae: 775.1673 - mse: 1825840.2500 - val_loss: 1.1843 - val_mae: 1.1843 - val_mse: 20.5775 - learning_rate: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 774.6339 - mae: 774.6339 - mse: 1823589.1250 - val_loss: 1.1838 - val_mae: 1.1838 - val_mse: 20.5646 - learning_rate: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 773.9457 - mae: 773.9457 - mse: 1821063.8750 - val_loss: 1.1832 - val_mae: 1.1832 - val_mse: 20.5402 - learning_rate: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 773.5260 - mae: 773.5260 - mse: 1819090.3750 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 20.5492 - learning_rate: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 772.6050 - mae: 772.6050 - mse: 1816507.7500 - val_loss: 1.1821 - val_mae: 1.1821 - val_mse: 20.4823 - learning_rate: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 773.1189 - mae: 773.1189 - mse: 1816194.7500 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 20.5480 - learning_rate: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 771.8055 - mae: 771.8055 - mse: 1814233.2500 - val_loss: 1.1818 - val_mae: 1.1818 - val_mse: 20.4100 - learning_rate: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 774.2386 - mae: 774.2386 - mse: 1818681.0000 - val_loss: 1.1835 - val_mae: 1.1835 - val_mse: 20.5588 - learning_rate: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 772.4353 - mae: 772.4353 - mse: 1817432.5000 - val_loss: 1.1817 - val_mae: 1.1817 - val_mse: 20.3557 - learning_rate: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 775.1678 - mae: 775.1678 - mse: 1821274.1250 - val_loss: 1.1836 - val_mae: 1.1836 - val_mse: 20.5540 - learning_rate: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 772.8582 - mae: 772.8582 - mse: 1819870.5000 - val_loss: 1.1823 - val_mae: 1.1823 - val_mse: 20.2916 - learning_rate: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 778.9391 - mae: 778.9391 - mse: 1833806.5000 - val_loss: 1.1851 - val_mae: 1.1851 - val_mse: 20.5895 - learning_rate: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 777.3935 - mae: 777.3935 - mse: 1837237.6250 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 20.2203 - learning_rate: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 787.7971 - mae: 787.7971 - mse: 1865203.0000 - val_loss: 1.1881 - val_mae: 1.1881 - val_mse: 20.6527 - learning_rate: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 787.7190 - mae: 787.7190 - mse: 1875669.0000 - val_loss: 1.1873 - val_mae: 1.1873 - val_mse: 20.1523 - learning_rate: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.6631 - mae: 804.6631 - mse: 1927095.0000 - val_loss: 1.1892 - val_mae: 1.1892 - val_mse: 20.6575 - learning_rate: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 793.6011 - mae: 793.6011 - mse: 1896748.5000 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 20.1150 - learning_rate: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 810.4398 - mae: 810.4398 - mse: 1949266.0000 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 20.6202 - learning_rate: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 794.3348 - mae: 794.3348 - mse: 1898831.3750 - val_loss: 1.1857 - val_mae: 1.1857 - val_mse: 20.0950 - learning_rate: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 801.5973 - mae: 801.5973 - mse: 1915937.0000 - val_loss: 1.1836 - val_mae: 1.1836 - val_mse: 20.4965 - learning_rate: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 782.7320 - mae: 782.7320 - mse: 1855738.1250 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 20.1194 - learning_rate: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 777.6166 - mae: 777.6166 - mse: 1828899.2500 - val_loss: 1.1777 - val_mae: 1.1777 - val_mse: 20.3103 - learning_rate: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 766.6555 - mae: 766.6555 - mse: 1796002.0000 - val_loss: 1.1764 - val_mae: 1.1764 - val_mse: 20.1627 - learning_rate: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 765.7800 - mae: 765.7800 - mse: 1788644.6250 - val_loss: 1.1757 - val_mae: 1.1757 - val_mse: 20.1953 - learning_rate: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 763.6674 - mae: 763.6674 - mse: 1781986.5000 - val_loss: 1.1754 - val_mae: 1.1754 - val_mse: 20.1985 - learning_rate: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 762.9308 - mae: 762.9308 - mse: 1780486.0000 - val_loss: 1.1752 - val_mae: 1.1752 - val_mse: 20.1374 - learning_rate: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 763.4392 - mae: 763.4392 - mse: 1780988.6250 - val_loss: 1.1749 - val_mae: 1.1749 - val_mse: 20.1869 - learning_rate: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 762.2415 - mae: 762.2415 - mse: 1779046.0000 - val_loss: 1.1749 - val_mae: 1.1749 - val_mse: 20.0924 - learning_rate: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 763.4408 - mae: 763.4408 - mse: 1780902.5000 - val_loss: 1.1744 - val_mae: 1.1744 - val_mse: 20.1699 - learning_rate: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 761.7638 - mae: 761.7638 - mse: 1777945.6250 - val_loss: 1.1744 - val_mae: 1.1744 - val_mse: 20.0737 - learning_rate: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 762.0362 - mae: 762.0362 - mse: 1776339.3750 - val_loss: 1.1739 - val_mae: 1.1739 - val_mse: 20.1377 - learning_rate: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 760.6444 - mae: 760.6444 - mse: 1774061.1250 - val_loss: 1.1741 - val_mae: 1.1741 - val_mse: 20.0466 - learning_rate: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 761.3481 - mae: 761.3481 - mse: 1774000.3750 - val_loss: 1.1735 - val_mae: 1.1735 - val_mse: 20.1167 - learning_rate: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 759.8687 - mae: 759.8687 - mse: 1771926.7500 - val_loss: 1.1739 - val_mae: 1.1739 - val_mse: 20.0191 - learning_rate: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 760.7418 - mae: 760.7418 - mse: 1771997.2500 - val_loss: 1.1730 - val_mae: 1.1730 - val_mse: 20.0904 - learning_rate: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 758.9204 - mae: 758.9204 - mse: 1768938.0000 - val_loss: 1.1736 - val_mae: 1.1736 - val_mse: 19.9973 - learning_rate: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 759.8428 - mae: 759.8428 - mse: 1769177.5000 - val_loss: 1.1726 - val_mae: 1.1726 - val_mse: 20.0662 - learning_rate: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 758.0344 - mae: 758.0344 - mse: 1766216.3750 - val_loss: 1.1733 - val_mae: 1.1733 - val_mse: 19.9786 - learning_rate: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 758.8016 - mae: 758.8016 - mse: 1765948.0000 - val_loss: 1.1722 - val_mae: 1.1722 - val_mse: 20.0416 - learning_rate: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 757.1049 - mae: 757.1049 - mse: 1763376.6250 - val_loss: 1.1733 - val_mae: 1.1733 - val_mse: 19.9482 - learning_rate: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 758.6476 - mae: 758.6476 - mse: 1765541.1250 - val_loss: 1.1721 - val_mae: 1.1721 - val_mse: 20.0428 - learning_rate: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 757.3373 - mae: 757.3373 - mse: 1765231.2500 - val_loss: 1.1747 - val_mae: 1.1747 - val_mse: 19.8874 - learning_rate: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 763.1754 - mae: 763.1754 - mse: 1781073.5000 - val_loss: 1.1734 - val_mae: 1.1734 - val_mse: 20.1030 - learning_rate: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 764.1791 - mae: 764.1791 - mse: 1789849.3750 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 19.8220 - learning_rate: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 779.1216 - mae: 779.1216 - mse: 1836990.7500 - val_loss: 1.1787 - val_mae: 1.1787 - val_mse: 20.2438 - learning_rate: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 787.2551 - mae: 787.2551 - mse: 1873795.3750 - val_loss: 1.1904 - val_mae: 1.1904 - val_mse: 19.7839 - learning_rate: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 815.4506 - mae: 815.4506 - mse: 1972056.8750 - val_loss: 1.1846 - val_mae: 1.1846 - val_mse: 20.3554 - learning_rate: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 812.8449 - mae: 812.8449 - mse: 1968070.0000 - val_loss: 1.1905 - val_mae: 1.1905 - val_mse: 19.7676 - learning_rate: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 816.9529 - mae: 816.9529 - mse: 1977414.2500 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 20.2360 - learning_rate: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 795.0857 - mae: 795.0857 - mse: 1901630.5000 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 19.7519 - learning_rate: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 795.5555 - mae: 795.5555 - mse: 1896537.8750 - val_loss: 1.1757 - val_mae: 1.1757 - val_mse: 20.1332 - learning_rate: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 780.8534 - mae: 780.8534 - mse: 1849680.2500 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 19.7417 - learning_rate: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 781.8680 - mae: 781.8680 - mse: 1846474.8750 - val_loss: 1.1742 - val_mae: 1.1742 - val_mse: 20.0804 - learning_rate: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 775.0540 - mae: 775.0540 - mse: 1829213.3750 - val_loss: 1.1808 - val_mae: 1.1808 - val_mse: 19.7240 - learning_rate: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 785.3881 - mae: 785.3881 - mse: 1859252.0000 - val_loss: 1.1753 - val_mae: 1.1753 - val_mse: 20.1074 - learning_rate: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 782.0716 - mae: 782.0716 - mse: 1854612.6250 - val_loss: 1.1826 - val_mae: 1.1826 - val_mse: 19.7092 - learning_rate: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 790.7326 - mae: 790.7326 - mse: 1878913.2500 - val_loss: 1.1753 - val_mae: 1.1753 - val_mse: 20.0986 - learning_rate: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 783.5009 - mae: 783.5009 - mse: 1859850.7500 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 19.6973 - learning_rate: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 788.6663 - mae: 788.6663 - mse: 1871361.0000 - val_loss: 1.1741 - val_mae: 1.1741 - val_mse: 20.0630 - learning_rate: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 780.1804 - mae: 780.1804 - mse: 1847708.0000 - val_loss: 1.1808 - val_mae: 1.1808 - val_mse: 19.6861 - learning_rate: 1.0000e-04\n",
            "Epoch 244/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 784.8819 - mae: 784.8819 - mse: 1857666.8750 - val_loss: 1.1731 - val_mae: 1.1731 - val_mse: 20.0325 - learning_rate: 1.0000e-04\n",
            "Epoch 245/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 777.4049 - mae: 777.4049 - mse: 1837671.8750 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 19.6755 - learning_rate: 1.0000e-04\n",
            "Epoch 246/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 781.3665 - mae: 781.3665 - mse: 1845040.5000 - val_loss: 1.1722 - val_mae: 1.1722 - val_mse: 20.0053 - learning_rate: 1.0000e-04\n",
            "Epoch 247/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 775.1108 - mae: 775.1108 - mse: 1829536.7500 - val_loss: 1.1795 - val_mae: 1.1795 - val_mse: 19.6637 - learning_rate: 1.0000e-04\n",
            "Epoch 248/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 780.5902 - mae: 780.5902 - mse: 1842257.5000 - val_loss: 1.1717 - val_mae: 1.1717 - val_mse: 19.9879 - learning_rate: 1.0000e-04\n",
            "Epoch 249/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 774.4268 - mae: 774.4268 - mse: 1827154.8750 - val_loss: 1.1795 - val_mae: 1.1795 - val_mse: 19.6506 - learning_rate: 1.0000e-04\n",
            "Epoch 250/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 780.6901 - mae: 780.6901 - mse: 1842613.0000 - val_loss: 1.1720 - val_mae: 1.1720 - val_mse: 19.9911 - learning_rate: 1.0000e-04\n",
            "Epoch 251/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 777.4219 - mae: 777.4219 - mse: 1838083.7500 - val_loss: 1.1802 - val_mae: 1.1802 - val_mse: 19.6385 - learning_rate: 1.0000e-04\n",
            "Epoch 252/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 782.8953 - mae: 782.8953 - mse: 1850244.6250 - val_loss: 1.1722 - val_mae: 1.1722 - val_mse: 19.9909 - learning_rate: 1.0000e-04\n",
            "Epoch 253/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 779.7925 - mae: 779.7925 - mse: 1846835.6250 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 19.6268 - learning_rate: 1.0000e-04\n",
            "Epoch 254/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 781.2308 - mae: 781.2308 - mse: 1844173.2500 - val_loss: 1.1709 - val_mae: 1.1709 - val_mse: 19.9550 - learning_rate: 1.0000e-04\n",
            "Epoch 255/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 775.4241 - mae: 775.4241 - mse: 1830808.5000 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 19.6155 - learning_rate: 1.0000e-04\n",
            "Epoch 256/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 779.4384 - mae: 779.4384 - mse: 1837648.7500 - val_loss: 1.1707 - val_mae: 1.1707 - val_mse: 19.9457 - learning_rate: 1.0000e-04\n",
            "Epoch 257/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 775.7996 - mae: 775.7996 - mse: 1832270.3750 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 19.6033 - learning_rate: 1.0000e-04\n",
            "Epoch 258/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 780.0018 - mae: 780.0018 - mse: 1839400.6250 - val_loss: 1.1705 - val_mae: 1.1705 - val_mse: 19.9335 - learning_rate: 1.0000e-04\n",
            "Epoch 259/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 775.8237 - mae: 775.8237 - mse: 1832461.0000 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 19.5904 - learning_rate: 1.0000e-04\n",
            "Epoch 260/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 779.3936 - mae: 779.3936 - mse: 1837054.0000 - val_loss: 1.1700 - val_mae: 1.1700 - val_mse: 19.9144 - learning_rate: 1.0000e-04\n",
            "Epoch 261/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 774.8688 - mae: 774.8688 - mse: 1829003.8750 - val_loss: 1.1791 - val_mae: 1.1791 - val_mse: 19.5772 - learning_rate: 1.0000e-04\n",
            "Epoch 262/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 777.4124 - mae: 777.4124 - mse: 1829876.3750 - val_loss: 1.1693 - val_mae: 1.1693 - val_mse: 19.8883 - learning_rate: 1.0000e-04\n",
            "Epoch 263/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 772.7800 - mae: 772.7800 - mse: 1821506.0000 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 19.5614 - learning_rate: 1.0000e-04\n",
            "Epoch 264/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 778.1732 - mae: 778.1732 - mse: 1832397.7500 - val_loss: 1.1698 - val_mae: 1.1698 - val_mse: 19.8936 - learning_rate: 1.0000e-04\n",
            "Epoch 265/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 776.6280 - mae: 776.6280 - mse: 1836002.7500 - val_loss: 1.1802 - val_mae: 1.1802 - val_mse: 19.5470 - learning_rate: 1.0000e-04\n",
            "Epoch 266/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 781.1666 - mae: 781.1666 - mse: 1842693.2500 - val_loss: 1.1703 - val_mae: 1.1703 - val_mse: 19.8969 - learning_rate: 1.0000e-04\n",
            "Epoch 267/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 779.6627 - mae: 779.6627 - mse: 1847465.3750 - val_loss: 1.1827 - val_mae: 1.1827 - val_mse: 19.5360 - learning_rate: 1.0000e-04\n",
            "Epoch 268/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 788.6091 - mae: 788.6091 - mse: 1868741.5000 - val_loss: 1.1724 - val_mae: 1.1724 - val_mse: 19.9334 - learning_rate: 1.0000e-04\n",
            "Epoch 269/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 789.6172 - mae: 789.6172 - mse: 1883775.8750 - val_loss: 1.1865 - val_mae: 1.1865 - val_mse: 19.5305 - learning_rate: 1.0000e-04\n",
            "Epoch 270/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.6723 - mae: 800.6723 - mse: 1911760.8750 - val_loss: 1.1740 - val_mae: 1.1740 - val_mse: 19.9578 - learning_rate: 1.0000e-04\n",
            "Epoch 271/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 797.7094 - mae: 797.7094 - mse: 1913545.0000 - val_loss: 1.1862 - val_mae: 1.1862 - val_mse: 19.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 272/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.5516 - mae: 799.5516 - mse: 1907356.0000 - val_loss: 1.1723 - val_mae: 1.1723 - val_mse: 19.9199 - learning_rate: 1.0000e-04\n",
            "Epoch 273/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 792.4775 - mae: 792.4775 - mse: 1894310.6250 - val_loss: 1.1856 - val_mae: 1.1856 - val_mse: 19.5051 - learning_rate: 1.0000e-04\n",
            "Epoch 274/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.5410 - mae: 797.5410 - mse: 1899966.1250 - val_loss: 1.1723 - val_mae: 1.1723 - val_mse: 19.9120 - learning_rate: 1.0000e-04\n",
            "Epoch 275/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 793.7689 - mae: 793.7689 - mse: 1899193.0000 - val_loss: 1.1861 - val_mae: 1.1861 - val_mse: 19.4938 - learning_rate: 1.0000e-04\n",
            "Epoch 276/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.0306 - mae: 799.0306 - mse: 1905110.6250 - val_loss: 1.1720 - val_mae: 1.1720 - val_mse: 19.8966 - learning_rate: 1.0000e-04\n",
            "Epoch 277/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 793.7096 - mae: 793.7096 - mse: 1899022.8750 - val_loss: 1.1854 - val_mae: 1.1854 - val_mse: 19.4797 - learning_rate: 1.0000e-04\n",
            "Epoch 278/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.7372 - mae: 796.7372 - mse: 1896625.5000 - val_loss: 1.1711 - val_mae: 1.1711 - val_mse: 19.8731 - learning_rate: 1.0000e-04\n",
            "Epoch 279/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.4733 - mae: 791.4733 - mse: 1890879.0000 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 19.4682 - learning_rate: 1.0000e-04\n",
            "Epoch 280/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 795.1278 - mae: 795.1278 - mse: 1890641.5000 - val_loss: 1.1706 - val_mae: 1.1706 - val_mse: 19.8569 - learning_rate: 1.0000e-04\n",
            "Epoch 281/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 790.1732 - mae: 790.1732 - mse: 1886283.5000 - val_loss: 1.1852 - val_mae: 1.1852 - val_mse: 19.4590 - learning_rate: 1.0000e-04\n",
            "Epoch 282/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 796.1335 - mae: 796.1335 - mse: 1893950.5000 - val_loss: 1.1708 - val_mae: 1.1708 - val_mse: 19.8554 - learning_rate: 1.0000e-04\n",
            "Epoch 283/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 792.1475 - mae: 792.1475 - mse: 1893593.0000 - val_loss: 1.1856 - val_mae: 1.1856 - val_mse: 19.4501 - learning_rate: 1.0000e-04\n",
            "Epoch 284/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 797.3708 - mae: 797.3708 - mse: 1898146.6250 - val_loss: 1.1711 - val_mae: 1.1711 - val_mse: 19.8553 - learning_rate: 1.0000e-04\n",
            "Epoch 285/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 794.3396 - mae: 794.3396 - mse: 1901820.3750 - val_loss: 1.1867 - val_mae: 1.1867 - val_mse: 19.4418 - learning_rate: 1.0000e-04\n",
            "Epoch 286/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.9968 - mae: 800.9968 - mse: 1910921.6250 - val_loss: 1.1709 - val_mae: 1.1709 - val_mse: 19.8417 - learning_rate: 1.0000e-04\n",
            "Epoch 287/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 794.9723 - mae: 794.9723 - mse: 1904242.0000 - val_loss: 1.1861 - val_mae: 1.1861 - val_mse: 19.4272 - learning_rate: 1.0000e-04\n",
            "Epoch 288/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.1971 - mae: 799.1971 - mse: 1904166.3750 - val_loss: 1.1699 - val_mae: 1.1699 - val_mse: 19.8100 - learning_rate: 1.0000e-04\n",
            "Epoch 289/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.5114 - mae: 791.5114 - mse: 1891429.1250 - val_loss: 1.1844 - val_mae: 1.1844 - val_mse: 19.4113 - learning_rate: 1.0000e-04\n",
            "Epoch 290/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 793.3820 - mae: 793.3820 - mse: 1883156.3750 - val_loss: 1.1686 - val_mae: 1.1686 - val_mse: 19.7758 - learning_rate: 1.0000e-04\n",
            "Epoch 291/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 786.5682 - mae: 786.5682 - mse: 1873486.3750 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 19.3992 - learning_rate: 1.0000e-04\n",
            "Epoch 292/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 792.8878 - mae: 792.8878 - mse: 1881200.7500 - val_loss: 1.1689 - val_mae: 1.1689 - val_mse: 19.7758 - learning_rate: 1.0000e-04\n",
            "Epoch 293/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 789.1636 - mae: 789.1636 - mse: 1883063.6250 - val_loss: 1.1845 - val_mae: 1.1845 - val_mse: 19.3887 - learning_rate: 1.0000e-04\n",
            "Epoch 294/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 793.9943 - mae: 793.9943 - mse: 1884944.6250 - val_loss: 1.1693 - val_mae: 1.1693 - val_mse: 19.7766 - learning_rate: 1.0000e-04\n",
            "Epoch 295/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 791.6445 - mae: 791.6445 - mse: 1892436.0000 - val_loss: 1.1860 - val_mae: 1.1860 - val_mse: 19.3808 - learning_rate: 1.0000e-04\n",
            "Epoch 296/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.6992 - mae: 798.6992 - mse: 1901499.1250 - val_loss: 1.1699 - val_mae: 1.1699 - val_mse: 19.7772 - learning_rate: 1.0000e-04\n",
            "Epoch 297/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.1508 - mae: 795.1508 - mse: 1905626.6250 - val_loss: 1.1871 - val_mae: 1.1871 - val_mse: 19.3720 - learning_rate: 1.0000e-04\n",
            "Epoch 298/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 802.5876 - mae: 802.5876 - mse: 1915173.2500 - val_loss: 1.1692 - val_mae: 1.1692 - val_mse: 19.7506 - learning_rate: 1.0000e-04\n",
            "Epoch 299/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 792.9349 - mae: 792.9349 - mse: 1897212.6250 - val_loss: 1.1848 - val_mae: 1.1848 - val_mse: 19.3540 - learning_rate: 1.0000e-04\n",
            "Epoch 300/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 794.5587 - mae: 794.5587 - mse: 1886259.0000 - val_loss: 1.1687 - val_mae: 1.1687 - val_mse: 19.7293 - learning_rate: 1.0000e-04\n",
            "Epoch 301/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.1947 - mae: 791.1947 - mse: 1891012.2500 - val_loss: 1.1856 - val_mae: 1.1856 - val_mse: 19.3449 - learning_rate: 1.0000e-04\n",
            "Epoch 302/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 797.0602 - mae: 797.0602 - mse: 1894963.3750 - val_loss: 1.1688 - val_mae: 1.1688 - val_mse: 19.7232 - learning_rate: 1.0000e-04\n",
            "Epoch 303/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 792.4741 - mae: 792.4741 - mse: 1895855.7500 - val_loss: 1.1859 - val_mae: 1.1859 - val_mse: 19.3339 - learning_rate: 1.0000e-04\n",
            "Epoch 304/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.1204 - mae: 798.1204 - mse: 1898570.5000 - val_loss: 1.1690 - val_mae: 1.1690 - val_mse: 19.7189 - learning_rate: 1.0000e-04\n",
            "Epoch 305/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 794.4216 - mae: 794.4216 - mse: 1903398.0000 - val_loss: 1.1873 - val_mae: 1.1873 - val_mse: 19.3260 - learning_rate: 1.0000e-04\n",
            "Epoch 306/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 802.9396 - mae: 802.9396 - mse: 1915903.5000 - val_loss: 1.1692 - val_mae: 1.1692 - val_mse: 19.7121 - learning_rate: 1.0000e-04\n",
            "Epoch 307/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.0923 - mae: 796.0923 - mse: 1909598.0000 - val_loss: 1.1874 - val_mae: 1.1874 - val_mse: 19.3150 - learning_rate: 1.0000e-04\n",
            "Epoch 308/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.4622 - mae: 803.4622 - mse: 1917611.2500 - val_loss: 1.1689 - val_mae: 1.1689 - val_mse: 19.6955 - learning_rate: 1.0000e-04\n",
            "Epoch 309/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.6389 - mae: 795.6389 - mse: 1907950.3750 - val_loss: 1.1872 - val_mae: 1.1872 - val_mse: 19.3043 - learning_rate: 1.0000e-04\n",
            "Epoch 310/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 802.4725 - mae: 802.4725 - mse: 1913816.5000 - val_loss: 1.1689 - val_mae: 1.1689 - val_mse: 19.6852 - learning_rate: 1.0000e-04\n",
            "Epoch 311/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 796.1038 - mae: 796.1038 - mse: 1909680.2500 - val_loss: 1.1871 - val_mae: 1.1871 - val_mse: 19.2951 - learning_rate: 1.0000e-04\n",
            "Epoch 312/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.8064 - mae: 801.8064 - mse: 1911194.1250 - val_loss: 1.1688 - val_mae: 1.1688 - val_mse: 19.6736 - learning_rate: 1.0000e-04\n",
            "Epoch 313/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.0683 - mae: 796.0683 - mse: 1909613.3750 - val_loss: 1.1876 - val_mae: 1.1876 - val_mse: 19.2892 - learning_rate: 1.0000e-04\n",
            "Epoch 314/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.0898 - mae: 803.0898 - mse: 1915697.0000 - val_loss: 1.1695 - val_mae: 1.1695 - val_mse: 19.6793 - learning_rate: 1.0000e-04\n",
            "Epoch 315/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.4036 - mae: 799.4036 - mse: 1922085.1250 - val_loss: 1.1890 - val_mae: 1.1890 - val_mse: 19.2883 - learning_rate: 1.0000e-04\n",
            "Epoch 316/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 807.4044 - mae: 807.4044 - mse: 1931067.2500 - val_loss: 1.1699 - val_mae: 1.1699 - val_mse: 19.6799 - learning_rate: 1.0000e-04\n",
            "Epoch 317/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.4435 - mae: 801.4435 - mse: 1929671.0000 - val_loss: 1.1886 - val_mae: 1.1886 - val_mse: 19.2806 - learning_rate: 1.0000e-04\n",
            "Epoch 318/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.3175 - mae: 805.3175 - mse: 1923292.8750 - val_loss: 1.1694 - val_mae: 1.1694 - val_mse: 19.6612 - learning_rate: 1.0000e-04\n",
            "Epoch 319/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.1931 - mae: 799.1931 - mse: 1921262.3750 - val_loss: 1.1885 - val_mae: 1.1885 - val_mse: 19.2744 - learning_rate: 1.0000e-04\n",
            "Epoch 320/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804.0723 - mae: 804.0723 - mse: 1918651.1250 - val_loss: 1.1698 - val_mae: 1.1698 - val_mse: 19.6593 - learning_rate: 1.0000e-04\n",
            "Epoch 321/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 800.7631 - mae: 800.7631 - mse: 1927151.0000 - val_loss: 1.1892 - val_mae: 1.1892 - val_mse: 19.2717 - learning_rate: 1.0000e-04\n",
            "Epoch 322/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.4403 - mae: 805.4403 - mse: 1923342.1250 - val_loss: 1.1695 - val_mae: 1.1695 - val_mse: 19.6447 - learning_rate: 1.0000e-04\n",
            "Epoch 323/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.1517 - mae: 799.1517 - mse: 1921083.7500 - val_loss: 1.1894 - val_mae: 1.1894 - val_mse: 19.2681 - learning_rate: 1.0000e-04\n",
            "Epoch 324/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 804.8659 - mae: 804.8659 - mse: 1921038.1250 - val_loss: 1.1696 - val_mae: 1.1696 - val_mse: 19.6372 - learning_rate: 1.0000e-04\n",
            "Epoch 325/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 799.2681 - mae: 799.2681 - mse: 1921471.8750 - val_loss: 1.1897 - val_mae: 1.1897 - val_mse: 19.2660 - learning_rate: 1.0000e-04\n",
            "Epoch 326/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 805.1466 - mae: 805.1466 - mse: 1921769.2500 - val_loss: 1.1698 - val_mae: 1.1698 - val_mse: 19.6319 - learning_rate: 1.0000e-04\n",
            "Epoch 327/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 799.8689 - mae: 799.8689 - mse: 1923827.3750 - val_loss: 1.1905 - val_mae: 1.1905 - val_mse: 19.2642 - learning_rate: 1.0000e-04\n",
            "Epoch 328/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.2034 - mae: 807.2034 - mse: 1928898.7500 - val_loss: 1.1700 - val_mae: 1.1700 - val_mse: 19.6268 - learning_rate: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 800.7108 - mae: 800.7108 - mse: 1927103.7500 - val_loss: 1.1923 - val_mae: 1.1923 - val_mse: 19.2637 - learning_rate: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 812.1461 - mae: 812.1461 - mse: 1946720.7500 - val_loss: 1.1710 - val_mae: 1.1710 - val_mse: 19.6368 - learning_rate: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.3315 - mae: 805.3315 - mse: 1944223.2500 - val_loss: 1.1969 - val_mae: 1.1969 - val_mse: 19.2757 - learning_rate: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 825.4540 - mae: 825.4540 - mse: 1996420.6250 - val_loss: 1.1715 - val_mae: 1.1715 - val_mse: 19.6421 - learning_rate: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 808.9013 - mae: 808.9013 - mse: 1956821.6250 - val_loss: 1.1947 - val_mae: 1.1947 - val_mse: 19.2616 - learning_rate: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.9701 - mae: 819.9701 - mse: 1975113.6250 - val_loss: 1.1691 - val_mae: 1.1691 - val_mse: 19.5991 - learning_rate: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.8493 - mae: 799.8493 - mse: 1923489.3750 - val_loss: 1.1899 - val_mae: 1.1899 - val_mse: 19.2371 - learning_rate: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 806.2847 - mae: 806.2847 - mse: 1924605.5000 - val_loss: 1.1687 - val_mae: 1.1687 - val_mse: 19.5910 - learning_rate: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 799.0860 - mae: 799.0860 - mse: 1921095.0000 - val_loss: 1.1916 - val_mae: 1.1916 - val_mse: 19.2365 - learning_rate: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 811.2740 - mae: 811.2740 - mse: 1942794.1250 - val_loss: 1.1702 - val_mae: 1.1702 - val_mse: 19.6105 - learning_rate: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 805.6495 - mae: 805.6495 - mse: 1945533.7500 - val_loss: 1.1978 - val_mae: 1.1978 - val_mse: 19.2548 - learning_rate: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 829.5394 - mae: 829.5394 - mse: 2011439.8750 - val_loss: 1.1698 - val_mae: 1.1698 - val_mse: 19.6029 - learning_rate: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.8585 - mae: 805.8585 - mse: 1945904.0000 - val_loss: 1.1937 - val_mae: 1.1937 - val_mse: 19.2303 - learning_rate: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 818.7706 - mae: 818.7706 - mse: 1970174.8750 - val_loss: 1.1682 - val_mae: 1.1682 - val_mse: 19.5742 - learning_rate: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.2408 - mae: 800.2408 - mse: 1925597.6250 - val_loss: 1.1913 - val_mae: 1.1913 - val_mse: 19.2120 - learning_rate: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 812.2858 - mae: 812.2858 - mse: 1946130.5000 - val_loss: 1.1690 - val_mae: 1.1690 - val_mse: 19.5832 - learning_rate: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 804.4036 - mae: 804.4036 - mse: 1941227.0000 - val_loss: 1.1955 - val_mae: 1.1955 - val_mse: 19.2199 - learning_rate: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 824.9735 - mae: 824.9735 - mse: 1993799.6250 - val_loss: 1.1697 - val_mae: 1.1697 - val_mse: 19.5915 - learning_rate: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 809.3027 - mae: 809.3027 - mse: 1958770.7500 - val_loss: 1.1929 - val_mae: 1.1929 - val_mse: 19.2002 - learning_rate: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 818.6663 - mae: 818.6663 - mse: 1969498.5000 - val_loss: 1.1668 - val_mae: 1.1668 - val_mse: 19.5370 - learning_rate: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 797.9093 - mae: 797.9093 - mse: 1917286.7500 - val_loss: 1.1878 - val_mae: 1.1878 - val_mse: 19.1686 - learning_rate: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 804.3341 - mae: 804.3341 - mse: 1916899.6250 - val_loss: 1.1668 - val_mae: 1.1668 - val_mse: 19.5311 - learning_rate: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 798.3173 - mae: 798.3173 - mse: 1919535.6250 - val_loss: 1.1927 - val_mae: 1.1927 - val_mse: 19.1776 - learning_rate: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 819.2152 - mae: 819.2152 - mse: 1971580.7500 - val_loss: 1.1683 - val_mae: 1.1683 - val_mse: 19.5522 - learning_rate: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 806.6116 - mae: 806.6116 - mse: 1949483.5000 - val_loss: 1.1937 - val_mae: 1.1937 - val_mse: 19.1694 - learning_rate: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 823.5378 - mae: 823.5378 - mse: 1987808.0000 - val_loss: 1.1676 - val_mae: 1.1676 - val_mse: 19.5358 - learning_rate: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 806.8792 - mae: 806.8792 - mse: 1950459.7500 - val_loss: 1.1922 - val_mae: 1.1922 - val_mse: 19.1493 - learning_rate: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 821.1308 - mae: 821.1308 - mse: 1978365.2500 - val_loss: 1.1653 - val_mae: 1.1653 - val_mse: 19.4869 - learning_rate: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 798.9636 - mae: 798.9636 - mse: 1921938.0000 - val_loss: 1.1893 - val_mae: 1.1893 - val_mse: 19.1210 - learning_rate: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 814.7802 - mae: 814.7802 - mse: 1954393.3750 - val_loss: 1.1649 - val_mae: 1.1649 - val_mse: 19.4713 - learning_rate: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 799.6646 - mae: 799.6646 - mse: 1924781.0000 - val_loss: 1.1904 - val_mae: 1.1904 - val_mse: 19.1081 - learning_rate: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 819.8521 - mae: 819.8521 - mse: 1973309.5000 - val_loss: 1.1647 - val_mae: 1.1647 - val_mse: 19.4584 - learning_rate: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 802.0012 - mae: 802.0012 - mse: 1933259.6250 - val_loss: 1.1898 - val_mae: 1.1898 - val_mse: 19.0901 - learning_rate: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 820.1528 - mae: 820.1528 - mse: 1974371.5000 - val_loss: 1.1650 - val_mae: 1.1650 - val_mse: 19.4524 - learning_rate: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 805.9119 - mae: 805.9119 - mse: 1947528.7500 - val_loss: 1.1904 - val_mae: 1.1904 - val_mse: 19.0779 - learning_rate: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 823.4015 - mae: 823.4015 - mse: 1986333.6250 - val_loss: 1.1640 - val_mae: 1.1640 - val_mse: 19.4259 - learning_rate: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 804.5502 - mae: 804.5502 - mse: 1942792.6250 - val_loss: 1.1891 - val_mae: 1.1891 - val_mse: 19.0591 - learning_rate: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 821.1973 - mae: 821.1973 - mse: 1977721.8750 - val_loss: 1.1630 - val_mae: 1.1630 - val_mse: 19.3973 - learning_rate: 1.0000e-04\n",
            "Epoch 367/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 802.3887 - mae: 802.3887 - mse: 1935258.8750 - val_loss: 1.1881 - val_mae: 1.1881 - val_mse: 19.0401 - learning_rate: 1.0000e-04\n",
            "Epoch 368/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.4686 - mae: 819.4686 - mse: 1971030.6250 - val_loss: 1.1631 - val_mae: 1.1631 - val_mse: 19.3848 - learning_rate: 1.0000e-04\n",
            "Epoch 369/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.9103 - mae: 804.9103 - mse: 1944729.6250 - val_loss: 1.1898 - val_mae: 1.1898 - val_mse: 19.0324 - learning_rate: 1.0000e-04\n",
            "Epoch 370/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 825.3398 - mae: 825.3398 - mse: 1992828.0000 - val_loss: 1.1627 - val_mae: 1.1627 - val_mse: 19.3627 - learning_rate: 1.0000e-04\n",
            "Epoch 371/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804.9193 - mae: 804.9193 - mse: 1944761.3750 - val_loss: 1.1885 - val_mae: 1.1885 - val_mse: 19.0134 - learning_rate: 1.0000e-04\n",
            "Epoch 372/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 822.3786 - mae: 822.3786 - mse: 1981340.6250 - val_loss: 1.1627 - val_mae: 1.1627 - val_mse: 19.3485 - learning_rate: 1.0000e-04\n",
            "Epoch 373/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 806.7070 - mae: 806.7070 - mse: 1951333.5000 - val_loss: 1.1891 - val_mae: 1.1891 - val_mse: 19.0030 - learning_rate: 1.0000e-04\n",
            "Epoch 374/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 824.8252 - mae: 824.8252 - mse: 1990107.8750 - val_loss: 1.1616 - val_mae: 1.1616 - val_mse: 19.3164 - learning_rate: 1.0000e-04\n",
            "Epoch 375/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.3722 - mae: 803.3722 - mse: 1939162.5000 - val_loss: 1.1869 - val_mae: 1.1869 - val_mse: 18.9786 - learning_rate: 1.0000e-04\n",
            "Epoch 376/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 819.4998 - mae: 819.4998 - mse: 1969866.1250 - val_loss: 1.1615 - val_mae: 1.1615 - val_mse: 19.3030 - learning_rate: 1.0000e-04\n",
            "Epoch 377/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 804.2197 - mae: 804.2197 - mse: 1942470.8750 - val_loss: 1.1883 - val_mae: 1.1883 - val_mse: 18.9736 - learning_rate: 1.0000e-04\n",
            "Epoch 378/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 823.7672 - mae: 823.7672 - mse: 1985563.2500 - val_loss: 1.1615 - val_mae: 1.1615 - val_mse: 19.2933 - learning_rate: 1.0000e-04\n",
            "Epoch 379/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 805.4702 - mae: 805.4702 - mse: 1947034.2500 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.9683 - learning_rate: 1.0000e-04\n",
            "Epoch 380/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 825.5017 - mae: 825.5017 - mse: 1991821.2500 - val_loss: 1.1609 - val_mae: 1.1609 - val_mse: 19.2742 - learning_rate: 1.0000e-04\n",
            "Epoch 381/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.5730 - mae: 803.5730 - mse: 1940137.2500 - val_loss: 1.1878 - val_mae: 1.1878 - val_mse: 18.9552 - learning_rate: 1.0000e-04\n",
            "Epoch 382/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 822.6612 - mae: 822.6612 - mse: 1980955.2500 - val_loss: 1.1613 - val_mae: 1.1613 - val_mse: 19.2712 - learning_rate: 1.0000e-04\n",
            "Epoch 383/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 806.0659 - mae: 806.0659 - mse: 1949121.0000 - val_loss: 1.1888 - val_mae: 1.1888 - val_mse: 18.9537 - learning_rate: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 825.4024 - mae: 825.4024 - mse: 1991022.5000 - val_loss: 1.1605 - val_mae: 1.1605 - val_mse: 19.2481 - learning_rate: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 803.0311 - mae: 803.0311 - mse: 1938013.2500 - val_loss: 1.1874 - val_mae: 1.1874 - val_mse: 18.9365 - learning_rate: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 821.6130 - mae: 821.6130 - mse: 1976707.0000 - val_loss: 1.1609 - val_mae: 1.1609 - val_mse: 19.2433 - learning_rate: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 805.4583 - mae: 805.4583 - mse: 1946825.0000 - val_loss: 1.1886 - val_mae: 1.1886 - val_mse: 18.9329 - learning_rate: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 825.2906 - mae: 825.2906 - mse: 1990297.1250 - val_loss: 1.1604 - val_mae: 1.1604 - val_mse: 19.2259 - learning_rate: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 804.2449 - mae: 804.2449 - mse: 1942251.5000 - val_loss: 1.1874 - val_mae: 1.1874 - val_mse: 18.9168 - learning_rate: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 822.1851 - mae: 822.1851 - mse: 1978502.0000 - val_loss: 1.1605 - val_mae: 1.1605 - val_mse: 19.2197 - learning_rate: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.4565 - mae: 805.4565 - mse: 1946786.1250 - val_loss: 1.1891 - val_mae: 1.1891 - val_mse: 18.9153 - learning_rate: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 827.5796 - mae: 827.5796 - mse: 1998687.3750 - val_loss: 1.1590 - val_mae: 1.1590 - val_mse: 19.1879 - learning_rate: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.8828 - mae: 799.8828 - mse: 1926372.7500 - val_loss: 1.1852 - val_mae: 1.1852 - val_mse: 18.8867 - learning_rate: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 816.9550 - mae: 816.9550 - mse: 1958771.1250 - val_loss: 1.1602 - val_mae: 1.1602 - val_mse: 19.1985 - learning_rate: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.6528 - mae: 805.6528 - mse: 1947518.2500 - val_loss: 1.1899 - val_mae: 1.1899 - val_mse: 18.9031 - learning_rate: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 830.6165 - mae: 830.6165 - mse: 2010269.2500 - val_loss: 1.1589 - val_mae: 1.1589 - val_mse: 19.1686 - learning_rate: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.5312 - mae: 801.5312 - mse: 1932119.3750 - val_loss: 1.1855 - val_mae: 1.1855 - val_mse: 18.8676 - learning_rate: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.3635 - mae: 819.3635 - mse: 1967491.1250 - val_loss: 1.1597 - val_mae: 1.1597 - val_mse: 19.1711 - learning_rate: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.7083 - mae: 805.7083 - mse: 1947601.5000 - val_loss: 1.1894 - val_mae: 1.1894 - val_mse: 18.8744 - learning_rate: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 830.9117 - mae: 830.9117 - mse: 2011159.6250 - val_loss: 1.1580 - val_mae: 1.1580 - val_mse: 19.1368 - learning_rate: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.7691 - mae: 799.7691 - mse: 1925654.5000 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 18.8367 - learning_rate: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 815.6810 - mae: 815.6810 - mse: 1953539.3750 - val_loss: 1.1592 - val_mae: 1.1592 - val_mse: 19.1467 - learning_rate: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 805.0262 - mae: 805.0262 - mse: 1945155.5000 - val_loss: 1.1899 - val_mae: 1.1899 - val_mse: 18.8600 - learning_rate: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 832.9551 - mae: 832.9551 - mse: 2019063.5000 - val_loss: 1.1588 - val_mae: 1.1588 - val_mse: 19.1319 - learning_rate: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 804.4627 - mae: 804.4627 - mse: 1942594.8750 - val_loss: 1.1868 - val_mae: 1.1868 - val_mse: 18.8378 - learning_rate: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 824.9475 - mae: 824.9475 - mse: 1987916.2500 - val_loss: 1.1578 - val_mae: 1.1578 - val_mse: 19.1081 - learning_rate: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.6105 - mae: 800.6105 - mse: 1928708.0000 - val_loss: 1.1850 - val_mae: 1.1850 - val_mse: 18.8208 - learning_rate: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.2101 - mae: 820.2101 - mse: 1969938.8750 - val_loss: 1.1584 - val_mae: 1.1584 - val_mse: 19.1104 - learning_rate: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 804.1336 - mae: 804.1336 - mse: 1941707.3750 - val_loss: 1.1887 - val_mae: 1.1887 - val_mse: 18.8301 - learning_rate: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 830.9865 - mae: 830.9865 - mse: 2010963.7500 - val_loss: 1.1576 - val_mae: 1.1576 - val_mse: 19.0905 - learning_rate: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.8384 - mae: 801.8384 - mse: 1932899.7500 - val_loss: 1.1847 - val_mae: 1.1847 - val_mse: 18.8024 - learning_rate: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.4398 - mae: 820.4398 - mse: 1970474.2500 - val_loss: 1.1575 - val_mae: 1.1575 - val_mse: 19.0825 - learning_rate: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 801.9021 - mae: 801.9021 - mse: 1933405.1250 - val_loss: 1.1865 - val_mae: 1.1865 - val_mse: 18.8034 - learning_rate: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 825.9767 - mae: 825.9767 - mse: 1991350.7500 - val_loss: 1.1565 - val_mae: 1.1565 - val_mse: 19.0618 - learning_rate: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 798.9607 - mae: 798.9607 - mse: 1922610.0000 - val_loss: 1.1844 - val_mae: 1.1844 - val_mse: 18.7850 - learning_rate: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.5485 - mae: 820.5485 - mse: 1970742.3750 - val_loss: 1.1577 - val_mae: 1.1577 - val_mse: 19.0736 - learning_rate: 1.0000e-04\n",
            "Epoch 417/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.4863 - mae: 804.4863 - mse: 1942827.7500 - val_loss: 1.1886 - val_mae: 1.1886 - val_mse: 18.8001 - learning_rate: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 832.4259 - mae: 832.4259 - mse: 2016181.7500 - val_loss: 1.1577 - val_mae: 1.1577 - val_mse: 19.0668 - learning_rate: 1.0000e-04\n",
            "Epoch 419/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 805.2216 - mae: 805.2216 - mse: 1945139.5000 - val_loss: 1.1860 - val_mae: 1.1860 - val_mse: 18.7799 - learning_rate: 1.0000e-04\n",
            "Epoch 420/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 825.8937 - mae: 825.8937 - mse: 1990675.0000 - val_loss: 1.1563 - val_mae: 1.1563 - val_mse: 19.0406 - learning_rate: 1.0000e-04\n",
            "Epoch 421/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 799.8754 - mae: 799.8754 - mse: 1925818.6250 - val_loss: 1.1855 - val_mae: 1.1855 - val_mse: 18.7721 - learning_rate: 1.0000e-04\n",
            "Epoch 422/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 824.7203 - mae: 824.7203 - mse: 1986198.1250 - val_loss: 1.1567 - val_mae: 1.1567 - val_mse: 19.0418 - learning_rate: 1.0000e-04\n",
            "Epoch 423/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 802.7067 - mae: 802.7067 - mse: 1936092.2500 - val_loss: 1.1866 - val_mae: 1.1866 - val_mse: 18.7703 - learning_rate: 1.0000e-04\n",
            "Epoch 424/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 828.2150 - mae: 828.2150 - mse: 1999398.6250 - val_loss: 1.1566 - val_mae: 1.1566 - val_mse: 19.0330 - learning_rate: 1.0000e-04\n",
            "Epoch 425/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.9208 - mae: 802.9208 - mse: 1936795.5000 - val_loss: 1.1860 - val_mae: 1.1860 - val_mse: 18.7578 - learning_rate: 1.0000e-04\n",
            "Epoch 426/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 827.2157 - mae: 827.2157 - mse: 1995381.7500 - val_loss: 1.1565 - val_mae: 1.1565 - val_mse: 19.0270 - learning_rate: 1.0000e-04\n",
            "Epoch 427/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.7134 - mae: 803.7134 - mse: 1939604.2500 - val_loss: 1.1854 - val_mae: 1.1854 - val_mse: 18.7466 - learning_rate: 1.0000e-04\n",
            "Epoch 428/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 826.4480 - mae: 826.4480 - mse: 1992111.1250 - val_loss: 1.1556 - val_mae: 1.1556 - val_mse: 19.0096 - learning_rate: 1.0000e-04\n",
            "Epoch 429/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 801.0255 - mae: 801.0255 - mse: 1929772.5000 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.7323 - learning_rate: 1.0000e-04\n",
            "Epoch 430/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 822.3568 - mae: 822.3568 - mse: 1976477.3750 - val_loss: 1.1555 - val_mae: 1.1555 - val_mse: 19.0019 - learning_rate: 1.0000e-04\n",
            "Epoch 431/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.1894 - mae: 801.1894 - mse: 1930584.2500 - val_loss: 1.1845 - val_mae: 1.1845 - val_mse: 18.7287 - learning_rate: 1.0000e-04\n",
            "Epoch 432/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 824.4845 - mae: 824.4845 - mse: 1984362.6250 - val_loss: 1.1558 - val_mae: 1.1558 - val_mse: 19.0005 - learning_rate: 1.0000e-04\n",
            "Epoch 433/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.1652 - mae: 803.1652 - mse: 1937685.7500 - val_loss: 1.1858 - val_mae: 1.1858 - val_mse: 18.7293 - learning_rate: 1.0000e-04\n",
            "Epoch 434/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 828.8361 - mae: 828.8361 - mse: 2000809.8750 - val_loss: 1.1547 - val_mae: 1.1547 - val_mse: 18.9806 - learning_rate: 1.0000e-04\n",
            "Epoch 435/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 800.2192 - mae: 800.2192 - mse: 1926782.7500 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 18.7055 - learning_rate: 1.0000e-04\n",
            "Epoch 436/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 822.5933 - mae: 822.5933 - mse: 1976771.8750 - val_loss: 1.1550 - val_mae: 1.1550 - val_mse: 18.9793 - learning_rate: 1.0000e-04\n",
            "Epoch 437/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 802.0180 - mae: 802.0180 - mse: 1933706.5000 - val_loss: 1.1865 - val_mae: 1.1865 - val_mse: 18.7168 - learning_rate: 1.0000e-04\n",
            "Epoch 438/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 831.3969 - mae: 831.3969 - mse: 2010719.7500 - val_loss: 1.1554 - val_mae: 1.1554 - val_mse: 18.9770 - learning_rate: 1.0000e-04\n",
            "Epoch 439/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.5885 - mae: 804.5885 - mse: 1942617.1250 - val_loss: 1.1857 - val_mae: 1.1857 - val_mse: 18.7034 - learning_rate: 1.0000e-04\n",
            "Epoch 440/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 830.3101 - mae: 830.3101 - mse: 2006121.0000 - val_loss: 1.1534 - val_mae: 1.1534 - val_mse: 18.9383 - learning_rate: 1.0000e-04\n",
            "Epoch 441/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 797.4620 - mae: 797.4620 - mse: 1916449.5000 - val_loss: 1.1799 - val_mae: 1.1799 - val_mse: 18.6623 - learning_rate: 1.0000e-04\n",
            "Epoch 442/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 815.1653 - mae: 815.1653 - mse: 1948713.3750 - val_loss: 1.1542 - val_mae: 1.1542 - val_mse: 18.9432 - learning_rate: 1.0000e-04\n",
            "Epoch 443/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 801.3752 - mae: 801.3752 - mse: 1931467.7500 - val_loss: 1.1876 - val_mae: 1.1876 - val_mse: 18.6993 - learning_rate: 1.0000e-04\n",
            "Epoch 444/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 835.4218 - mae: 835.4218 - mse: 2026241.7500 - val_loss: 1.1564 - val_mae: 1.1564 - val_mse: 18.9677 - learning_rate: 1.0000e-04\n",
            "Epoch 445/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 811.8195 - mae: 811.8195 - mse: 1968878.1250 - val_loss: 1.1870 - val_mae: 1.1870 - val_mse: 18.6877 - learning_rate: 1.0000e-04\n",
            "Epoch 446/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 834.7126 - mae: 834.7126 - mse: 2023154.6250 - val_loss: 1.1545 - val_mae: 1.1545 - val_mse: 18.9315 - learning_rate: 1.0000e-04\n",
            "Epoch 447/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.1465 - mae: 805.1465 - mse: 1944195.0000 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 18.6572 - learning_rate: 1.0000e-04\n",
            "Epoch 448/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 825.5313 - mae: 825.5313 - mse: 1987338.1250 - val_loss: 1.1530 - val_mae: 1.1530 - val_mse: 18.9000 - learning_rate: 1.0000e-04\n",
            "Epoch 449/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 799.2131 - mae: 799.2131 - mse: 1922781.8750 - val_loss: 1.1813 - val_mae: 1.1813 - val_mse: 18.6399 - learning_rate: 1.0000e-04\n",
            "Epoch 450/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 820.2753 - mae: 820.2753 - mse: 1967416.6250 - val_loss: 1.1542 - val_mae: 1.1542 - val_mse: 18.9121 - learning_rate: 1.0000e-04\n",
            "Epoch 451/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804.9053 - mae: 804.9053 - mse: 1943705.8750 - val_loss: 1.1866 - val_mae: 1.1866 - val_mse: 18.6649 - learning_rate: 1.0000e-04\n",
            "Epoch 452/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 833.7986 - mae: 833.7986 - mse: 2019421.2500 - val_loss: 1.1546 - val_mae: 1.1546 - val_mse: 18.9100 - learning_rate: 1.0000e-04\n",
            "Epoch 453/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 807.1448 - mae: 807.1448 - mse: 1951485.3750 - val_loss: 1.1847 - val_mae: 1.1847 - val_mse: 18.6457 - learning_rate: 1.0000e-04\n",
            "Epoch 454/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 829.8031 - mae: 829.8031 - mse: 2003420.0000 - val_loss: 1.1517 - val_mae: 1.1517 - val_mse: 18.8592 - learning_rate: 1.0000e-04\n",
            "Epoch 455/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.4874 - mae: 795.4874 - mse: 1908675.6250 - val_loss: 1.1777 - val_mae: 1.1777 - val_mse: 18.6016 - learning_rate: 1.0000e-04\n",
            "Epoch 456/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.5250 - mae: 811.5250 - mse: 1934527.3750 - val_loss: 1.1525 - val_mae: 1.1525 - val_mse: 18.8674 - learning_rate: 1.0000e-04\n",
            "Epoch 457/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 798.9943 - mae: 798.9943 - mse: 1922324.6250 - val_loss: 1.1853 - val_mae: 1.1853 - val_mse: 18.6366 - learning_rate: 1.0000e-04\n",
            "Epoch 458/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 831.2167 - mae: 831.2167 - mse: 2009250.2500 - val_loss: 1.1545 - val_mae: 1.1545 - val_mse: 18.8921 - learning_rate: 1.0000e-04\n",
            "Epoch 459/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.8925 - mae: 807.8925 - mse: 1954063.0000 - val_loss: 1.1855 - val_mae: 1.1855 - val_mse: 18.6318 - learning_rate: 1.0000e-04\n",
            "Epoch 460/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 832.0327 - mae: 832.0327 - mse: 2012123.7500 - val_loss: 1.1536 - val_mae: 1.1536 - val_mse: 18.8738 - learning_rate: 1.0000e-04\n",
            "Epoch 461/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 804.7606 - mae: 804.7606 - mse: 1942700.5000 - val_loss: 1.1851 - val_mae: 1.1851 - val_mse: 18.6211 - learning_rate: 1.0000e-04\n",
            "Epoch 462/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 831.5410 - mae: 831.5410 - mse: 2010119.2500 - val_loss: 1.1531 - val_mae: 1.1531 - val_mse: 18.8626 - learning_rate: 1.0000e-04\n",
            "Epoch 463/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.7797 - mae: 803.7797 - mse: 1938846.1250 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 18.6070 - learning_rate: 1.0000e-04\n",
            "Epoch 464/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 826.5469 - mae: 826.5469 - mse: 1990408.0000 - val_loss: 1.1511 - val_mae: 1.1511 - val_mse: 18.8290 - learning_rate: 1.0000e-04\n",
            "Epoch 465/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.6541 - mae: 795.6541 - mse: 1908924.1250 - val_loss: 1.1780 - val_mae: 1.1780 - val_mse: 18.5769 - learning_rate: 1.0000e-04\n",
            "Epoch 466/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 812.5073 - mae: 812.5073 - mse: 1937876.2500 - val_loss: 1.1534 - val_mae: 1.1534 - val_mse: 18.8584 - learning_rate: 1.0000e-04\n",
            "Epoch 467/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 804.3640 - mae: 804.3640 - mse: 1941542.0000 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.6313 - learning_rate: 1.0000e-04\n",
            "Epoch 468/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 840.8702 - mae: 840.8702 - mse: 2046488.7500 - val_loss: 1.1552 - val_mae: 1.1552 - val_mse: 18.8786 - learning_rate: 1.0000e-04\n",
            "Epoch 469/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 812.7873 - mae: 812.7873 - mse: 1970989.6250 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 18.5938 - learning_rate: 1.0000e-04\n",
            "Epoch 470/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 828.0975 - mae: 828.0975 - mse: 1995991.5000 - val_loss: 1.1504 - val_mae: 1.1504 - val_mse: 18.8028 - learning_rate: 1.0000e-04\n",
            "Epoch 471/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 793.1108 - mae: 793.1108 - mse: 1899465.5000 - val_loss: 1.1771 - val_mae: 1.1771 - val_mse: 18.5534 - learning_rate: 1.0000e-04\n",
            "Epoch 472/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 810.7363 - mae: 810.7363 - mse: 1930954.7500 - val_loss: 1.1522 - val_mae: 1.1522 - val_mse: 18.8246 - learning_rate: 1.0000e-04\n",
            "Epoch 473/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 800.1777 - mae: 800.1777 - mse: 1926204.2500 - val_loss: 1.1865 - val_mae: 1.1865 - val_mse: 18.5971 - learning_rate: 1.0000e-04\n",
            "Epoch 474/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 835.0242 - mae: 835.0242 - mse: 2023223.5000 - val_loss: 1.1543 - val_mae: 1.1543 - val_mse: 18.8480 - learning_rate: 1.0000e-04\n",
            "Epoch 475/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 809.1918 - mae: 809.1918 - mse: 1957926.5000 - val_loss: 1.1846 - val_mae: 1.1846 - val_mse: 18.5779 - learning_rate: 1.0000e-04\n",
            "Epoch 476/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 830.5044 - mae: 830.5044 - mse: 2005324.6250 - val_loss: 1.1520 - val_mae: 1.1520 - val_mse: 18.8099 - learning_rate: 1.0000e-04\n",
            "Epoch 477/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 800.1978 - mae: 800.1978 - mse: 1925192.7500 - val_loss: 1.1804 - val_mae: 1.1804 - val_mse: 18.5508 - learning_rate: 1.0000e-04\n",
            "Epoch 478/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 819.2984 - mae: 819.2984 - mse: 1962224.6250 - val_loss: 1.1520 - val_mae: 1.1520 - val_mse: 18.8038 - learning_rate: 1.0000e-04\n",
            "Epoch 479/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 799.9181 - mae: 799.9181 - mse: 1924428.6250 - val_loss: 1.1826 - val_mae: 1.1826 - val_mse: 18.5596 - learning_rate: 1.0000e-04\n",
            "Epoch 480/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 825.1104 - mae: 825.1104 - mse: 1984337.0000 - val_loss: 1.1516 - val_mae: 1.1516 - val_mse: 18.7971 - learning_rate: 1.0000e-04\n",
            "Epoch 481/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 799.6343 - mae: 799.6343 - mse: 1923153.7500 - val_loss: 1.1809 - val_mae: 1.1809 - val_mse: 18.5478 - learning_rate: 1.0000e-04\n",
            "Epoch 482/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 821.2001 - mae: 821.2001 - mse: 1969231.1250 - val_loss: 1.1510 - val_mae: 1.1510 - val_mse: 18.7855 - learning_rate: 1.0000e-04\n",
            "Epoch 483/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 797.7824 - mae: 797.7824 - mse: 1916075.8750 - val_loss: 1.1783 - val_mae: 1.1783 - val_mse: 18.5292 - learning_rate: 1.0000e-04\n",
            "Epoch 484/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 814.0105 - mae: 814.0105 - mse: 1942461.3750 - val_loss: 1.1526 - val_mae: 1.1526 - val_mse: 18.8028 - learning_rate: 1.0000e-04\n",
            "Epoch 485/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 803.2957 - mae: 803.2957 - mse: 1936843.3750 - val_loss: 1.1879 - val_mae: 1.1879 - val_mse: 18.5739 - learning_rate: 1.0000e-04\n",
            "Epoch 486/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 838.9550 - mae: 838.9550 - mse: 2038120.6250 - val_loss: 1.1555 - val_mae: 1.1555 - val_mse: 18.8399 - learning_rate: 1.0000e-04\n",
            "Epoch 487/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 817.0886 - mae: 817.0886 - mse: 1986288.1250 - val_loss: 1.1845 - val_mae: 1.1845 - val_mse: 18.5528 - learning_rate: 1.0000e-04\n",
            "Epoch 488/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 831.8480 - mae: 831.8480 - mse: 2009850.2500 - val_loss: 1.1517 - val_mae: 1.1517 - val_mse: 18.7822 - learning_rate: 1.0000e-04\n",
            "Epoch 489/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 802.8644 - mae: 802.8644 - mse: 1934565.5000 - val_loss: 1.1823 - val_mae: 1.1823 - val_mse: 18.5362 - learning_rate: 1.0000e-04\n",
            "Epoch 490/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 826.8621 - mae: 826.8621 - mse: 1990628.3750 - val_loss: 1.1505 - val_mae: 1.1505 - val_mse: 18.7607 - learning_rate: 1.0000e-04\n",
            "Epoch 491/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 798.8741 - mae: 798.8741 - mse: 1919913.8750 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.5146 - learning_rate: 1.0000e-04\n",
            "Epoch 492/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 819.8101 - mae: 819.8101 - mse: 1963489.3750 - val_loss: 1.1499 - val_mae: 1.1499 - val_mse: 18.7458 - learning_rate: 1.0000e-04\n",
            "Epoch 493/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 796.0851 - mae: 796.0851 - mse: 1909811.8750 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 18.5106 - learning_rate: 1.0000e-04\n",
            "Epoch 494/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 819.8638 - mae: 819.8638 - mse: 1963786.8750 - val_loss: 1.1506 - val_mae: 1.1506 - val_mse: 18.7541 - learning_rate: 1.0000e-04\n",
            "Epoch 495/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.6735 - mae: 799.6735 - mse: 1923017.5000 - val_loss: 1.1828 - val_mae: 1.1828 - val_mse: 18.5256 - learning_rate: 1.0000e-04\n",
            "Epoch 496/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 828.3911 - mae: 828.3911 - mse: 1996554.3750 - val_loss: 1.1516 - val_mae: 1.1516 - val_mse: 18.7681 - learning_rate: 1.0000e-04\n",
            "Epoch 497/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.1772 - mae: 805.1772 - mse: 1942610.2500 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 18.5298 - learning_rate: 1.0000e-04\n",
            "Epoch 498/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 831.6289 - mae: 831.6289 - mse: 2008805.5000 - val_loss: 1.1521 - val_mae: 1.1521 - val_mse: 18.7735 - learning_rate: 1.0000e-04\n",
            "Epoch 499/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 809.3115 - mae: 809.3115 - mse: 1957176.8750 - val_loss: 1.1815 - val_mae: 1.1815 - val_mse: 18.5117 - learning_rate: 1.0000e-04\n",
            "Epoch 500/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 826.7384 - mae: 826.7384 - mse: 1989615.0000 - val_loss: 1.1494 - val_mae: 1.1494 - val_mse: 18.7266 - learning_rate: 1.0000e-04\n",
            "Epoch 501/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 798.3312 - mae: 798.3312 - mse: 1917370.2500 - val_loss: 1.1791 - val_mae: 1.1791 - val_mse: 18.4896 - learning_rate: 1.0000e-04\n",
            "Epoch 502/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.0593 - mae: 820.0593 - mse: 1964018.2500 - val_loss: 1.1490 - val_mae: 1.1490 - val_mse: 18.7116 - learning_rate: 1.0000e-04\n",
            "Epoch 503/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.2631 - mae: 796.2631 - mse: 1910051.3750 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.4848 - learning_rate: 1.0000e-04\n",
            "Epoch 504/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 821.2410 - mae: 821.2410 - mse: 1968599.1250 - val_loss: 1.1495 - val_mae: 1.1495 - val_mse: 18.7132 - learning_rate: 1.0000e-04\n",
            "Epoch 505/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.0692 - mae: 799.0692 - mse: 1920003.6250 - val_loss: 1.1799 - val_mae: 1.1799 - val_mse: 18.4814 - learning_rate: 1.0000e-04\n",
            "Epoch 506/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 822.3746 - mae: 822.3746 - mse: 1972933.0000 - val_loss: 1.1497 - val_mae: 1.1497 - val_mse: 18.7111 - learning_rate: 1.0000e-04\n",
            "Epoch 507/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.6326 - mae: 800.6326 - mse: 1925835.5000 - val_loss: 1.1818 - val_mae: 1.1818 - val_mse: 18.4866 - learning_rate: 1.0000e-04\n",
            "Epoch 508/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 827.8412 - mae: 827.8412 - mse: 1993911.6250 - val_loss: 1.1511 - val_mae: 1.1511 - val_mse: 18.7276 - learning_rate: 1.0000e-04\n",
            "Epoch 509/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.8874 - mae: 807.8874 - mse: 1951881.0000 - val_loss: 1.1822 - val_mae: 1.1822 - val_mse: 18.4842 - learning_rate: 1.0000e-04\n",
            "Epoch 510/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 829.4743 - mae: 829.4743 - mse: 1999830.3750 - val_loss: 1.1504 - val_mae: 1.1504 - val_mse: 18.7125 - learning_rate: 1.0000e-04\n",
            "Epoch 511/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 806.1328 - mae: 806.1328 - mse: 1945445.0000 - val_loss: 1.1811 - val_mae: 1.1811 - val_mse: 18.4727 - learning_rate: 1.0000e-04\n",
            "Epoch 512/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 827.3866 - mae: 827.3866 - mse: 1991798.5000 - val_loss: 1.1503 - val_mae: 1.1503 - val_mse: 18.7071 - learning_rate: 1.0000e-04\n",
            "Epoch 513/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 806.7183 - mae: 806.7183 - mse: 1947496.5000 - val_loss: 1.1813 - val_mae: 1.1813 - val_mse: 18.4710 - learning_rate: 1.0000e-04\n",
            "Epoch 514/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 827.7868 - mae: 827.7868 - mse: 1993178.2500 - val_loss: 1.1503 - val_mae: 1.1503 - val_mse: 18.7017 - learning_rate: 1.0000e-04\n",
            "Epoch 515/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 807.0321 - mae: 807.0321 - mse: 1948487.3750 - val_loss: 1.1809 - val_mae: 1.1809 - val_mse: 18.4672 - learning_rate: 1.0000e-04\n",
            "Epoch 516/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 826.9153 - mae: 826.9153 - mse: 1989695.1250 - val_loss: 1.1499 - val_mae: 1.1499 - val_mse: 18.6924 - learning_rate: 1.0000e-04\n",
            "Epoch 517/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.7040 - mae: 805.7040 - mse: 1943550.7500 - val_loss: 1.1804 - val_mae: 1.1804 - val_mse: 18.4607 - learning_rate: 1.0000e-04\n",
            "Epoch 518/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 825.7603 - mae: 825.7603 - mse: 1985160.3750 - val_loss: 1.1494 - val_mae: 1.1494 - val_mse: 18.6811 - learning_rate: 1.0000e-04\n",
            "Epoch 519/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.0048 - mae: 804.0048 - mse: 1937282.7500 - val_loss: 1.1800 - val_mae: 1.1800 - val_mse: 18.4540 - learning_rate: 1.0000e-04\n",
            "Epoch 520/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 824.8284 - mae: 824.8284 - mse: 1981574.0000 - val_loss: 1.1492 - val_mae: 1.1492 - val_mse: 18.6730 - learning_rate: 1.0000e-04\n",
            "Epoch 521/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 803.1479 - mae: 803.1479 - mse: 1934183.2500 - val_loss: 1.1803 - val_mae: 1.1803 - val_mse: 18.4513 - learning_rate: 1.0000e-04\n",
            "Epoch 522/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 825.4329 - mae: 825.4329 - mse: 1983847.0000 - val_loss: 1.1495 - val_mae: 1.1495 - val_mse: 18.6739 - learning_rate: 1.0000e-04\n",
            "Epoch 523/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 805.0262 - mae: 805.0262 - mse: 1940789.2500 - val_loss: 1.1800 - val_mae: 1.1800 - val_mse: 18.4464 - learning_rate: 1.0000e-04\n",
            "Epoch 524/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 824.3884 - mae: 824.3884 - mse: 1979715.2500 - val_loss: 1.1493 - val_mae: 1.1493 - val_mse: 18.6645 - learning_rate: 1.0000e-04\n",
            "Epoch 525/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.0436 - mae: 804.0436 - mse: 1937174.0000 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.4362 - learning_rate: 1.0000e-04\n",
            "Epoch 526/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 823.5438 - mae: 823.5438 - mse: 1976398.0000 - val_loss: 1.1488 - val_mae: 1.1488 - val_mse: 18.6527 - learning_rate: 1.0000e-04\n",
            "Epoch 527/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 801.9904 - mae: 801.9904 - mse: 1929623.6250 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.4254 - learning_rate: 1.0000e-04\n",
            "Epoch 528/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 821.9369 - mae: 821.9369 - mse: 1970312.6250 - val_loss: 1.1490 - val_mae: 1.1490 - val_mse: 18.6492 - learning_rate: 1.0000e-04\n",
            "Epoch 529/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 802.4208 - mae: 802.4208 - mse: 1931208.5000 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.4233 - learning_rate: 1.0000e-04\n",
            "Epoch 530/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 824.0890 - mae: 824.0890 - mse: 1978437.8750 - val_loss: 1.1500 - val_mae: 1.1500 - val_mse: 18.6540 - learning_rate: 1.0000e-04\n",
            "Epoch 531/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 806.5878 - mae: 806.5878 - mse: 1946179.2500 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 18.4146 - learning_rate: 1.0000e-04\n",
            "Epoch 532/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 825.4171 - mae: 825.4171 - mse: 1983329.7500 - val_loss: 1.1504 - val_mae: 1.1504 - val_mse: 18.6442 - learning_rate: 1.0000e-04\n",
            "Epoch 533/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.7554 - mae: 807.7554 - mse: 1950342.1250 - val_loss: 1.1808 - val_mae: 1.1808 - val_mse: 18.3999 - learning_rate: 1.0000e-04\n",
            "Epoch 534/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 825.0748 - mae: 825.0748 - mse: 1981803.0000 - val_loss: 1.1497 - val_mae: 1.1497 - val_mse: 18.6147 - learning_rate: 1.0000e-04\n",
            "Epoch 535/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.6447 - mae: 803.6447 - mse: 1935171.8750 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 18.3736 - learning_rate: 1.0000e-04\n",
            "Epoch 536/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 821.1608 - mae: 821.1608 - mse: 1967032.6250 - val_loss: 1.1492 - val_mae: 1.1492 - val_mse: 18.5910 - learning_rate: 1.0000e-04\n",
            "Epoch 537/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.1890 - mae: 800.1890 - mse: 1922416.8750 - val_loss: 1.1791 - val_mae: 1.1791 - val_mse: 18.3505 - learning_rate: 1.0000e-04\n",
            "Epoch 538/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 817.7996 - mae: 817.7996 - mse: 1954319.7500 - val_loss: 1.1494 - val_mae: 1.1494 - val_mse: 18.5761 - learning_rate: 1.0000e-04\n",
            "Epoch 539/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 798.7523 - mae: 798.7523 - mse: 1917116.0000 - val_loss: 1.1800 - val_mae: 1.1800 - val_mse: 18.3347 - learning_rate: 1.0000e-04\n",
            "Epoch 540/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 818.0686 - mae: 818.0686 - mse: 1955474.5000 - val_loss: 1.1512 - val_mae: 1.1512 - val_mse: 18.5868 - learning_rate: 1.0000e-04\n",
            "Epoch 541/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 803.5055 - mae: 803.5055 - mse: 1934483.3750 - val_loss: 1.1829 - val_mae: 1.1829 - val_mse: 18.3355 - learning_rate: 1.0000e-04\n",
            "Epoch 542/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 824.1912 - mae: 824.1912 - mse: 1978349.5000 - val_loss: 1.1526 - val_mae: 1.1526 - val_mse: 18.5978 - learning_rate: 1.0000e-04\n",
            "Epoch 543/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 808.6083 - mae: 808.6083 - mse: 1953195.5000 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 18.3406 - learning_rate: 1.0000e-04\n",
            "Epoch 544/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 829.4694 - mae: 829.4694 - mse: 1998116.2500 - val_loss: 1.1521 - val_mae: 1.1521 - val_mse: 18.5886 - learning_rate: 1.0000e-04\n",
            "Epoch 545/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 808.1141 - mae: 808.1141 - mse: 1950985.0000 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 18.3243 - learning_rate: 1.0000e-04\n",
            "Epoch 546/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 823.0885 - mae: 823.0885 - mse: 1973807.5000 - val_loss: 1.1506 - val_mae: 1.1506 - val_mse: 18.5674 - learning_rate: 1.0000e-04\n",
            "Epoch 547/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.4495 - mae: 803.4495 - mse: 1933647.0000 - val_loss: 1.1803 - val_mae: 1.1803 - val_mse: 18.3199 - learning_rate: 1.0000e-04\n",
            "Epoch 548/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.1814 - mae: 819.1814 - mse: 1959021.1250 - val_loss: 1.1492 - val_mae: 1.1492 - val_mse: 18.5475 - learning_rate: 1.0000e-04\n",
            "Epoch 549/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.9550 - mae: 798.9550 - mse: 1917184.0000 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.3158 - learning_rate: 1.0000e-04\n",
            "Epoch 550/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 818.1866 - mae: 818.1866 - mse: 1955256.6250 - val_loss: 1.1491 - val_mae: 1.1491 - val_mse: 18.5439 - learning_rate: 1.0000e-04\n",
            "Epoch 551/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.2408 - mae: 799.2408 - mse: 1918112.8750 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.3134 - learning_rate: 1.0000e-04\n",
            "Epoch 552/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 817.1367 - mae: 817.1367 - mse: 1951251.7500 - val_loss: 1.1489 - val_mae: 1.1489 - val_mse: 18.5397 - learning_rate: 1.0000e-04\n",
            "Epoch 553/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 798.8651 - mae: 798.8651 - mse: 1916720.3750 - val_loss: 1.1799 - val_mae: 1.1799 - val_mse: 18.3122 - learning_rate: 1.0000e-04\n",
            "Epoch 554/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 817.8223 - mae: 817.8223 - mse: 1953693.5000 - val_loss: 1.1493 - val_mae: 1.1493 - val_mse: 18.5432 - learning_rate: 1.0000e-04\n",
            "Epoch 555/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 800.6073 - mae: 800.6073 - mse: 1923014.2500 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 18.3119 - learning_rate: 1.0000e-04\n",
            "Epoch 556/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.0354 - mae: 819.0354 - mse: 1958297.3750 - val_loss: 1.1508 - val_mae: 1.1508 - val_mse: 18.5610 - learning_rate: 1.0000e-04\n",
            "Epoch 557/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 806.7092 - mae: 806.7092 - mse: 1945402.3750 - val_loss: 1.1828 - val_mae: 1.1828 - val_mse: 18.3181 - learning_rate: 1.0000e-04\n",
            "Epoch 558/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 824.2111 - mae: 824.2111 - mse: 1977440.5000 - val_loss: 1.1510 - val_mae: 1.1510 - val_mse: 18.5598 - learning_rate: 1.0000e-04\n",
            "Epoch 559/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.8191 - mae: 807.8191 - mse: 1949336.5000 - val_loss: 1.1830 - val_mae: 1.1830 - val_mse: 18.3133 - learning_rate: 1.0000e-04\n",
            "Epoch 560/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 824.8476 - mae: 824.8476 - mse: 1979622.5000 - val_loss: 1.1510 - val_mae: 1.1510 - val_mse: 18.5544 - learning_rate: 1.0000e-04\n",
            "Epoch 561/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 807.7614 - mae: 807.7614 - mse: 1949132.1250 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 18.3122 - learning_rate: 1.0000e-04\n",
            "Epoch 562/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 827.8430 - mae: 827.8430 - mse: 1990792.6250 - val_loss: 1.1513 - val_mae: 1.1513 - val_mse: 18.5527 - learning_rate: 1.0000e-04\n",
            "Epoch 563/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 808.9519 - mae: 808.9519 - mse: 1953247.7500 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.3036 - learning_rate: 1.0000e-04\n",
            "Epoch 564/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 827.3385 - mae: 827.3385 - mse: 1988770.3750 - val_loss: 1.1510 - val_mae: 1.1510 - val_mse: 18.5435 - learning_rate: 1.0000e-04\n",
            "Epoch 565/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 808.0900 - mae: 808.0900 - mse: 1949835.5000 - val_loss: 1.1829 - val_mae: 1.1829 - val_mse: 18.2907 - learning_rate: 1.0000e-04\n",
            "Epoch 566/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 824.9183 - mae: 824.9183 - mse: 1979487.0000 - val_loss: 1.1497 - val_mae: 1.1497 - val_mse: 18.5240 - learning_rate: 1.0000e-04\n",
            "Epoch 567/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.4799 - mae: 804.4799 - mse: 1936184.8750 - val_loss: 1.1787 - val_mae: 1.1787 - val_mse: 18.2687 - learning_rate: 1.0000e-04\n",
            "Epoch 568/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 814.9879 - mae: 814.9879 - mse: 1942078.0000 - val_loss: 1.1472 - val_mae: 1.1472 - val_mse: 18.4886 - learning_rate: 1.0000e-04\n",
            "Epoch 569/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 795.3657 - mae: 795.3657 - mse: 1902899.3750 - val_loss: 1.1787 - val_mae: 1.1787 - val_mse: 18.2703 - learning_rate: 1.0000e-04\n",
            "Epoch 570/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 814.6938 - mae: 814.6938 - mse: 1941026.2500 - val_loss: 1.1479 - val_mae: 1.1479 - val_mse: 18.4976 - learning_rate: 1.0000e-04\n",
            "Epoch 571/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.0306 - mae: 799.0306 - mse: 1916409.1250 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 18.2793 - learning_rate: 1.0000e-04\n",
            "Epoch 572/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 819.1649 - mae: 819.1649 - mse: 1957981.1250 - val_loss: 1.1503 - val_mae: 1.1503 - val_mse: 18.5280 - learning_rate: 1.0000e-04\n",
            "Epoch 573/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 808.9681 - mae: 808.9681 - mse: 1952888.8750 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 18.2929 - learning_rate: 1.0000e-04\n",
            "Epoch 574/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 828.2945 - mae: 828.2945 - mse: 1991752.7500 - val_loss: 1.1498 - val_mae: 1.1498 - val_mse: 18.5166 - learning_rate: 1.0000e-04\n",
            "Epoch 575/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 806.9796 - mae: 806.9796 - mse: 1945209.3750 - val_loss: 1.1815 - val_mae: 1.1815 - val_mse: 18.2726 - learning_rate: 1.0000e-04\n",
            "Epoch 576/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 821.9171 - mae: 821.9171 - mse: 1967718.0000 - val_loss: 1.1493 - val_mae: 1.1493 - val_mse: 18.5053 - learning_rate: 1.0000e-04\n",
            "Epoch 577/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.0064 - mae: 805.0064 - mse: 1937733.2500 - val_loss: 1.1799 - val_mae: 1.1799 - val_mse: 18.2591 - learning_rate: 1.0000e-04\n",
            "Epoch 578/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 817.7416 - mae: 817.7416 - mse: 1951990.2500 - val_loss: 1.1476 - val_mae: 1.1476 - val_mse: 18.4787 - learning_rate: 1.0000e-04\n",
            "Epoch 579/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 798.4694 - mae: 798.4694 - mse: 1913687.2500 - val_loss: 1.1786 - val_mae: 1.1786 - val_mse: 18.2498 - learning_rate: 1.0000e-04\n",
            "Epoch 580/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 813.8764 - mae: 813.8764 - mse: 1937432.2500 - val_loss: 1.1471 - val_mae: 1.1471 - val_mse: 18.4691 - learning_rate: 1.0000e-04\n",
            "Epoch 581/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 796.6057 - mae: 796.6057 - mse: 1906773.5000 - val_loss: 1.1776 - val_mae: 1.1776 - val_mse: 18.2420 - learning_rate: 1.0000e-04\n",
            "Epoch 582/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 811.0920 - mae: 811.0920 - mse: 1926931.6250 - val_loss: 1.1470 - val_mae: 1.1470 - val_mse: 18.4653 - learning_rate: 1.0000e-04\n",
            "Epoch 583/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.4714 - mae: 796.4714 - mse: 1906433.5000 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.2499 - learning_rate: 1.0000e-04\n",
            "Epoch 584/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 815.3726 - mae: 815.3726 - mse: 1943090.1250 - val_loss: 1.1487 - val_mae: 1.1487 - val_mse: 18.4868 - learning_rate: 1.0000e-04\n",
            "Epoch 585/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 804.1222 - mae: 804.1222 - mse: 1934256.7500 - val_loss: 1.1805 - val_mae: 1.1805 - val_mse: 18.2494 - learning_rate: 1.0000e-04\n",
            "Epoch 586/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 817.5690 - mae: 817.5690 - mse: 1951112.3750 - val_loss: 1.1485 - val_mae: 1.1485 - val_mse: 18.4795 - learning_rate: 1.0000e-04\n",
            "Epoch 587/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.5251 - mae: 803.5251 - mse: 1931892.6250 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.2410 - learning_rate: 1.0000e-04\n",
            "Epoch 588/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 816.8297 - mae: 816.8297 - mse: 1948191.6250 - val_loss: 1.1480 - val_mae: 1.1480 - val_mse: 18.4670 - learning_rate: 1.0000e-04\n",
            "Epoch 589/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.3625 - mae: 801.3625 - mse: 1924005.5000 - val_loss: 1.1804 - val_mae: 1.1804 - val_mse: 18.2379 - learning_rate: 1.0000e-04\n",
            "Epoch 590/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 817.2748 - mae: 817.2748 - mse: 1949800.8750 - val_loss: 1.1482 - val_mae: 1.1482 - val_mse: 18.4665 - learning_rate: 1.0000e-04\n",
            "Epoch 591/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 802.9929 - mae: 802.9929 - mse: 1929748.2500 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.2327 - learning_rate: 1.0000e-04\n",
            "Epoch 592/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 816.5809 - mae: 816.5809 - mse: 1947079.0000 - val_loss: 1.1475 - val_mae: 1.1475 - val_mse: 18.4542 - learning_rate: 1.0000e-04\n",
            "Epoch 593/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 801.3668 - mae: 801.3668 - mse: 1923802.2500 - val_loss: 1.1802 - val_mae: 1.1802 - val_mse: 18.2267 - learning_rate: 1.0000e-04\n",
            "Epoch 594/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 816.5839 - mae: 816.5839 - mse: 1947096.2500 - val_loss: 1.1478 - val_mae: 1.1478 - val_mse: 18.4531 - learning_rate: 1.0000e-04\n",
            "Epoch 595/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 803.0721 - mae: 803.0721 - mse: 1929898.7500 - val_loss: 1.1797 - val_mae: 1.1797 - val_mse: 18.2184 - learning_rate: 1.0000e-04\n",
            "Epoch 596/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 815.7929 - mae: 815.7929 - mse: 1944008.5000 - val_loss: 1.1475 - val_mae: 1.1475 - val_mse: 18.4443 - learning_rate: 1.0000e-04\n",
            "Epoch 597/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 802.3036 - mae: 802.3036 - mse: 1927056.7500 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.2142 - learning_rate: 1.0000e-04\n",
            "Epoch 598/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 816.8079 - mae: 816.8079 - mse: 1947816.5000 - val_loss: 1.1479 - val_mae: 1.1479 - val_mse: 18.4456 - learning_rate: 1.0000e-04\n",
            "Epoch 599/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 804.2449 - mae: 804.2449 - mse: 1934121.2500 - val_loss: 1.1803 - val_mae: 1.1803 - val_mse: 18.2115 - learning_rate: 1.0000e-04\n",
            "Epoch 600/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 817.3719 - mae: 817.3719 - mse: 1949743.5000 - val_loss: 1.1476 - val_mae: 1.1476 - val_mse: 18.4376 - learning_rate: 1.0000e-04\n",
            "Epoch 601/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 803.5724 - mae: 803.5724 - mse: 1931429.1250 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.2006 - learning_rate: 1.0000e-04\n",
            "Epoch 602/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 814.0137 - mae: 814.0137 - mse: 1937202.7500 - val_loss: 1.1464 - val_mae: 1.1464 - val_mse: 18.4191 - learning_rate: 1.0000e-04\n",
            "Epoch 603/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 799.1763 - mae: 799.1763 - mse: 1915682.2500 - val_loss: 1.1814 - val_mae: 1.1814 - val_mse: 18.2104 - learning_rate: 1.0000e-04\n",
            "Epoch 604/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 819.4031 - mae: 819.4031 - mse: 1957256.0000 - val_loss: 1.1489 - val_mae: 1.1489 - val_mse: 18.4480 - learning_rate: 1.0000e-04\n",
            "Epoch 605/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 809.0626 - mae: 809.0626 - mse: 1951762.1250 - val_loss: 1.1840 - val_mae: 1.1840 - val_mse: 18.2208 - learning_rate: 1.0000e-04\n",
            "Epoch 606/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 826.2339 - mae: 826.2339 - mse: 1982475.6250 - val_loss: 1.1490 - val_mae: 1.1490 - val_mse: 18.4464 - learning_rate: 1.0000e-04\n",
            "Epoch 607/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 809.4733 - mae: 809.4733 - mse: 1952920.5000 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 18.2065 - learning_rate: 1.0000e-04\n",
            "Epoch 608/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 821.5320 - mae: 821.5320 - mse: 1964941.8750 - val_loss: 1.1487 - val_mae: 1.1487 - val_mse: 18.4382 - learning_rate: 1.0000e-04\n",
            "Epoch 609/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 808.0344 - mae: 808.0344 - mse: 1947716.7500 - val_loss: 1.1824 - val_mae: 1.1824 - val_mse: 18.2041 - learning_rate: 1.0000e-04\n",
            "Epoch 610/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 822.2266 - mae: 822.2266 - mse: 1967514.8750 - val_loss: 1.1493 - val_mae: 1.1493 - val_mse: 18.4423 - learning_rate: 1.0000e-04\n",
            "Epoch 611/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 810.3997 - mae: 810.3997 - mse: 1956221.3750 - val_loss: 1.1823 - val_mae: 1.1823 - val_mse: 18.2002 - learning_rate: 1.0000e-04\n",
            "Epoch 612/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 821.7996 - mae: 821.7996 - mse: 1965809.3750 - val_loss: 1.1494 - val_mae: 1.1494 - val_mse: 18.4400 - learning_rate: 1.0000e-04\n",
            "Epoch 613/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 810.6331 - mae: 810.6331 - mse: 1957029.3750 - val_loss: 1.1830 - val_mae: 1.1830 - val_mse: 18.2001 - learning_rate: 1.0000e-04\n",
            "Epoch 614/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 823.1392 - mae: 823.1392 - mse: 1970592.1250 - val_loss: 1.1492 - val_mae: 1.1492 - val_mse: 18.4336 - learning_rate: 1.0000e-04\n",
            "Epoch 615/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 809.6707 - mae: 809.6707 - mse: 1953410.7500 - val_loss: 1.1818 - val_mae: 1.1818 - val_mse: 18.1901 - learning_rate: 1.0000e-04\n",
            "Epoch 616/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 820.1655 - mae: 820.1655 - mse: 1959292.5000 - val_loss: 1.1476 - val_mae: 1.1476 - val_mse: 18.4084 - learning_rate: 1.0000e-04\n",
            "Epoch 617/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 803.5483 - mae: 803.5483 - mse: 1930604.2500 - val_loss: 1.1771 - val_mae: 1.1771 - val_mse: 18.1605 - learning_rate: 1.0000e-04\n",
            "Epoch 618/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 808.7737 - mae: 808.7737 - mse: 1916861.3750 - val_loss: 1.1447 - val_mae: 1.1447 - val_mse: 18.3657 - learning_rate: 1.0000e-04\n",
            "Epoch 619/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 791.8407 - mae: 791.8407 - mse: 1888714.0000 - val_loss: 1.1796 - val_mae: 1.1796 - val_mse: 18.1676 - learning_rate: 1.0000e-04\n",
            "Epoch 620/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 814.2716 - mae: 814.2716 - mse: 1937565.2500 - val_loss: 1.1480 - val_mae: 1.1480 - val_mse: 18.4075 - learning_rate: 1.0000e-04\n",
            "Epoch 621/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 805.5687 - mae: 805.5687 - mse: 1938830.0000 - val_loss: 1.1836 - val_mae: 1.1836 - val_mse: 18.1859 - learning_rate: 1.0000e-04\n",
            "Epoch 622/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 824.2448 - mae: 824.2448 - mse: 1974460.8750 - val_loss: 1.1494 - val_mae: 1.1494 - val_mse: 18.4233 - learning_rate: 1.0000e-04\n",
            "Epoch 623/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 810.9289 - mae: 810.9289 - mse: 1958166.0000 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.1856 - learning_rate: 1.0000e-04\n",
            "Epoch 624/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 825.3432 - mae: 825.3432 - mse: 1978220.1250 - val_loss: 1.1481 - val_mae: 1.1481 - val_mse: 18.4045 - learning_rate: 1.0000e-04\n",
            "Epoch 625/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.7713 - mae: 805.7713 - mse: 1939141.3750 - val_loss: 1.1812 - val_mae: 1.1812 - val_mse: 18.1706 - learning_rate: 1.0000e-04\n",
            "Epoch 626/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 818.4321 - mae: 818.4321 - mse: 1952510.7500 - val_loss: 1.1476 - val_mae: 1.1476 - val_mse: 18.3947 - learning_rate: 1.0000e-04\n",
            "Epoch 627/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.7911 - mae: 803.7911 - mse: 1932085.5000 - val_loss: 1.1814 - val_mae: 1.1814 - val_mse: 18.1691 - learning_rate: 1.0000e-04\n",
            "Epoch 628/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.1088 - mae: 819.1088 - mse: 1954972.5000 - val_loss: 1.1475 - val_mae: 1.1475 - val_mse: 18.3904 - learning_rate: 1.0000e-04\n",
            "Epoch 629/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 804.0127 - mae: 804.0127 - mse: 1932957.0000 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 18.1664 - learning_rate: 1.0000e-04\n",
            "Epoch 630/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.5560 - mae: 820.5560 - mse: 1960352.2500 - val_loss: 1.1481 - val_mae: 1.1481 - val_mse: 18.3944 - learning_rate: 1.0000e-04\n",
            "Epoch 631/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 806.9460 - mae: 806.9460 - mse: 1943441.5000 - val_loss: 1.1822 - val_mae: 1.1822 - val_mse: 18.1659 - learning_rate: 1.0000e-04\n",
            "Epoch 632/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 821.4238 - mae: 821.4238 - mse: 1963457.7500 - val_loss: 1.1478 - val_mae: 1.1478 - val_mse: 18.3882 - learning_rate: 1.0000e-04\n",
            "Epoch 633/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 806.1646 - mae: 806.1646 - mse: 1940602.8750 - val_loss: 1.1823 - val_mae: 1.1823 - val_mse: 18.1656 - learning_rate: 1.0000e-04\n",
            "Epoch 634/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 821.4305 - mae: 821.4305 - mse: 1963415.5000 - val_loss: 1.1477 - val_mae: 1.1477 - val_mse: 18.3847 - learning_rate: 1.0000e-04\n",
            "Epoch 635/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 806.1305 - mae: 806.1305 - mse: 1940449.0000 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 18.1631 - learning_rate: 1.0000e-04\n",
            "Epoch 636/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 820.8785 - mae: 820.8785 - mse: 1961147.1250 - val_loss: 1.1466 - val_mae: 1.1466 - val_mse: 18.3671 - learning_rate: 1.0000e-04\n",
            "Epoch 637/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.4116 - mae: 802.4116 - mse: 1926327.7500 - val_loss: 1.1770 - val_mae: 1.1770 - val_mse: 18.1328 - learning_rate: 1.0000e-04\n",
            "Epoch 638/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 808.6359 - mae: 808.6359 - mse: 1915871.7500 - val_loss: 1.1445 - val_mae: 1.1445 - val_mse: 18.3367 - learning_rate: 1.0000e-04\n",
            "Epoch 639/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.0154 - mae: 794.0154 - mse: 1896545.2500 - val_loss: 1.1806 - val_mae: 1.1806 - val_mse: 18.1481 - learning_rate: 1.0000e-04\n",
            "Epoch 640/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 816.7358 - mae: 816.7358 - mse: 1946044.0000 - val_loss: 1.1480 - val_mae: 1.1480 - val_mse: 18.3790 - learning_rate: 1.0000e-04\n",
            "Epoch 641/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.7786 - mae: 807.7786 - mse: 1946732.7500 - val_loss: 1.1846 - val_mae: 1.1846 - val_mse: 18.1674 - learning_rate: 1.0000e-04\n",
            "Epoch 642/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 826.6830 - mae: 826.6830 - mse: 1982772.7500 - val_loss: 1.1482 - val_mae: 1.1482 - val_mse: 18.3797 - learning_rate: 1.0000e-04\n",
            "Epoch 643/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 808.7567 - mae: 808.7567 - mse: 1949886.1250 - val_loss: 1.1817 - val_mae: 1.1817 - val_mse: 18.1531 - learning_rate: 1.0000e-04\n",
            "Epoch 644/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 819.5121 - mae: 819.5121 - mse: 1955780.8750 - val_loss: 1.1464 - val_mae: 1.1464 - val_mse: 18.3545 - learning_rate: 1.0000e-04\n",
            "Epoch 645/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 802.1155 - mae: 802.1155 - mse: 1925185.1250 - val_loss: 1.1768 - val_mae: 1.1768 - val_mse: 18.1244 - learning_rate: 1.0000e-04\n",
            "Epoch 646/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 807.1971 - mae: 807.1971 - mse: 1910347.6250 - val_loss: 1.1439 - val_mae: 1.1439 - val_mse: 18.3193 - learning_rate: 1.0000e-04\n",
            "Epoch 647/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 791.9339 - mae: 791.9339 - mse: 1889087.3750 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 18.1411 - learning_rate: 1.0000e-04\n",
            "Epoch 648/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 816.1536 - mae: 816.1536 - mse: 1943690.3750 - val_loss: 1.1482 - val_mae: 1.1482 - val_mse: 18.3706 - learning_rate: 1.0000e-04\n",
            "Epoch 649/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 809.1565 - mae: 809.1565 - mse: 1951805.8750 - val_loss: 1.1857 - val_mae: 1.1857 - val_mse: 18.1647 - learning_rate: 1.0000e-04\n",
            "Epoch 650/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 829.0546 - mae: 829.0546 - mse: 1991351.2500 - val_loss: 1.1480 - val_mae: 1.1480 - val_mse: 18.3648 - learning_rate: 1.0000e-04\n",
            "Epoch 651/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 808.5041 - mae: 808.5041 - mse: 1948852.2500 - val_loss: 1.1813 - val_mae: 1.1813 - val_mse: 18.1380 - learning_rate: 1.0000e-04\n",
            "Epoch 652/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 818.2956 - mae: 818.2956 - mse: 1951094.2500 - val_loss: 1.1462 - val_mae: 1.1462 - val_mse: 18.3397 - learning_rate: 1.0000e-04\n",
            "Epoch 653/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 802.1649 - mae: 802.1649 - mse: 1925409.6250 - val_loss: 1.1768 - val_mae: 1.1768 - val_mse: 18.1116 - learning_rate: 1.0000e-04\n",
            "Epoch 654/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.3214 - mae: 807.3214 - mse: 1910683.2500 - val_loss: 1.1432 - val_mae: 1.1432 - val_mse: 18.2986 - learning_rate: 1.0000e-04\n",
            "Epoch 655/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 790.3631 - mae: 790.3631 - mse: 1883320.7500 - val_loss: 1.1789 - val_mae: 1.1789 - val_mse: 18.1202 - learning_rate: 1.0000e-04\n",
            "Epoch 656/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 811.6068 - mae: 811.6068 - mse: 1926665.6250 - val_loss: 1.1459 - val_mae: 1.1459 - val_mse: 18.3321 - learning_rate: 1.0000e-04\n",
            "Epoch 657/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.6356 - mae: 801.6356 - mse: 1923843.3750 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.1196 - learning_rate: 1.0000e-04\n",
            "Epoch 658/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.7450 - mae: 811.7450 - mse: 1926912.5000 - val_loss: 1.1453 - val_mae: 1.1453 - val_mse: 18.3230 - learning_rate: 1.0000e-04\n",
            "Epoch 659/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.5308 - mae: 799.5308 - mse: 1916200.0000 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 18.1176 - learning_rate: 1.0000e-04\n",
            "Epoch 660/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 812.3710 - mae: 812.3710 - mse: 1929163.7500 - val_loss: 1.1454 - val_mae: 1.1454 - val_mse: 18.3216 - learning_rate: 1.0000e-04\n",
            "Epoch 661/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.7979 - mae: 799.7979 - mse: 1917137.0000 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.1131 - learning_rate: 1.0000e-04\n",
            "Epoch 662/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.6226 - mae: 811.6226 - mse: 1926370.8750 - val_loss: 1.1454 - val_mae: 1.1454 - val_mse: 18.3197 - learning_rate: 1.0000e-04\n",
            "Epoch 663/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 800.0626 - mae: 800.0626 - mse: 1918118.3750 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.1097 - learning_rate: 1.0000e-04\n",
            "Epoch 664/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.6581 - mae: 811.6581 - mse: 1926390.3750 - val_loss: 1.1445 - val_mae: 1.1445 - val_mse: 18.3057 - learning_rate: 1.0000e-04\n",
            "Epoch 665/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 797.0388 - mae: 797.0388 - mse: 1907214.6250 - val_loss: 1.1794 - val_mae: 1.1794 - val_mse: 18.1077 - learning_rate: 1.0000e-04\n",
            "Epoch 666/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 812.3437 - mae: 812.3437 - mse: 1928970.0000 - val_loss: 1.1450 - val_mae: 1.1450 - val_mse: 18.3091 - learning_rate: 1.0000e-04\n",
            "Epoch 667/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.1781 - mae: 799.1781 - mse: 1914996.8750 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 18.1049 - learning_rate: 1.0000e-04\n",
            "Epoch 668/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 812.2466 - mae: 812.2466 - mse: 1928534.7500 - val_loss: 1.1447 - val_mae: 1.1447 - val_mse: 18.3023 - learning_rate: 1.0000e-04\n",
            "Epoch 669/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 797.9497 - mae: 797.9497 - mse: 1910613.6250 - val_loss: 1.1800 - val_mae: 1.1800 - val_mse: 18.1065 - learning_rate: 1.0000e-04\n",
            "Epoch 670/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 813.6433 - mae: 813.6433 - mse: 1933770.8750 - val_loss: 1.1457 - val_mae: 1.1457 - val_mse: 18.3124 - learning_rate: 1.0000e-04\n",
            "Epoch 671/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.5693 - mae: 801.5693 - mse: 1924407.2500 - val_loss: 1.1846 - val_mae: 1.1846 - val_mse: 18.1295 - learning_rate: 1.0000e-04\n",
            "Epoch 672/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 824.8755 - mae: 824.8755 - mse: 1975309.0000 - val_loss: 1.1482 - val_mae: 1.1482 - val_mse: 18.3399 - learning_rate: 1.0000e-04\n",
            "Epoch 673/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 811.1801 - mae: 811.1801 - mse: 1958759.2500 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 18.1272 - learning_rate: 1.0000e-04\n",
            "Epoch 674/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 824.0291 - mae: 824.0291 - mse: 1971929.5000 - val_loss: 1.1470 - val_mae: 1.1470 - val_mse: 18.3225 - learning_rate: 1.0000e-04\n",
            "Epoch 675/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 806.1756 - mae: 806.1756 - mse: 1940633.5000 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 18.1198 - learning_rate: 1.0000e-04\n",
            "Epoch 676/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 821.3481 - mae: 821.3481 - mse: 1961699.0000 - val_loss: 1.1456 - val_mae: 1.1456 - val_mse: 18.3037 - learning_rate: 1.0000e-04\n",
            "Epoch 677/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.2280 - mae: 801.2280 - mse: 1922392.0000 - val_loss: 1.1789 - val_mae: 1.1789 - val_mse: 18.0928 - learning_rate: 1.0000e-04\n",
            "Epoch 678/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 810.6450 - mae: 810.6450 - mse: 1922430.0000 - val_loss: 1.1436 - val_mae: 1.1436 - val_mse: 18.2785 - learning_rate: 1.0000e-04\n",
            "Epoch 679/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 793.8961 - mae: 793.8961 - mse: 1895929.3750 - val_loss: 1.1791 - val_mae: 1.1791 - val_mse: 18.0924 - learning_rate: 1.0000e-04\n",
            "Epoch 680/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 810.5720 - mae: 810.5720 - mse: 1922425.7500 - val_loss: 1.1454 - val_mae: 1.1454 - val_mse: 18.3003 - learning_rate: 1.0000e-04\n",
            "Epoch 681/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.6245 - mae: 800.6245 - mse: 1920689.1250 - val_loss: 1.1824 - val_mae: 1.1824 - val_mse: 18.1097 - learning_rate: 1.0000e-04\n",
            "Epoch 682/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 818.5764 - mae: 818.5764 - mse: 1951565.1250 - val_loss: 1.1468 - val_mae: 1.1468 - val_mse: 18.3162 - learning_rate: 1.0000e-04\n",
            "Epoch 683/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 805.5825 - mae: 805.5825 - mse: 1938680.1250 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 18.1212 - learning_rate: 1.0000e-04\n",
            "Epoch 684/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 824.7418 - mae: 824.7418 - mse: 1974525.5000 - val_loss: 1.1479 - val_mae: 1.1479 - val_mse: 18.3291 - learning_rate: 1.0000e-04\n",
            "Epoch 685/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 810.0563 - mae: 810.0563 - mse: 1954525.8750 - val_loss: 1.1847 - val_mae: 1.1847 - val_mse: 18.1201 - learning_rate: 1.0000e-04\n",
            "Epoch 686/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 824.2375 - mae: 824.2375 - mse: 1972339.5000 - val_loss: 1.1462 - val_mae: 1.1462 - val_mse: 18.3071 - learning_rate: 1.0000e-04\n",
            "Epoch 687/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.4767 - mae: 803.4767 - mse: 1930817.7500 - val_loss: 1.1829 - val_mae: 1.1829 - val_mse: 18.1107 - learning_rate: 1.0000e-04\n",
            "Epoch 688/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.5403 - mae: 819.5403 - mse: 1954818.6250 - val_loss: 1.1457 - val_mae: 1.1457 - val_mse: 18.3008 - learning_rate: 1.0000e-04\n",
            "Epoch 689/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 801.8312 - mae: 801.8312 - mse: 1924987.3750 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 18.1097 - learning_rate: 1.0000e-04\n",
            "Epoch 690/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 820.1165 - mae: 820.1165 - mse: 1956906.7500 - val_loss: 1.1456 - val_mae: 1.1456 - val_mse: 18.2996 - learning_rate: 1.0000e-04\n",
            "Epoch 691/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.9593 - mae: 801.9593 - mse: 1925411.2500 - val_loss: 1.1830 - val_mae: 1.1830 - val_mse: 18.1059 - learning_rate: 1.0000e-04\n",
            "Epoch 692/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 820.2749 - mae: 820.2749 - mse: 1957510.1250 - val_loss: 1.1460 - val_mae: 1.1460 - val_mse: 18.3037 - learning_rate: 1.0000e-04\n",
            "Epoch 693/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.8094 - mae: 803.8094 - mse: 1931997.5000 - val_loss: 1.1843 - val_mae: 1.1843 - val_mse: 18.1098 - learning_rate: 1.0000e-04\n",
            "Epoch 694/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 823.7249 - mae: 823.7249 - mse: 1970258.1250 - val_loss: 1.1465 - val_mae: 1.1465 - val_mse: 18.3071 - learning_rate: 1.0000e-04\n",
            "Epoch 695/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 806.2062 - mae: 806.2062 - mse: 1940466.5000 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.1076 - learning_rate: 1.0000e-04\n",
            "Epoch 696/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 822.4738 - mae: 822.4738 - mse: 1965588.2500 - val_loss: 1.1464 - val_mae: 1.1464 - val_mse: 18.3037 - learning_rate: 1.0000e-04\n",
            "Epoch 697/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 805.8910 - mae: 805.8910 - mse: 1939352.1250 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 18.1045 - learning_rate: 1.0000e-04\n",
            "Epoch 698/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 820.9236 - mae: 820.9236 - mse: 1959780.1250 - val_loss: 1.1458 - val_mae: 1.1458 - val_mse: 18.2960 - learning_rate: 1.0000e-04\n",
            "Epoch 699/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 804.0077 - mae: 804.0077 - mse: 1932646.7500 - val_loss: 1.1835 - val_mae: 1.1835 - val_mse: 18.1027 - learning_rate: 1.0000e-04\n",
            "Epoch 700/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 821.3896 - mae: 821.3896 - mse: 1961487.5000 - val_loss: 1.1459 - val_mae: 1.1459 - val_mse: 18.2968 - learning_rate: 1.0000e-04\n",
            "Epoch 701/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.8632 - mae: 804.8632 - mse: 1935672.8750 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.1012 - learning_rate: 1.0000e-04\n",
            "Epoch 702/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 822.6555 - mae: 822.6555 - mse: 1966128.0000 - val_loss: 1.1462 - val_mae: 1.1462 - val_mse: 18.2985 - learning_rate: 1.0000e-04\n",
            "Epoch 703/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 806.2203 - mae: 806.2203 - mse: 1940371.3750 - val_loss: 1.1835 - val_mae: 1.1835 - val_mse: 18.0980 - learning_rate: 1.0000e-04\n",
            "Epoch 704/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 821.8239 - mae: 821.8239 - mse: 1963030.7500 - val_loss: 1.1460 - val_mae: 1.1460 - val_mse: 18.2945 - learning_rate: 1.0000e-04\n",
            "Epoch 705/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 805.4191 - mae: 805.4191 - mse: 1937532.1250 - val_loss: 1.1826 - val_mae: 1.1826 - val_mse: 18.0923 - learning_rate: 1.0000e-04\n",
            "Epoch 706/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 819.3981 - mae: 819.3981 - mse: 1954041.3750 - val_loss: 1.1454 - val_mae: 1.1454 - val_mse: 18.2865 - learning_rate: 1.0000e-04\n",
            "Epoch 707/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.3348 - mae: 803.3348 - mse: 1930149.6250 - val_loss: 1.1832 - val_mae: 1.1832 - val_mse: 18.0927 - learning_rate: 1.0000e-04\n",
            "Epoch 708/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 820.9333 - mae: 820.9333 - mse: 1959646.0000 - val_loss: 1.1457 - val_mae: 1.1457 - val_mse: 18.2902 - learning_rate: 1.0000e-04\n",
            "Epoch 709/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 804.9365 - mae: 804.9365 - mse: 1935752.7500 - val_loss: 1.1834 - val_mae: 1.1834 - val_mse: 18.0926 - learning_rate: 1.0000e-04\n",
            "Epoch 710/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 821.6207 - mae: 821.6207 - mse: 1962092.1250 - val_loss: 1.1454 - val_mae: 1.1454 - val_mse: 18.2856 - learning_rate: 1.0000e-04\n",
            "Epoch 711/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 803.9134 - mae: 803.9134 - mse: 1932100.6250 - val_loss: 1.1826 - val_mae: 1.1826 - val_mse: 18.0852 - learning_rate: 1.0000e-04\n",
            "Epoch 712/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 819.7581 - mae: 819.7581 - mse: 1955185.2500 - val_loss: 1.1450 - val_mae: 1.1450 - val_mse: 18.2789 - learning_rate: 1.0000e-04\n",
            "Epoch 713/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 802.5530 - mae: 802.5530 - mse: 1927103.1250 - val_loss: 1.1816 - val_mae: 1.1816 - val_mse: 18.0766 - learning_rate: 1.0000e-04\n",
            "Epoch 714/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 817.3544 - mae: 817.3544 - mse: 1946338.1250 - val_loss: 1.1449 - val_mae: 1.1449 - val_mse: 18.2749 - learning_rate: 1.0000e-04\n",
            "Epoch 715/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 802.0688 - mae: 802.0688 - mse: 1925429.1250 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 18.0778 - learning_rate: 1.0000e-04\n",
            "Epoch 716/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 818.1655 - mae: 818.1655 - mse: 1949359.8750 - val_loss: 1.1453 - val_mae: 1.1453 - val_mse: 18.2794 - learning_rate: 1.0000e-04\n",
            "Epoch 717/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 803.7476 - mae: 803.7476 - mse: 1931509.7500 - val_loss: 1.1834 - val_mae: 1.1834 - val_mse: 18.0855 - learning_rate: 1.0000e-04\n",
            "Epoch 718/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 821.5474 - mae: 821.5474 - mse: 1961685.2500 - val_loss: 1.1451 - val_mae: 1.1451 - val_mse: 18.2763 - learning_rate: 1.0000e-04\n",
            "Epoch 719/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 803.4106 - mae: 803.4106 - mse: 1930106.2500 - val_loss: 1.1828 - val_mae: 1.1828 - val_mse: 18.0817 - learning_rate: 1.0000e-04\n",
            "Epoch 720/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 820.2310 - mae: 820.2310 - mse: 1956734.2500 - val_loss: 1.1447 - val_mae: 1.1447 - val_mse: 18.2701 - learning_rate: 1.0000e-04\n",
            "Epoch 721/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 801.7888 - mae: 801.7888 - mse: 1924262.1250 - val_loss: 1.1808 - val_mae: 1.1808 - val_mse: 18.0700 - learning_rate: 1.0000e-04\n",
            "Epoch 722/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 815.6174 - mae: 815.6174 - mse: 1939812.1250 - val_loss: 1.1442 - val_mae: 1.1442 - val_mse: 18.2639 - learning_rate: 1.0000e-04\n",
            "Epoch 723/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 800.2175 - mae: 800.2175 - mse: 1918411.5000 - val_loss: 1.1788 - val_mae: 1.1788 - val_mse: 18.0576 - learning_rate: 1.0000e-04\n",
            "Epoch 724/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 810.4699 - mae: 810.4699 - mse: 1921057.7500 - val_loss: 1.1427 - val_mae: 1.1427 - val_mse: 18.2448 - learning_rate: 1.0000e-04\n",
            "Epoch 725/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 794.4523 - mae: 794.4523 - mse: 1897714.8750 - val_loss: 1.1783 - val_mae: 1.1783 - val_mse: 18.0542 - learning_rate: 1.0000e-04\n",
            "Epoch 726/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 808.8083 - mae: 808.8083 - mse: 1915176.0000 - val_loss: 1.1434 - val_mae: 1.1434 - val_mse: 18.2538 - learning_rate: 1.0000e-04\n",
            "Epoch 727/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 797.0817 - mae: 797.0817 - mse: 1907330.8750 - val_loss: 1.1798 - val_mae: 1.1798 - val_mse: 18.0614 - learning_rate: 1.0000e-04\n",
            "Epoch 728/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 811.9418 - mae: 811.9418 - mse: 1926607.5000 - val_loss: 1.1448 - val_mae: 1.1448 - val_mse: 18.2709 - learning_rate: 1.0000e-04\n",
            "Epoch 729/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 802.2032 - mae: 802.2032 - mse: 1926001.5000 - val_loss: 1.1835 - val_mae: 1.1835 - val_mse: 18.0815 - learning_rate: 1.0000e-04\n",
            "Epoch 730/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 821.3694 - mae: 821.3694 - mse: 1960824.5000 - val_loss: 1.1446 - val_mae: 1.1446 - val_mse: 18.2677 - learning_rate: 1.0000e-04\n",
            "Epoch 731/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 801.7780 - mae: 801.7780 - mse: 1924190.6250 - val_loss: 1.1811 - val_mae: 1.1811 - val_mse: 18.0698 - learning_rate: 1.0000e-04\n",
            "Epoch 732/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 815.2665 - mae: 815.2665 - mse: 1938533.3750 - val_loss: 1.1444 - val_mae: 1.1444 - val_mse: 18.2660 - learning_rate: 1.0000e-04\n",
            "Epoch 733/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 801.1024 - mae: 801.1024 - mse: 1921957.0000 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 18.0744 - learning_rate: 1.0000e-04\n",
            "Epoch 734/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 817.5773 - mae: 817.5773 - mse: 1946929.1250 - val_loss: 1.1446 - val_mae: 1.1446 - val_mse: 18.2688 - learning_rate: 1.0000e-04\n",
            "Epoch 735/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 802.2887 - mae: 802.2887 - mse: 1926022.5000 - val_loss: 1.1822 - val_mae: 1.1822 - val_mse: 18.0759 - learning_rate: 1.0000e-04\n",
            "Epoch 736/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 818.0720 - mae: 818.0720 - mse: 1948631.3750 - val_loss: 1.1440 - val_mae: 1.1440 - val_mse: 18.2609 - learning_rate: 1.0000e-04\n",
            "Epoch 737/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 800.4297 - mae: 800.4297 - mse: 1919187.0000 - val_loss: 1.1794 - val_mae: 1.1794 - val_mse: 18.0616 - learning_rate: 1.0000e-04\n",
            "Epoch 738/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 811.1328 - mae: 811.1328 - mse: 1923424.6250 - val_loss: 1.1435 - val_mae: 1.1435 - val_mse: 18.2546 - learning_rate: 1.0000e-04\n",
            "Epoch 739/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 798.8978 - mae: 798.8978 - mse: 1913629.5000 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.0565 - learning_rate: 1.0000e-04\n",
            "Epoch 740/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 810.1169 - mae: 810.1169 - mse: 1919761.2500 - val_loss: 1.1428 - val_mae: 1.1428 - val_mse: 18.2462 - learning_rate: 1.0000e-04\n",
            "Epoch 741/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 796.2574 - mae: 796.2574 - mse: 1904214.5000 - val_loss: 1.1782 - val_mae: 1.1782 - val_mse: 18.0511 - learning_rate: 1.0000e-04\n",
            "Epoch 742/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 807.8927 - mae: 807.8927 - mse: 1911793.1250 - val_loss: 1.1429 - val_mae: 1.1429 - val_mse: 18.2478 - learning_rate: 1.0000e-04\n",
            "Epoch 743/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 796.1000 - mae: 796.1000 - mse: 1903756.8750 - val_loss: 1.1795 - val_mae: 1.1795 - val_mse: 18.0582 - learning_rate: 1.0000e-04\n",
            "Epoch 744/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 810.6526 - mae: 810.6526 - mse: 1921749.7500 - val_loss: 1.1438 - val_mae: 1.1438 - val_mse: 18.2596 - learning_rate: 1.0000e-04\n",
            "Epoch 745/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 799.9237 - mae: 799.9237 - mse: 1917481.0000 - val_loss: 1.1811 - val_mae: 1.1811 - val_mse: 18.0670 - learning_rate: 1.0000e-04\n",
            "Epoch 746/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 814.2579 - mae: 814.2579 - mse: 1934775.2500 - val_loss: 1.1444 - val_mae: 1.1444 - val_mse: 18.2649 - learning_rate: 1.0000e-04\n",
            "Epoch 747/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 802.5513 - mae: 802.5513 - mse: 1927026.6250 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 18.0712 - learning_rate: 1.0000e-04\n",
            "Epoch 748/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 816.2083 - mae: 816.2083 - mse: 1941765.8750 - val_loss: 1.1443 - val_mae: 1.1443 - val_mse: 18.2629 - learning_rate: 1.0000e-04\n",
            "Epoch 749/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 802.1990 - mae: 802.1990 - mse: 1925666.2500 - val_loss: 1.1816 - val_mae: 1.1816 - val_mse: 18.0686 - learning_rate: 1.0000e-04\n",
            "Epoch 750/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 815.5867 - mae: 815.5867 - mse: 1939440.7500 - val_loss: 1.1444 - val_mae: 1.1444 - val_mse: 18.2650 - learning_rate: 1.0000e-04\n",
            "Epoch 751/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.6035 - mae: 802.6035 - mse: 1927048.1250 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 18.0714 - learning_rate: 1.0000e-04\n",
            "Epoch 752/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 816.4724 - mae: 816.4724 - mse: 1942523.5000 - val_loss: 1.1439 - val_mae: 1.1439 - val_mse: 18.2602 - learning_rate: 1.0000e-04\n",
            "Epoch 753/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 801.0778 - mae: 801.0778 - mse: 1921632.2500 - val_loss: 1.1811 - val_mae: 1.1811 - val_mse: 18.0675 - learning_rate: 1.0000e-04\n",
            "Epoch 754/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 814.2089 - mae: 814.2089 - mse: 1934461.0000 - val_loss: 1.1447 - val_mae: 1.1447 - val_mse: 18.2694 - learning_rate: 1.0000e-04\n",
            "Epoch 755/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804.2249 - mae: 804.2249 - mse: 1933011.2500 - val_loss: 1.1830 - val_mae: 1.1830 - val_mse: 18.0751 - learning_rate: 1.0000e-04\n",
            "Epoch 756/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 818.9315 - mae: 818.9315 - mse: 1951293.0000 - val_loss: 1.1428 - val_mae: 1.1428 - val_mse: 18.2446 - learning_rate: 1.0000e-04\n",
            "Epoch 757/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 797.1041 - mae: 797.1041 - mse: 1906741.2500 - val_loss: 1.1759 - val_mae: 1.1759 - val_mse: 18.0357 - learning_rate: 1.0000e-04\n",
            "Epoch 758/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 802.1345 - mae: 802.1345 - mse: 1890758.7500 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.2181 - learning_rate: 1.0000e-04\n",
            "Epoch 759/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 789.6256 - mae: 789.6256 - mse: 1880631.0000 - val_loss: 1.1778 - val_mae: 1.1778 - val_mse: 18.0427 - learning_rate: 1.0000e-04\n",
            "Epoch 760/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 806.3205 - mae: 806.3205 - mse: 1906005.1250 - val_loss: 1.1425 - val_mae: 1.1425 - val_mse: 18.2396 - learning_rate: 1.0000e-04\n",
            "Epoch 761/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 796.5277 - mae: 796.5277 - mse: 1905276.2500 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 18.0507 - learning_rate: 1.0000e-04\n",
            "Epoch 762/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 809.5570 - mae: 809.5570 - mse: 1917614.3750 - val_loss: 1.1435 - val_mae: 1.1435 - val_mse: 18.2536 - learning_rate: 1.0000e-04\n",
            "Epoch 763/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 800.3571 - mae: 800.3571 - mse: 1919409.0000 - val_loss: 1.1834 - val_mae: 1.1834 - val_mse: 18.0727 - learning_rate: 1.0000e-04\n",
            "Epoch 764/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 819.3097 - mae: 819.3097 - mse: 1952709.6250 - val_loss: 1.1429 - val_mae: 1.1429 - val_mse: 18.2467 - learning_rate: 1.0000e-04\n",
            "Epoch 765/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 798.7487 - mae: 798.7487 - mse: 1912715.5000 - val_loss: 1.1771 - val_mae: 1.1771 - val_mse: 18.0424 - learning_rate: 1.0000e-04\n",
            "Epoch 766/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 804.4573 - mae: 804.4573 - mse: 1898939.0000 - val_loss: 1.1411 - val_mae: 1.1411 - val_mse: 18.2213 - learning_rate: 1.0000e-04\n",
            "Epoch 767/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.2384 - mae: 791.2384 - mse: 1886221.2500 - val_loss: 1.1770 - val_mae: 1.1770 - val_mse: 18.0414 - learning_rate: 1.0000e-04\n",
            "Epoch 768/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.6339 - mae: 803.6339 - mse: 1896342.1250 - val_loss: 1.1429 - val_mae: 1.1429 - val_mse: 18.2457 - learning_rate: 1.0000e-04\n",
            "Epoch 769/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 798.9507 - mae: 798.9507 - mse: 1913970.3750 - val_loss: 1.1804 - val_mae: 1.1804 - val_mse: 18.0564 - learning_rate: 1.0000e-04\n",
            "Epoch 770/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 811.0437 - mae: 811.0437 - mse: 1922722.7500 - val_loss: 1.1427 - val_mae: 1.1427 - val_mse: 18.2431 - learning_rate: 1.0000e-04\n",
            "Epoch 771/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 798.8800 - mae: 798.8800 - mse: 1913465.0000 - val_loss: 1.1789 - val_mae: 1.1789 - val_mse: 18.0484 - learning_rate: 1.0000e-04\n",
            "Epoch 772/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.2557 - mae: 807.2557 - mse: 1909030.5000 - val_loss: 1.1420 - val_mae: 1.1420 - val_mse: 18.2310 - learning_rate: 1.0000e-04\n",
            "Epoch 773/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.4647 - mae: 795.4647 - mse: 1901409.2500 - val_loss: 1.1784 - val_mae: 1.1784 - val_mse: 18.0445 - learning_rate: 1.0000e-04\n",
            "Epoch 774/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 806.2339 - mae: 806.2339 - mse: 1905304.6250 - val_loss: 1.1415 - val_mae: 1.1415 - val_mse: 18.2252 - learning_rate: 1.0000e-04\n",
            "Epoch 775/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 793.3322 - mae: 793.3322 - mse: 1893685.1250 - val_loss: 1.1780 - val_mae: 1.1780 - val_mse: 18.0394 - learning_rate: 1.0000e-04\n",
            "Epoch 776/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 805.4081 - mae: 805.4081 - mse: 1902425.2500 - val_loss: 1.1420 - val_mae: 1.1420 - val_mse: 18.2279 - learning_rate: 1.0000e-04\n",
            "Epoch 777/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.2652 - mae: 795.2652 - mse: 1900822.5000 - val_loss: 1.1793 - val_mae: 1.1793 - val_mse: 18.0428 - learning_rate: 1.0000e-04\n",
            "Epoch 778/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.9228 - mae: 807.9228 - mse: 1911585.5000 - val_loss: 1.1431 - val_mae: 1.1431 - val_mse: 18.2413 - learning_rate: 1.0000e-04\n",
            "Epoch 779/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 799.8246 - mae: 799.8246 - mse: 1917253.6250 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 18.0543 - learning_rate: 1.0000e-04\n",
            "Epoch 780/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 813.6573 - mae: 813.6573 - mse: 1932168.2500 - val_loss: 1.1441 - val_mae: 1.1441 - val_mse: 18.2516 - learning_rate: 1.0000e-04\n",
            "Epoch 781/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.9578 - mae: 803.9578 - mse: 1932136.6250 - val_loss: 1.1829 - val_mae: 1.1829 - val_mse: 18.0608 - learning_rate: 1.0000e-04\n",
            "Epoch 782/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 815.8293 - mae: 815.8293 - mse: 1939789.7500 - val_loss: 1.1427 - val_mae: 1.1427 - val_mse: 18.2342 - learning_rate: 1.0000e-04\n",
            "Epoch 783/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.2547 - mae: 799.2547 - mse: 1914587.1250 - val_loss: 1.1772 - val_mae: 1.1772 - val_mse: 18.0333 - learning_rate: 1.0000e-04\n",
            "Epoch 784/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 802.1141 - mae: 802.1141 - mse: 1890480.8750 - val_loss: 1.1411 - val_mae: 1.1411 - val_mse: 18.2125 - learning_rate: 1.0000e-04\n",
            "Epoch 785/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 792.8060 - mae: 792.8060 - mse: 1891891.2500 - val_loss: 1.1776 - val_mae: 1.1776 - val_mse: 18.0327 - learning_rate: 1.0000e-04\n",
            "Epoch 786/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 802.8666 - mae: 802.8666 - mse: 1893330.5000 - val_loss: 1.1421 - val_mae: 1.1421 - val_mse: 18.2230 - learning_rate: 1.0000e-04\n",
            "Epoch 787/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.5412 - mae: 796.5412 - mse: 1905470.7500 - val_loss: 1.1818 - val_mae: 1.1818 - val_mse: 18.0488 - learning_rate: 1.0000e-04\n",
            "Epoch 788/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 812.5689 - mae: 812.5689 - mse: 1928219.2500 - val_loss: 1.1436 - val_mae: 1.1436 - val_mse: 18.2390 - learning_rate: 1.0000e-04\n",
            "Epoch 789/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 802.6037 - mae: 802.6037 - mse: 1927279.8750 - val_loss: 1.1827 - val_mae: 1.1827 - val_mse: 18.0513 - learning_rate: 1.0000e-04\n",
            "Epoch 790/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 814.8322 - mae: 814.8322 - mse: 1936188.1250 - val_loss: 1.1429 - val_mae: 1.1429 - val_mse: 18.2312 - learning_rate: 1.0000e-04\n",
            "Epoch 791/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.2820 - mae: 800.2820 - mse: 1918732.1250 - val_loss: 1.1809 - val_mae: 1.1809 - val_mse: 18.0450 - learning_rate: 1.0000e-04\n",
            "Epoch 792/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 810.4601 - mae: 810.4601 - mse: 1920413.6250 - val_loss: 1.1427 - val_mae: 1.1427 - val_mse: 18.2283 - learning_rate: 1.0000e-04\n",
            "Epoch 793/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.5696 - mae: 799.5696 - mse: 1915840.1250 - val_loss: 1.1781 - val_mae: 1.1781 - val_mse: 18.0317 - learning_rate: 1.0000e-04\n",
            "Epoch 794/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 803.8294 - mae: 803.8294 - mse: 1896427.6250 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1998 - learning_rate: 1.0000e-04\n",
            "Epoch 795/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 790.9145 - mae: 790.9145 - mse: 1885148.3750 - val_loss: 1.1781 - val_mae: 1.1781 - val_mse: 18.0290 - learning_rate: 1.0000e-04\n",
            "Epoch 796/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.4548 - mae: 803.4548 - mse: 1895336.5000 - val_loss: 1.1418 - val_mae: 1.1418 - val_mse: 18.2162 - learning_rate: 1.0000e-04\n",
            "Epoch 797/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.5343 - mae: 796.5343 - mse: 1905354.6250 - val_loss: 1.1815 - val_mae: 1.1815 - val_mse: 18.0424 - learning_rate: 1.0000e-04\n",
            "Epoch 798/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 811.1747 - mae: 811.1747 - mse: 1923038.5000 - val_loss: 1.1430 - val_mae: 1.1430 - val_mse: 18.2280 - learning_rate: 1.0000e-04\n",
            "Epoch 799/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.4224 - mae: 801.4224 - mse: 1923127.1250 - val_loss: 1.1835 - val_mae: 1.1835 - val_mse: 18.0510 - learning_rate: 1.0000e-04\n",
            "Epoch 800/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 815.9938 - mae: 815.9938 - mse: 1940279.8750 - val_loss: 1.1424 - val_mae: 1.1424 - val_mse: 18.2178 - learning_rate: 1.0000e-04\n",
            "Epoch 801/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.4402 - mae: 799.4402 - mse: 1915229.5000 - val_loss: 1.1780 - val_mae: 1.1780 - val_mse: 18.0251 - learning_rate: 1.0000e-04\n",
            "Epoch 802/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.9254 - mae: 802.9254 - mse: 1893257.7500 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1935 - learning_rate: 1.0000e-04\n",
            "Epoch 803/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791.7842 - mae: 791.7842 - mse: 1888271.3750 - val_loss: 1.1786 - val_mae: 1.1786 - val_mse: 18.0268 - learning_rate: 1.0000e-04\n",
            "Epoch 804/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 803.7921 - mae: 803.7921 - mse: 1896489.8750 - val_loss: 1.1413 - val_mae: 1.1413 - val_mse: 18.2022 - learning_rate: 1.0000e-04\n",
            "Epoch 805/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 794.7542 - mae: 794.7542 - mse: 1899056.8750 - val_loss: 1.1810 - val_mae: 1.1810 - val_mse: 18.0334 - learning_rate: 1.0000e-04\n",
            "Epoch 806/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 809.3552 - mae: 809.3552 - mse: 1916512.0000 - val_loss: 1.1431 - val_mae: 1.1431 - val_mse: 18.2226 - learning_rate: 1.0000e-04\n",
            "Epoch 807/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 802.5536 - mae: 802.5536 - mse: 1927150.5000 - val_loss: 1.1836 - val_mae: 1.1836 - val_mse: 18.0433 - learning_rate: 1.0000e-04\n",
            "Epoch 808/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 815.7488 - mae: 815.7488 - mse: 1939264.7500 - val_loss: 1.1418 - val_mae: 1.1418 - val_mse: 18.2049 - learning_rate: 1.0000e-04\n",
            "Epoch 809/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.1081 - mae: 798.1081 - mse: 1910469.7500 - val_loss: 1.1780 - val_mae: 1.1780 - val_mse: 18.0163 - learning_rate: 1.0000e-04\n",
            "Epoch 810/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 802.3103 - mae: 802.3103 - mse: 1891060.7500 - val_loss: 1.1403 - val_mae: 1.1403 - val_mse: 18.1821 - learning_rate: 1.0000e-04\n",
            "Epoch 811/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 791.3389 - mae: 791.3389 - mse: 1886775.0000 - val_loss: 1.1790 - val_mae: 1.1790 - val_mse: 18.0196 - learning_rate: 1.0000e-04\n",
            "Epoch 812/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804.0973 - mae: 804.0973 - mse: 1897806.0000 - val_loss: 1.1421 - val_mae: 1.1421 - val_mse: 18.2063 - learning_rate: 1.0000e-04\n",
            "Epoch 813/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 799.6569 - mae: 799.6569 - mse: 1916931.7500 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 18.0393 - learning_rate: 1.0000e-04\n",
            "Epoch 814/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 815.6389 - mae: 815.6389 - mse: 1938936.8750 - val_loss: 1.1420 - val_mae: 1.1420 - val_mse: 18.2028 - learning_rate: 1.0000e-04\n",
            "Epoch 815/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.6827 - mae: 799.6827 - mse: 1916267.7500 - val_loss: 1.1788 - val_mae: 1.1788 - val_mse: 18.0135 - learning_rate: 1.0000e-04\n",
            "Epoch 816/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 804.3154 - mae: 804.3154 - mse: 1898266.6250 - val_loss: 1.1411 - val_mae: 1.1411 - val_mse: 18.1888 - learning_rate: 1.0000e-04\n",
            "Epoch 817/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.6082 - mae: 795.6082 - mse: 1902007.1250 - val_loss: 1.1800 - val_mae: 1.1800 - val_mse: 18.0169 - learning_rate: 1.0000e-04\n",
            "Epoch 818/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 806.6535 - mae: 806.6535 - mse: 1906638.5000 - val_loss: 1.1418 - val_mae: 1.1418 - val_mse: 18.1974 - learning_rate: 1.0000e-04\n",
            "Epoch 819/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.1956 - mae: 799.1956 - mse: 1914793.5000 - val_loss: 1.1808 - val_mae: 1.1808 - val_mse: 18.0200 - learning_rate: 1.0000e-04\n",
            "Epoch 820/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 808.3934 - mae: 808.3934 - mse: 1912813.2500 - val_loss: 1.1421 - val_mae: 1.1421 - val_mse: 18.2004 - learning_rate: 1.0000e-04\n",
            "Epoch 821/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 800.7446 - mae: 800.7446 - mse: 1920548.0000 - val_loss: 1.1828 - val_mae: 1.1828 - val_mse: 18.0317 - learning_rate: 1.0000e-04\n",
            "Epoch 822/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 812.4462 - mae: 812.4462 - mse: 1927249.7500 - val_loss: 1.1412 - val_mae: 1.1412 - val_mse: 18.1889 - learning_rate: 1.0000e-04\n",
            "Epoch 823/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 797.4913 - mae: 797.4913 - mse: 1908417.6250 - val_loss: 1.1787 - val_mae: 1.1787 - val_mse: 18.0117 - learning_rate: 1.0000e-04\n",
            "Epoch 824/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.7395 - mae: 802.7395 - mse: 1892455.5000 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1713 - learning_rate: 1.0000e-04\n",
            "Epoch 825/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 792.1495 - mae: 792.1495 - mse: 1889582.6250 - val_loss: 1.1794 - val_mae: 1.1794 - val_mse: 18.0120 - learning_rate: 1.0000e-04\n",
            "Epoch 826/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.8824 - mae: 803.8824 - mse: 1896855.7500 - val_loss: 1.1413 - val_mae: 1.1413 - val_mse: 18.1871 - learning_rate: 1.0000e-04\n",
            "Epoch 827/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 798.1930 - mae: 798.1930 - mse: 1911307.2500 - val_loss: 1.1812 - val_mae: 1.1812 - val_mse: 18.0180 - learning_rate: 1.0000e-04\n",
            "Epoch 828/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 807.9236 - mae: 807.9236 - mse: 1911129.5000 - val_loss: 1.1415 - val_mae: 1.1415 - val_mse: 18.1870 - learning_rate: 1.0000e-04\n",
            "Epoch 829/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.0391 - mae: 799.0391 - mse: 1914351.3750 - val_loss: 1.1812 - val_mae: 1.1812 - val_mse: 18.0182 - learning_rate: 1.0000e-04\n",
            "Epoch 830/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.7925 - mae: 807.7925 - mse: 1910591.2500 - val_loss: 1.1413 - val_mae: 1.1413 - val_mse: 18.1844 - learning_rate: 1.0000e-04\n",
            "Epoch 831/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 798.3077 - mae: 798.3077 - mse: 1911553.0000 - val_loss: 1.1803 - val_mae: 1.1803 - val_mse: 18.0147 - learning_rate: 1.0000e-04\n",
            "Epoch 832/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.5402 - mae: 805.5402 - mse: 1902522.1250 - val_loss: 1.1411 - val_mae: 1.1411 - val_mse: 18.1822 - learning_rate: 1.0000e-04\n",
            "Epoch 833/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.5791 - mae: 797.5791 - mse: 1909015.5000 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.0127 - learning_rate: 1.0000e-04\n",
            "Epoch 834/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 804.7297 - mae: 804.7297 - mse: 1899591.8750 - val_loss: 1.1407 - val_mae: 1.1407 - val_mse: 18.1764 - learning_rate: 1.0000e-04\n",
            "Epoch 835/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.9851 - mae: 795.9851 - mse: 1903420.6250 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 18.0088 - learning_rate: 1.0000e-04\n",
            "Epoch 836/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.6010 - mae: 804.6010 - mse: 1899187.8750 - val_loss: 1.1410 - val_mae: 1.1410 - val_mse: 18.1785 - learning_rate: 1.0000e-04\n",
            "Epoch 837/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 797.2418 - mae: 797.2418 - mse: 1907902.8750 - val_loss: 1.1813 - val_mae: 1.1813 - val_mse: 18.0118 - learning_rate: 1.0000e-04\n",
            "Epoch 838/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.2068 - mae: 807.2068 - mse: 1908463.6250 - val_loss: 1.1415 - val_mae: 1.1415 - val_mse: 18.1812 - learning_rate: 1.0000e-04\n",
            "Epoch 839/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 799.0546 - mae: 799.0546 - mse: 1914604.5000 - val_loss: 1.1827 - val_mae: 1.1827 - val_mse: 18.0195 - learning_rate: 1.0000e-04\n",
            "Epoch 840/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 810.2745 - mae: 810.2745 - mse: 1919311.1250 - val_loss: 1.1412 - val_mae: 1.1412 - val_mse: 18.1753 - learning_rate: 1.0000e-04\n",
            "Epoch 841/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 798.2277 - mae: 798.2277 - mse: 1911249.0000 - val_loss: 1.1806 - val_mae: 1.1806 - val_mse: 18.0092 - learning_rate: 1.0000e-04\n",
            "Epoch 842/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 804.8251 - mae: 804.8251 - mse: 1899959.1250 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1670 - learning_rate: 1.0000e-04\n",
            "Epoch 843/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 795.8095 - mae: 795.8095 - mse: 1902859.1250 - val_loss: 1.1805 - val_mae: 1.1805 - val_mse: 18.0066 - learning_rate: 1.0000e-04\n",
            "Epoch 844/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 804.3998 - mae: 804.3998 - mse: 1898445.5000 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1684 - learning_rate: 1.0000e-04\n",
            "Epoch 845/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 796.8253 - mae: 796.8253 - mse: 1906504.7500 - val_loss: 1.1810 - val_mae: 1.1810 - val_mse: 18.0063 - learning_rate: 1.0000e-04\n",
            "Epoch 846/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 805.3144 - mae: 805.3144 - mse: 1901760.2500 - val_loss: 1.1414 - val_mae: 1.1414 - val_mse: 18.1751 - learning_rate: 1.0000e-04\n",
            "Epoch 847/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 799.3462 - mae: 799.3462 - mse: 1915766.2500 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 18.0197 - learning_rate: 1.0000e-04\n",
            "Epoch 848/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 812.2825 - mae: 812.2825 - mse: 1926414.8750 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.1662 - learning_rate: 1.0000e-04\n",
            "Epoch 849/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 797.4654 - mae: 797.4654 - mse: 1908514.7500 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 18.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 850/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 804.4084 - mae: 804.4084 - mse: 1898282.8750 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1593 - learning_rate: 1.0000e-04\n",
            "Epoch 851/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 795.8165 - mae: 795.8165 - mse: 1902950.0000 - val_loss: 1.1801 - val_mae: 1.1801 - val_mse: 17.9986 - learning_rate: 1.0000e-04\n",
            "Epoch 852/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 802.5612 - mae: 802.5612 - mse: 1891903.2500 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1606 - learning_rate: 1.0000e-04\n",
            "Epoch 853/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 797.3260 - mae: 797.3260 - mse: 1908434.3750 - val_loss: 1.1821 - val_mae: 1.1821 - val_mse: 18.0057 - learning_rate: 1.0000e-04\n",
            "Epoch 854/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 806.7313 - mae: 806.7313 - mse: 1906636.5000 - val_loss: 1.1413 - val_mae: 1.1413 - val_mse: 18.1659 - learning_rate: 1.0000e-04\n",
            "Epoch 855/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 799.8481 - mae: 799.8481 - mse: 1917824.0000 - val_loss: 1.1854 - val_mae: 1.1854 - val_mse: 18.0223 - learning_rate: 1.0000e-04\n",
            "Epoch 856/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 814.3685 - mae: 814.3685 - mse: 1933921.1250 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1542 - learning_rate: 1.0000e-04\n",
            "Epoch 857/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 796.3019 - mae: 796.3019 - mse: 1904424.7500 - val_loss: 1.1804 - val_mae: 1.1804 - val_mse: 17.9972 - learning_rate: 1.0000e-04\n",
            "Epoch 858/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 802.6923 - mae: 802.6923 - mse: 1892233.0000 - val_loss: 1.1402 - val_mae: 1.1402 - val_mse: 18.1495 - learning_rate: 1.0000e-04\n",
            "Epoch 859/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 794.9933 - mae: 794.9933 - mse: 1900188.2500 - val_loss: 1.1810 - val_mae: 1.1810 - val_mse: 17.9987 - learning_rate: 1.0000e-04\n",
            "Epoch 860/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 803.7634 - mae: 803.7634 - mse: 1896130.0000 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.1578 - learning_rate: 1.0000e-04\n",
            "Epoch 861/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 798.4301 - mae: 798.4301 - mse: 1912574.8750 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 18.0086 - learning_rate: 1.0000e-04\n",
            "Epoch 862/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 808.8723 - mae: 808.8723 - mse: 1914179.5000 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1551 - learning_rate: 1.0000e-04\n",
            "Epoch 863/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 798.1152 - mae: 798.1152 - mse: 1911134.8750 - val_loss: 1.1814 - val_mae: 1.1814 - val_mse: 17.9997 - learning_rate: 1.0000e-04\n",
            "Epoch 864/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 803.9119 - mae: 803.9119 - mse: 1896551.2500 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1494 - learning_rate: 1.0000e-04\n",
            "Epoch 865/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.7013 - mae: 796.7013 - mse: 1906293.3750 - val_loss: 1.1814 - val_mae: 1.1814 - val_mse: 17.9973 - learning_rate: 1.0000e-04\n",
            "Epoch 866/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 803.7051 - mae: 803.7051 - mse: 1895883.0000 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1480 - learning_rate: 1.0000e-04\n",
            "Epoch 867/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.2257 - mae: 797.2257 - mse: 1908197.0000 - val_loss: 1.1819 - val_mae: 1.1819 - val_mse: 17.9963 - learning_rate: 1.0000e-04\n",
            "Epoch 868/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.8508 - mae: 804.8508 - mse: 1899901.6250 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.1499 - learning_rate: 1.0000e-04\n",
            "Epoch 869/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 798.7818 - mae: 798.7818 - mse: 1914041.0000 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 18.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 870/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.5461 - mae: 807.5461 - mse: 1909457.8750 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.1488 - learning_rate: 1.0000e-04\n",
            "Epoch 871/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.9515 - mae: 798.9515 - mse: 1914588.6250 - val_loss: 1.1836 - val_mae: 1.1836 - val_mse: 18.0046 - learning_rate: 1.0000e-04\n",
            "Epoch 872/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 807.8479 - mae: 807.8479 - mse: 1910466.5000 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1446 - learning_rate: 1.0000e-04\n",
            "Epoch 873/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.9618 - mae: 797.9618 - mse: 1910948.0000 - val_loss: 1.1826 - val_mae: 1.1826 - val_mse: 17.9997 - learning_rate: 1.0000e-04\n",
            "Epoch 874/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 805.2410 - mae: 805.2410 - mse: 1901167.3750 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1401 - learning_rate: 1.0000e-04\n",
            "Epoch 875/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 797.3978 - mae: 797.3978 - mse: 1908878.2500 - val_loss: 1.1807 - val_mae: 1.1807 - val_mse: 17.9867 - learning_rate: 1.0000e-04\n",
            "Epoch 876/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 800.4734 - mae: 800.4734 - mse: 1884356.2500 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.1289 - learning_rate: 1.0000e-04\n",
            "Epoch 877/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 793.8497 - mae: 793.8497 - mse: 1896255.8750 - val_loss: 1.1806 - val_mae: 1.1806 - val_mse: 17.9812 - learning_rate: 1.0000e-04\n",
            "Epoch 878/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.1359 - mae: 800.1359 - mse: 1883242.8750 - val_loss: 1.1395 - val_mae: 1.1395 - val_mse: 18.1248 - learning_rate: 1.0000e-04\n",
            "Epoch 879/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 793.3432 - mae: 793.3432 - mse: 1894554.8750 - val_loss: 1.1821 - val_mae: 1.1821 - val_mse: 17.9873 - learning_rate: 1.0000e-04\n",
            "Epoch 880/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 802.6721 - mae: 802.6721 - mse: 1892287.7500 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1367 - learning_rate: 1.0000e-04\n",
            "Epoch 881/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.8058 - mae: 797.8058 - mse: 1910911.0000 - val_loss: 1.1852 - val_mae: 1.1852 - val_mse: 18.0049 - learning_rate: 1.0000e-04\n",
            "Epoch 882/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 809.3771 - mae: 809.3771 - mse: 1915893.7500 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1352 - learning_rate: 1.0000e-04\n",
            "Epoch 883/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.4104 - mae: 797.4104 - mse: 1908935.2500 - val_loss: 1.1820 - val_mae: 1.1820 - val_mse: 17.9881 - learning_rate: 1.0000e-04\n",
            "Epoch 884/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.9313 - mae: 801.9313 - mse: 1889461.7500 - val_loss: 1.1399 - val_mae: 1.1399 - val_mse: 18.1265 - learning_rate: 1.0000e-04\n",
            "Epoch 885/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.7255 - mae: 794.7255 - mse: 1899549.2500 - val_loss: 1.1816 - val_mae: 1.1816 - val_mse: 17.9832 - learning_rate: 1.0000e-04\n",
            "Epoch 886/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.6938 - mae: 800.6938 - mse: 1885190.1250 - val_loss: 1.1398 - val_mae: 1.1398 - val_mse: 18.1220 - learning_rate: 1.0000e-04\n",
            "Epoch 887/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 794.4568 - mae: 794.4568 - mse: 1898746.6250 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 17.9888 - learning_rate: 1.0000e-04\n",
            "Epoch 888/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 803.9107 - mae: 803.9107 - mse: 1896596.5000 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1307 - learning_rate: 1.0000e-04\n",
            "Epoch 889/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.2097 - mae: 798.2097 - mse: 1912756.6250 - val_loss: 1.1866 - val_mae: 1.1866 - val_mse: 18.0070 - learning_rate: 1.0000e-04\n",
            "Epoch 890/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 811.5006 - mae: 811.5006 - mse: 1923433.3750 - val_loss: 1.1399 - val_mae: 1.1399 - val_mse: 18.1217 - learning_rate: 1.0000e-04\n",
            "Epoch 891/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 795.0561 - mae: 795.0561 - mse: 1900603.5000 - val_loss: 1.1803 - val_mae: 1.1803 - val_mse: 17.9728 - learning_rate: 1.0000e-04\n",
            "Epoch 892/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 797.2729 - mae: 797.2729 - mse: 1873169.5000 - val_loss: 1.1392 - val_mae: 1.1392 - val_mse: 18.1108 - learning_rate: 1.0000e-04\n",
            "Epoch 893/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 792.0229 - mae: 792.0229 - mse: 1890337.0000 - val_loss: 1.1823 - val_mae: 1.1823 - val_mse: 17.9821 - learning_rate: 1.0000e-04\n",
            "Epoch 894/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.1794 - mae: 801.1794 - mse: 1886956.7500 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1290 - learning_rate: 1.0000e-04\n",
            "Epoch 895/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 796.8972 - mae: 796.8972 - mse: 1908004.5000 - val_loss: 1.1848 - val_mae: 1.1848 - val_mse: 17.9953 - learning_rate: 1.0000e-04\n",
            "Epoch 896/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 806.7740 - mae: 806.7740 - mse: 1906553.5000 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1290 - learning_rate: 1.0000e-04\n",
            "Epoch 897/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.5351 - mae: 797.5351 - mse: 1910139.2500 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 17.9958 - learning_rate: 1.0000e-04\n",
            "Epoch 898/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 806.7321 - mae: 806.7321 - mse: 1906244.0000 - val_loss: 1.1395 - val_mae: 1.1395 - val_mse: 18.1129 - learning_rate: 1.0000e-04\n",
            "Epoch 899/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 793.4543 - mae: 793.4543 - mse: 1895299.3750 - val_loss: 1.1814 - val_mae: 1.1814 - val_mse: 17.9741 - learning_rate: 1.0000e-04\n",
            "Epoch 900/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 798.0723 - mae: 798.0723 - mse: 1875969.2500 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.1085 - learning_rate: 1.0000e-04\n",
            "Epoch 901/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 793.8416 - mae: 793.8416 - mse: 1897097.1250 - val_loss: 1.1837 - val_mae: 1.1837 - val_mse: 17.9808 - learning_rate: 1.0000e-04\n",
            "Epoch 902/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 802.6655 - mae: 802.6655 - mse: 1892160.1250 - val_loss: 1.1401 - val_mae: 1.1401 - val_mse: 18.1125 - learning_rate: 1.0000e-04\n",
            "Epoch 903/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.5593 - mae: 796.5593 - mse: 1906955.0000 - val_loss: 1.1843 - val_mae: 1.1843 - val_mse: 17.9823 - learning_rate: 1.0000e-04\n",
            "Epoch 904/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 803.7372 - mae: 803.7372 - mse: 1895848.6250 - val_loss: 1.1399 - val_mae: 1.1399 - val_mse: 18.1076 - learning_rate: 1.0000e-04\n",
            "Epoch 905/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.6753 - mae: 795.6753 - mse: 1903870.3750 - val_loss: 1.1838 - val_mae: 1.1838 - val_mse: 17.9783 - learning_rate: 1.0000e-04\n",
            "Epoch 906/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 802.3264 - mae: 802.3264 - mse: 1890982.3750 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.1015 - learning_rate: 1.0000e-04\n",
            "Epoch 907/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.2857 - mae: 794.2857 - mse: 1899017.5000 - val_loss: 1.1832 - val_mae: 1.1832 - val_mse: 17.9733 - learning_rate: 1.0000e-04\n",
            "Epoch 908/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.7490 - mae: 800.7490 - mse: 1885444.2500 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.1002 - learning_rate: 1.0000e-04\n",
            "Epoch 909/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 793.7939 - mae: 793.7939 - mse: 1897518.2500 - val_loss: 1.1849 - val_mae: 1.1849 - val_mse: 17.9806 - learning_rate: 1.0000e-04\n",
            "Epoch 910/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.1181 - mae: 804.1181 - mse: 1897384.8750 - val_loss: 1.1399 - val_mae: 1.1399 - val_mse: 18.1018 - learning_rate: 1.0000e-04\n",
            "Epoch 911/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 795.2750 - mae: 795.2750 - mse: 1902939.5000 - val_loss: 1.1839 - val_mae: 1.1839 - val_mse: 17.9763 - learning_rate: 1.0000e-04\n",
            "Epoch 912/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 801.3556 - mae: 801.3556 - mse: 1887679.2500 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.0988 - learning_rate: 1.0000e-04\n",
            "Epoch 913/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 794.2946 - mae: 794.2946 - mse: 1899559.7500 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 17.9715 - learning_rate: 1.0000e-04\n",
            "Epoch 914/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 799.2180 - mae: 799.2180 - mse: 1880121.0000 - val_loss: 1.1395 - val_mae: 1.1395 - val_mse: 18.0961 - learning_rate: 1.0000e-04\n",
            "Epoch 915/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 793.1021 - mae: 793.1021 - mse: 1895422.7500 - val_loss: 1.1842 - val_mae: 1.1842 - val_mse: 17.9757 - learning_rate: 1.0000e-04\n",
            "Epoch 916/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.5777 - mae: 801.5777 - mse: 1888501.5000 - val_loss: 1.1402 - val_mae: 1.1402 - val_mse: 18.1045 - learning_rate: 1.0000e-04\n",
            "Epoch 917/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 795.7989 - mae: 795.7989 - mse: 1905468.5000 - val_loss: 1.1866 - val_mae: 1.1866 - val_mse: 17.9888 - learning_rate: 1.0000e-04\n",
            "Epoch 918/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 806.5356 - mae: 806.5356 - mse: 1905984.5000 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1077 - learning_rate: 1.0000e-04\n",
            "Epoch 919/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 797.3652 - mae: 797.3652 - mse: 1911275.5000 - val_loss: 1.1881 - val_mae: 1.1881 - val_mse: 17.9967 - learning_rate: 1.0000e-04\n",
            "Epoch 920/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 809.6578 - mae: 809.6578 - mse: 1916872.8750 - val_loss: 1.1397 - val_mae: 1.1397 - val_mse: 18.0973 - learning_rate: 1.0000e-04\n",
            "Epoch 921/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.3228 - mae: 794.3228 - mse: 1899740.7500 - val_loss: 1.1831 - val_mae: 1.1831 - val_mse: 17.9698 - learning_rate: 1.0000e-04\n",
            "Epoch 922/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 798.1437 - mae: 798.1437 - mse: 1876244.8750 - val_loss: 1.1388 - val_mae: 1.1388 - val_mse: 18.0850 - learning_rate: 1.0000e-04\n",
            "Epoch 923/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 790.8854 - mae: 790.8854 - mse: 1887884.0000 - val_loss: 1.1827 - val_mae: 1.1827 - val_mse: 17.9667 - learning_rate: 1.0000e-04\n",
            "Epoch 924/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.9358 - mae: 796.9358 - mse: 1872192.5000 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1059 - learning_rate: 1.0000e-04\n",
            "Epoch 925/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.1953 - mae: 795.1953 - mse: 1903742.7500 - val_loss: 1.1871 - val_mae: 1.1871 - val_mse: 17.9888 - learning_rate: 1.0000e-04\n",
            "Epoch 926/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 806.7769 - mae: 806.7769 - mse: 1906635.2500 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1077 - learning_rate: 1.0000e-04\n",
            "Epoch 927/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 795.3459 - mae: 795.3459 - mse: 1904120.2500 - val_loss: 1.1851 - val_mae: 1.1851 - val_mse: 17.9809 - learning_rate: 1.0000e-04\n",
            "Epoch 928/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 801.5042 - mae: 801.5042 - mse: 1888124.1250 - val_loss: 1.1401 - val_mae: 1.1401 - val_mse: 18.1073 - learning_rate: 1.0000e-04\n",
            "Epoch 929/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 795.1882 - mae: 795.1882 - mse: 1904187.7500 - val_loss: 1.1882 - val_mae: 1.1882 - val_mse: 18.0004 - learning_rate: 1.0000e-04\n",
            "Epoch 930/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 807.7594 - mae: 807.7594 - mse: 1910230.1250 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1093 - learning_rate: 1.0000e-04\n",
            "Epoch 931/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.5041 - mae: 796.5041 - mse: 1908959.7500 - val_loss: 1.1885 - val_mae: 1.1885 - val_mse: 18.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 932/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 808.0369 - mae: 808.0369 - mse: 1911271.2500 - val_loss: 1.1410 - val_mae: 1.1410 - val_mse: 18.1150 - learning_rate: 1.0000e-04\n",
            "Epoch 933/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 798.9633 - mae: 798.9633 - mse: 1917791.1250 - val_loss: 1.1881 - val_mae: 1.1881 - val_mse: 17.9963 - learning_rate: 1.0000e-04\n",
            "Epoch 934/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 807.3866 - mae: 807.3866 - mse: 1908850.6250 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1125 - learning_rate: 1.0000e-04\n",
            "Epoch 935/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 798.3779 - mae: 798.3779 - mse: 1915769.2500 - val_loss: 1.1872 - val_mae: 1.1872 - val_mse: 17.9906 - learning_rate: 1.0000e-04\n",
            "Epoch 936/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.1508 - mae: 805.1508 - mse: 1900646.5000 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.0974 - learning_rate: 1.0000e-04\n",
            "Epoch 937/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 793.6786 - mae: 793.6786 - mse: 1898727.2500 - val_loss: 1.1833 - val_mae: 1.1833 - val_mse: 17.9691 - learning_rate: 1.0000e-04\n",
            "Epoch 938/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.1925 - mae: 795.1925 - mse: 1865988.1250 - val_loss: 1.1392 - val_mae: 1.1392 - val_mse: 18.0864 - learning_rate: 1.0000e-04\n",
            "Epoch 939/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 792.5165 - mae: 792.5165 - mse: 1895272.1250 - val_loss: 1.1854 - val_mae: 1.1854 - val_mse: 17.9825 - learning_rate: 1.0000e-04\n",
            "Epoch 940/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 799.2552 - mae: 799.2552 - mse: 1880294.6250 - val_loss: 1.1394 - val_mae: 1.1394 - val_mse: 18.0958 - learning_rate: 1.0000e-04\n",
            "Epoch 941/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 792.4227 - mae: 792.4227 - mse: 1895084.3750 - val_loss: 1.1853 - val_mae: 1.1853 - val_mse: 17.9867 - learning_rate: 1.0000e-04\n",
            "Epoch 942/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.0677 - mae: 798.0677 - mse: 1876401.2500 - val_loss: 1.1402 - val_mae: 1.1402 - val_mse: 18.1092 - learning_rate: 1.0000e-04\n",
            "Epoch 943/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 795.2414 - mae: 795.2414 - mse: 1905969.1250 - val_loss: 1.1909 - val_mae: 1.1909 - val_mse: 18.0179 - learning_rate: 1.0000e-04\n",
            "Epoch 944/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 810.5339 - mae: 810.5339 - mse: 1919980.5000 - val_loss: 1.1409 - val_mae: 1.1409 - val_mse: 18.1197 - learning_rate: 1.0000e-04\n",
            "Epoch 945/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.5025 - mae: 797.5025 - mse: 1913852.2500 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.0059 - learning_rate: 1.0000e-04\n",
            "Epoch 946/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 806.2540 - mae: 806.2540 - mse: 1904806.5000 - val_loss: 1.1407 - val_mae: 1.1407 - val_mse: 18.1234 - learning_rate: 1.0000e-04\n",
            "Epoch 947/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.6583 - mae: 796.6583 - mse: 1910960.2500 - val_loss: 1.1887 - val_mae: 1.1887 - val_mse: 18.0038 - learning_rate: 1.0000e-04\n",
            "Epoch 948/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 805.5010 - mae: 805.5010 - mse: 1902174.6250 - val_loss: 1.1410 - val_mae: 1.1410 - val_mse: 18.1250 - learning_rate: 1.0000e-04\n",
            "Epoch 949/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 797.9362 - mae: 797.9362 - mse: 1915804.3750 - val_loss: 1.1897 - val_mae: 1.1897 - val_mse: 18.0095 - learning_rate: 1.0000e-04\n",
            "Epoch 950/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 807.3926 - mae: 807.3926 - mse: 1908765.2500 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1157 - learning_rate: 1.0000e-04\n",
            "Epoch 951/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 796.0386 - mae: 796.0386 - mse: 1909091.8750 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 952/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805.1767 - mae: 805.1767 - mse: 1901128.6250 - val_loss: 1.1406 - val_mae: 1.1406 - val_mse: 18.1235 - learning_rate: 1.0000e-04\n",
            "Epoch 953/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 797.3928 - mae: 797.3928 - mse: 1914038.6250 - val_loss: 1.1900 - val_mae: 1.1900 - val_mse: 18.0125 - learning_rate: 1.0000e-04\n",
            "Epoch 954/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 807.5540 - mae: 807.5540 - mse: 1909434.0000 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1225 - learning_rate: 1.0000e-04\n",
            "Epoch 955/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.4447 - mae: 796.4447 - mse: 1910651.6250 - val_loss: 1.1886 - val_mae: 1.1886 - val_mse: 18.0069 - learning_rate: 1.0000e-04\n",
            "Epoch 956/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.3508 - mae: 804.3508 - mse: 1898261.6250 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1204 - learning_rate: 1.0000e-04\n",
            "Epoch 957/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 796.1243 - mae: 796.1243 - mse: 1909794.2500 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.0101 - learning_rate: 1.0000e-04\n",
            "Epoch 958/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 804.5851 - mae: 804.5851 - mse: 1899232.1250 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1262 - learning_rate: 1.0000e-04\n",
            "Epoch 959/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 797.4446 - mae: 797.4446 - mse: 1914522.2500 - val_loss: 1.1893 - val_mae: 1.1893 - val_mse: 18.0125 - learning_rate: 1.0000e-04\n",
            "Epoch 960/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 805.1886 - mae: 805.1886 - mse: 1901296.8750 - val_loss: 1.1408 - val_mae: 1.1408 - val_mse: 18.1289 - learning_rate: 1.0000e-04\n",
            "Epoch 961/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 797.4174 - mae: 797.4174 - mse: 1914725.1250 - val_loss: 1.1899 - val_mae: 1.1899 - val_mse: 18.0160 - learning_rate: 1.0000e-04\n",
            "Epoch 962/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 806.1329 - mae: 806.1329 - mse: 1904634.0000 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1236 - learning_rate: 1.0000e-04\n",
            "Epoch 963/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 796.2365 - mae: 796.2365 - mse: 1910562.0000 - val_loss: 1.1883 - val_mae: 1.1883 - val_mse: 18.0079 - learning_rate: 1.0000e-04\n",
            "Epoch 964/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 802.1176 - mae: 802.1176 - mse: 1890755.8750 - val_loss: 1.1401 - val_mae: 1.1401 - val_mse: 18.1210 - learning_rate: 1.0000e-04\n",
            "Epoch 965/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 794.6429 - mae: 794.6429 - mse: 1905017.2500 - val_loss: 1.1877 - val_mae: 1.1877 - val_mse: 18.0076 - learning_rate: 1.0000e-04\n",
            "Epoch 966/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 800.2110 - mae: 800.2110 - mse: 1884180.6250 - val_loss: 1.1396 - val_mae: 1.1396 - val_mse: 18.1168 - learning_rate: 1.0000e-04\n",
            "Epoch 967/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 792.5913 - mae: 792.5913 - mse: 1897892.7500 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 18.0117 - learning_rate: 1.0000e-04\n",
            "Epoch 968/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 801.3931 - mae: 801.3931 - mse: 1888375.2500 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1247 - learning_rate: 1.0000e-04\n",
            "Epoch 969/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 793.9984 - mae: 793.9984 - mse: 1902916.0000 - val_loss: 1.1882 - val_mae: 1.1882 - val_mse: 18.0111 - learning_rate: 1.0000e-04\n",
            "Epoch 970/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 800.6183 - mae: 800.6183 - mse: 1885704.2500 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1259 - learning_rate: 1.0000e-04\n",
            "Epoch 971/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 793.9990 - mae: 793.9990 - mse: 1903039.7500 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 18.0128 - learning_rate: 1.0000e-04\n",
            "Epoch 972/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 800.8459 - mae: 800.8459 - mse: 1886458.3750 - val_loss: 1.1401 - val_mae: 1.1401 - val_mse: 18.1270 - learning_rate: 1.0000e-04\n",
            "Epoch 973/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 793.6544 - mae: 793.6544 - mse: 1901842.6250 - val_loss: 1.1881 - val_mae: 1.1881 - val_mse: 18.0119 - learning_rate: 1.0000e-04\n",
            "Epoch 974/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 800.1933 - mae: 800.1933 - mse: 1884225.1250 - val_loss: 1.1401 - val_mae: 1.1401 - val_mse: 18.1309 - learning_rate: 1.0000e-04\n",
            "Epoch 975/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 793.2549 - mae: 793.2549 - mse: 1900533.2500 - val_loss: 1.1888 - val_mae: 1.1888 - val_mse: 18.0179 - learning_rate: 1.0000e-04\n",
            "Epoch 976/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 801.2341 - mae: 801.2341 - mse: 1887842.7500 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1311 - learning_rate: 1.0000e-04\n",
            "Epoch 977/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 792.6282 - mae: 792.6282 - mse: 1898350.3750 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.0189 - learning_rate: 1.0000e-04\n",
            "Epoch 978/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 801.0543 - mae: 801.0543 - mse: 1887226.5000 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1310 - learning_rate: 1.0000e-04\n",
            "Epoch 979/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 792.8018 - mae: 792.8018 - mse: 1898987.6250 - val_loss: 1.1887 - val_mae: 1.1887 - val_mse: 18.0186 - learning_rate: 1.0000e-04\n",
            "Epoch 980/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 800.4102 - mae: 800.4102 - mse: 1885019.7500 - val_loss: 1.1402 - val_mae: 1.1402 - val_mse: 18.1358 - learning_rate: 1.0000e-04\n",
            "Epoch 981/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 793.4265 - mae: 793.4265 - mse: 1901222.2500 - val_loss: 1.1888 - val_mae: 1.1888 - val_mse: 18.0198 - learning_rate: 1.0000e-04\n",
            "Epoch 982/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.3409 - mae: 800.3409 - mse: 1884765.3750 - val_loss: 1.1403 - val_mae: 1.1403 - val_mse: 18.1384 - learning_rate: 1.0000e-04\n",
            "Epoch 983/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 793.9455 - mae: 793.9455 - mse: 1903075.3750 - val_loss: 1.1884 - val_mae: 1.1884 - val_mse: 18.0176 - learning_rate: 1.0000e-04\n",
            "Epoch 984/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 799.2091 - mae: 799.2091 - mse: 1880880.5000 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1350 - learning_rate: 1.0000e-04\n",
            "Epoch 985/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 792.6992 - mae: 792.6992 - mse: 1898818.1250 - val_loss: 1.1897 - val_mae: 1.1897 - val_mse: 18.0266 - learning_rate: 1.0000e-04\n",
            "Epoch 986/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 801.4641 - mae: 801.4641 - mse: 1888657.8750 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1448 - learning_rate: 1.0000e-04\n",
            "Epoch 987/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.3422 - mae: 794.3422 - mse: 1904606.0000 - val_loss: 1.1894 - val_mae: 1.1894 - val_mse: 18.0266 - learning_rate: 1.0000e-04\n",
            "Epoch 988/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 800.3267 - mae: 800.3267 - mse: 1884703.6250 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1465 - learning_rate: 1.0000e-04\n",
            "Epoch 989/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.5543 - mae: 794.5543 - mse: 1905456.0000 - val_loss: 1.1901 - val_mae: 1.1901 - val_mse: 18.0297 - learning_rate: 1.0000e-04\n",
            "Epoch 990/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 801.9970 - mae: 801.9970 - mse: 1890410.3750 - val_loss: 1.1400 - val_mae: 1.1400 - val_mse: 18.1407 - learning_rate: 1.0000e-04\n",
            "Epoch 991/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 792.1056 - mae: 792.1056 - mse: 1896598.8750 - val_loss: 1.1891 - val_mae: 1.1891 - val_mse: 18.0247 - learning_rate: 1.0000e-04\n",
            "Epoch 992/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 799.7894 - mae: 799.7894 - mse: 1882870.7500 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1469 - learning_rate: 1.0000e-04\n",
            "Epoch 993/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 794.1876 - mae: 794.1876 - mse: 1903988.0000 - val_loss: 1.1889 - val_mae: 1.1889 - val_mse: 18.0254 - learning_rate: 1.0000e-04\n",
            "Epoch 994/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 798.8719 - mae: 798.8719 - mse: 1879628.2500 - val_loss: 1.1405 - val_mae: 1.1405 - val_mse: 18.1494 - learning_rate: 1.0000e-04\n",
            "Epoch 995/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.0943 - mae: 794.0943 - mse: 1903686.8750 - val_loss: 1.1891 - val_mae: 1.1891 - val_mse: 18.0275 - learning_rate: 1.0000e-04\n",
            "Epoch 996/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 798.8893 - mae: 798.8893 - mse: 1879713.2500 - val_loss: 1.1407 - val_mae: 1.1407 - val_mse: 18.1543 - learning_rate: 1.0000e-04\n",
            "Epoch 997/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 794.7020 - mae: 794.7020 - mse: 1905902.8750 - val_loss: 1.1899 - val_mae: 1.1899 - val_mse: 18.0318 - learning_rate: 1.0000e-04\n",
            "Epoch 998/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 800.1863 - mae: 800.1863 - mse: 1884064.8750 - val_loss: 1.1404 - val_mae: 1.1404 - val_mse: 18.1505 - learning_rate: 1.0000e-04\n",
            "Epoch 999/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 793.3085 - mae: 793.3085 - mse: 1900822.1250 - val_loss: 1.1893 - val_mae: 1.1893 - val_mse: 18.0291 - learning_rate: 1.0000e-04\n",
            "Epoch 1000/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 798.4880 - mae: 798.4880 - mse: 1878237.1250 - val_loss: 1.1407 - val_mae: 1.1407 - val_mse: 18.1540 - learning_rate: 1.0000e-04\n",
            "Epoch 1/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 406ms/step - loss: 665282112.0000 - mae: 16156.4355 - mse: 665282112.0000 - val_loss: 2504.9246 - val_mae: 23.9471 - val_mse: 2504.9246 - learning_rate: 0.0010\n",
            "Epoch 2/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3163082496.0000 - mae: 39362.9297 - mse: 3163082496.0000 - val_loss: 267.7001 - val_mae: 5.6909 - val_mse: 267.7001 - learning_rate: 0.0010\n",
            "Epoch 3/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 77698024.0000 - mae: 5614.8599 - mse: 77698024.0000 - val_loss: 764.8415 - val_mae: 11.6853 - val_mse: 764.8415 - learning_rate: 0.0010\n",
            "Epoch 4/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 817091904.0000 - mae: 20411.9980 - mse: 817091904.0000 - val_loss: 460.3825 - val_mae: 8.0015 - val_mse: 460.3825 - learning_rate: 0.0010\n",
            "Epoch 5/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 355295712.0000 - mae: 12704.3047 - mse: 355295712.0000 - val_loss: 233.9173 - val_mae: 5.0197 - val_mse: 233.9173 - learning_rate: 0.0010\n",
            "Epoch 6/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 52400528.0000 - mae: 4816.3335 - mse: 52400528.0000 - val_loss: 364.3743 - val_mae: 7.6728 - val_mse: 364.3743 - learning_rate: 0.0010\n",
            "Epoch 7/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 231689840.0000 - mae: 10402.4707 - mse: 231689840.0000 - val_loss: 221.9922 - val_mae: 4.8564 - val_mse: 221.9922 - learning_rate: 0.0010\n",
            "Epoch 8/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 39946008.0000 - mae: 3909.7024 - mse: 39946008.0000 - val_loss: 229.0727 - val_mae: 4.5243 - val_mse: 229.0727 - learning_rate: 0.0010\n",
            "Epoch 9/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 67229152.0000 - mae: 5321.5171 - mse: 67229152.0000 - val_loss: 212.1904 - val_mae: 4.2549 - val_mse: 212.1904 - learning_rate: 0.0010\n",
            "Epoch 10/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 49915792.0000 - mae: 4418.5806 - mse: 49915792.0000 - val_loss: 182.1090 - val_mae: 4.1202 - val_mse: 182.1090 - learning_rate: 0.0010\n",
            "Epoch 11/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23296616.0000 - mae: 2995.7939 - mse: 23296616.0000 - val_loss: 175.5280 - val_mae: 4.2896 - val_mse: 175.5280 - learning_rate: 0.0010\n",
            "Epoch 12/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 33794140.0000 - mae: 3678.2356 - mse: 33794140.0000 - val_loss: 151.4080 - val_mae: 3.3938 - val_mse: 151.4080 - learning_rate: 0.0010\n",
            "Epoch 13/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15015011.0000 - mae: 2279.9900 - mse: 15015011.0000 - val_loss: 144.8419 - val_mae: 3.1832 - val_mse: 144.8419 - learning_rate: 0.0010\n",
            "Epoch 14/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20183230.0000 - mae: 2708.4006 - mse: 20183230.0000 - val_loss: 122.7519 - val_mae: 2.9643 - val_mse: 122.7519 - learning_rate: 0.0010\n",
            "Epoch 15/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11213666.0000 - mae: 1960.2316 - mse: 11213666.0000 - val_loss: 106.4331 - val_mae: 2.8368 - val_mse: 106.4331 - learning_rate: 0.0010\n",
            "Epoch 16/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11725850.0000 - mae: 2077.4346 - mse: 11725850.0000 - val_loss: 90.9961 - val_mae: 2.3668 - val_mse: 90.9961 - learning_rate: 0.0010\n",
            "Epoch 17/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7147888.5000 - mae: 1558.6313 - mse: 7147888.5000 - val_loss: 78.3584 - val_mae: 2.1553 - val_mse: 78.3584 - learning_rate: 0.0010\n",
            "Epoch 18/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5952976.5000 - mae: 1440.4528 - mse: 5952976.5000 - val_loss: 66.0135 - val_mae: 2.0277 - val_mse: 66.0135 - learning_rate: 0.0010\n",
            "Epoch 19/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6560083.0000 - mae: 1572.4801 - mse: 6560083.0000 - val_loss: 63.0044 - val_mae: 1.9261 - val_mse: 63.0044 - learning_rate: 0.0010\n",
            "Epoch 20/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5717583.0000 - mae: 1433.5140 - mse: 5717583.0000 - val_loss: 54.6507 - val_mae: 1.8388 - val_mse: 54.6507 - learning_rate: 0.0010\n",
            "Epoch 21/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5357409.0000 - mae: 1424.6694 - mse: 5357409.0000 - val_loss: 54.7693 - val_mae: 1.7687 - val_mse: 54.7693 - learning_rate: 0.0010\n",
            "Epoch 22/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4651120.5000 - mae: 1284.4943 - mse: 4651120.5000 - val_loss: 50.8950 - val_mae: 1.7259 - val_mse: 50.8950 - learning_rate: 0.0010\n",
            "Epoch 23/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4012809.5000 - mae: 1216.4625 - mse: 4012809.5000 - val_loss: 49.2562 - val_mae: 1.6628 - val_mse: 49.2562 - learning_rate: 0.0010\n",
            "Epoch 24/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3518252.5000 - mae: 1117.4913 - mse: 3518252.5000 - val_loss: 46.8767 - val_mae: 1.6262 - val_mse: 46.8767 - learning_rate: 0.0010\n",
            "Epoch 25/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3304083.2500 - mae: 1085.0061 - mse: 3304083.2500 - val_loss: 44.8480 - val_mae: 1.6132 - val_mse: 44.8480 - learning_rate: 0.0010\n",
            "Epoch 26/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3233805.0000 - mae: 1074.6923 - mse: 3233805.0000 - val_loss: 43.5394 - val_mae: 1.5667 - val_mse: 43.5394 - learning_rate: 0.0010\n",
            "Epoch 27/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3201303.2500 - mae: 1075.4436 - mse: 3201303.2500 - val_loss: 42.6141 - val_mae: 1.5932 - val_mse: 42.6141 - learning_rate: 0.0010\n",
            "Epoch 28/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3166568.0000 - mae: 1064.3275 - mse: 3166568.0000 - val_loss: 42.2252 - val_mae: 1.5429 - val_mse: 42.2252 - learning_rate: 0.0010\n",
            "Epoch 29/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3171827.5000 - mae: 1074.1963 - mse: 3171827.5000 - val_loss: 41.8244 - val_mae: 1.6012 - val_mse: 41.8244 - learning_rate: 0.0010\n",
            "Epoch 30/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3258759.5000 - mae: 1087.1703 - mse: 3258759.5000 - val_loss: 40.8894 - val_mae: 1.5222 - val_mse: 40.8894 - learning_rate: 0.0010\n",
            "Epoch 31/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3402603.0000 - mae: 1121.7432 - mse: 3402603.0000 - val_loss: 40.5464 - val_mae: 1.6299 - val_mse: 40.5464 - learning_rate: 0.0010\n",
            "Epoch 32/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3735586.0000 - mae: 1173.0946 - mse: 3735586.0000 - val_loss: 39.8636 - val_mae: 1.5421 - val_mse: 39.8636 - learning_rate: 0.0010\n",
            "Epoch 33/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4379219.0000 - mae: 1282.5682 - mse: 4379219.0000 - val_loss: 40.9481 - val_mae: 1.7429 - val_mse: 40.9481 - learning_rate: 0.0010\n",
            "Epoch 34/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5234114.0000 - mae: 1412.6858 - mse: 5234114.0000 - val_loss: 40.4118 - val_mae: 1.6292 - val_mse: 40.4118 - learning_rate: 0.0010\n",
            "Epoch 35/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6295723.0000 - mae: 1553.0266 - mse: 6295723.0000 - val_loss: 41.7061 - val_mae: 1.8336 - val_mse: 41.7061 - learning_rate: 0.0010\n",
            "Epoch 36/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6652152.0000 - mae: 1615.7830 - mse: 6652152.0000 - val_loss: 39.7956 - val_mae: 1.6154 - val_mse: 39.7956 - learning_rate: 0.0010\n",
            "Epoch 37/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6227677.0000 - mae: 1547.8071 - mse: 6227677.0000 - val_loss: 39.9002 - val_mae: 1.7270 - val_mse: 39.9002 - learning_rate: 0.0010\n",
            "Epoch 38/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5105497.0000 - mae: 1400.5865 - mse: 5105497.0000 - val_loss: 37.4769 - val_mae: 1.4928 - val_mse: 37.4769 - learning_rate: 0.0010\n",
            "Epoch 39/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4055278.2500 - mae: 1236.6396 - mse: 4055278.2500 - val_loss: 37.0508 - val_mae: 1.5549 - val_mse: 37.0508 - learning_rate: 0.0010\n",
            "Epoch 40/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3278494.7500 - mae: 1092.3137 - mse: 3278494.7500 - val_loss: 35.8056 - val_mae: 1.4309 - val_mse: 35.8056 - learning_rate: 0.0010\n",
            "Epoch 41/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2871347.7500 - mae: 1025.2430 - mse: 2871347.7500 - val_loss: 35.5902 - val_mae: 1.4673 - val_mse: 35.5902 - learning_rate: 0.0010\n",
            "Epoch 42/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2671477.5000 - mae: 974.4023 - mse: 2671477.5000 - val_loss: 34.9145 - val_mae: 1.4184 - val_mse: 34.9145 - learning_rate: 0.0010\n",
            "Epoch 43/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2589681.7500 - mae: 963.9641 - mse: 2589681.7500 - val_loss: 34.6371 - val_mae: 1.4293 - val_mse: 34.6371 - learning_rate: 0.0010\n",
            "Epoch 44/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2539510.0000 - mae: 948.2424 - mse: 2539510.0000 - val_loss: 34.0814 - val_mae: 1.4038 - val_mse: 34.0814 - learning_rate: 0.0010\n",
            "Epoch 45/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2509653.0000 - mae: 945.3621 - mse: 2509653.0000 - val_loss: 33.7139 - val_mae: 1.4060 - val_mse: 33.7139 - learning_rate: 0.0010\n",
            "Epoch 46/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2481681.2500 - mae: 936.6984 - mse: 2481681.2500 - val_loss: 33.1948 - val_mae: 1.3847 - val_mse: 33.1948 - learning_rate: 0.0010\n",
            "Epoch 47/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2460607.7500 - mae: 934.5535 - mse: 2460607.7500 - val_loss: 32.8584 - val_mae: 1.3891 - val_mse: 32.8584 - learning_rate: 0.0010\n",
            "Epoch 48/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2440994.5000 - mae: 927.3411 - mse: 2440994.5000 - val_loss: 32.3484 - val_mae: 1.3639 - val_mse: 32.3484 - learning_rate: 0.0010\n",
            "Epoch 49/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2432447.5000 - mae: 929.5994 - mse: 2432447.5000 - val_loss: 32.1946 - val_mae: 1.3828 - val_mse: 32.1946 - learning_rate: 0.0010\n",
            "Epoch 50/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2430688.7500 - mae: 924.3601 - mse: 2430688.7500 - val_loss: 31.5970 - val_mae: 1.3436 - val_mse: 31.5970 - learning_rate: 0.0010\n",
            "Epoch 51/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2472734.7500 - mae: 941.9939 - mse: 2472734.7500 - val_loss: 31.7894 - val_mae: 1.4022 - val_mse: 31.7894 - learning_rate: 0.0010\n",
            "Epoch 52/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2586500.7500 - mae: 957.0337 - mse: 2586500.7500 - val_loss: 31.0084 - val_mae: 1.3428 - val_mse: 31.0084 - learning_rate: 0.0010\n",
            "Epoch 53/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2962726.0000 - mae: 1044.5996 - mse: 2962726.0000 - val_loss: 32.4865 - val_mae: 1.5291 - val_mse: 32.4865 - learning_rate: 0.0010\n",
            "Epoch 54/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3954752.2500 - mae: 1216.0198 - mse: 3954752.2500 - val_loss: 32.7625 - val_mae: 1.5540 - val_mse: 32.7625 - learning_rate: 0.0010\n",
            "Epoch 55/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6846853.5000 - mae: 1621.2391 - mse: 6846853.5000 - val_loss: 40.8710 - val_mae: 2.1269 - val_mse: 40.8710 - learning_rate: 0.0010\n",
            "Epoch 56/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14368374.0000 - mae: 2413.1172 - mse: 14368374.0000 - val_loss: 50.7742 - val_mae: 2.6590 - val_mse: 50.7742 - learning_rate: 0.0010\n",
            "Epoch 57/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 32271440.0000 - mae: 3669.2207 - mse: 32271440.0000 - val_loss: 80.2725 - val_mae: 3.7597 - val_mse: 80.2725 - learning_rate: 0.0010\n",
            "Epoch 58/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 64572248.0000 - mae: 5244.2720 - mse: 64572248.0000 - val_loss: 106.4258 - val_mae: 4.5364 - val_mse: 106.4258 - learning_rate: 0.0010\n",
            "Epoch 59/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 106779808.0000 - mae: 6829.7505 - mse: 106779808.0000 - val_loss: 137.1548 - val_mae: 5.2533 - val_mse: 137.1548 - learning_rate: 0.0010\n",
            "Epoch 60/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 140431168.0000 - mae: 7870.2095 - mse: 140431168.0000 - val_loss: 131.2666 - val_mae: 5.1344 - val_mse: 131.2666 - learning_rate: 0.0010\n",
            "Epoch 61/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 140427776.0000 - mae: 7956.6396 - mse: 140427776.0000 - val_loss: 112.5278 - val_mae: 4.6556 - val_mse: 112.5278 - learning_rate: 0.0010\n",
            "Epoch 62/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 107807536.0000 - mae: 6976.6309 - mse: 107807536.0000 - val_loss: 71.8943 - val_mae: 3.4399 - val_mse: 71.8943 - learning_rate: 0.0010\n",
            "Epoch 63/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 59839236.0000 - mae: 5226.4297 - mse: 59839236.0000 - val_loss: 48.0187 - val_mae: 2.5142 - val_mse: 48.0187 - learning_rate: 0.0010\n",
            "Epoch 64/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23664732.0000 - mae: 3238.4277 - mse: 23664732.0000 - val_loss: 31.6962 - val_mae: 1.5038 - val_mse: 31.6962 - learning_rate: 0.0010\n",
            "Epoch 65/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6202644.0000 - mae: 1564.4977 - mse: 6202644.0000 - val_loss: 28.8006 - val_mae: 1.3434 - val_mse: 28.8006 - learning_rate: 0.0010\n",
            "Epoch 66/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2448839.2500 - mae: 933.2799 - mse: 2448839.2500 - val_loss: 30.7607 - val_mae: 1.5230 - val_mse: 30.7607 - learning_rate: 0.0010\n",
            "Epoch 67/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3874290.7500 - mae: 1199.9545 - mse: 3874290.7500 - val_loss: 31.0539 - val_mae: 1.6154 - val_mse: 31.0539 - learning_rate: 0.0010\n",
            "Epoch 68/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9449925.0000 - mae: 1922.3264 - mse: 9449925.0000 - val_loss: 39.5144 - val_mae: 2.1608 - val_mse: 39.5144 - learning_rate: 0.0010\n",
            "Epoch 69/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14311345.0000 - mae: 2436.6851 - mse: 14311345.0000 - val_loss: 36.2603 - val_mae: 1.9867 - val_mse: 36.2603 - learning_rate: 0.0010\n",
            "Epoch 70/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16068852.0000 - mae: 2588.7615 - mse: 16068852.0000 - val_loss: 39.8458 - val_mae: 2.1957 - val_mse: 39.8458 - learning_rate: 0.0010\n",
            "Epoch 71/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16237565.0000 - mae: 2609.8826 - mse: 16237565.0000 - val_loss: 34.7701 - val_mae: 1.8908 - val_mse: 34.7701 - learning_rate: 0.0010\n",
            "Epoch 72/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 14606269.0000 - mae: 2458.8574 - mse: 14606269.0000 - val_loss: 38.0860 - val_mae: 2.0759 - val_mse: 38.0860 - learning_rate: 0.0010\n",
            "Epoch 73/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12920078.0000 - mae: 2315.7502 - mse: 12920078.0000 - val_loss: 31.9029 - val_mae: 1.7282 - val_mse: 31.9029 - learning_rate: 0.0010\n",
            "Epoch 74/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11565629.0000 - mae: 2167.3564 - mse: 11565629.0000 - val_loss: 35.7161 - val_mae: 1.9508 - val_mse: 35.7161 - learning_rate: 0.0010\n",
            "Epoch 75/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10804462.0000 - mae: 2103.7820 - mse: 10804462.0000 - val_loss: 30.3125 - val_mae: 1.6712 - val_mse: 30.3125 - learning_rate: 0.0010\n",
            "Epoch 76/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10543543.0000 - mae: 2058.7747 - mse: 10543543.0000 - val_loss: 35.3340 - val_mae: 1.9688 - val_mse: 35.3340 - learning_rate: 0.0010\n",
            "Epoch 77/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10994948.0000 - mae: 2118.2385 - mse: 10994948.0000 - val_loss: 29.6407 - val_mae: 1.7405 - val_mse: 29.6407 - learning_rate: 0.0010\n",
            "Epoch 78/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 12249681.0000 - mae: 2228.6130 - mse: 12249681.0000 - val_loss: 37.7395 - val_mae: 2.1930 - val_mse: 37.7395 - learning_rate: 0.0010\n",
            "Epoch 79/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15321111.0000 - mae: 2523.0100 - mse: 15321111.0000 - val_loss: 35.8356 - val_mae: 2.1851 - val_mse: 35.8356 - learning_rate: 0.0010\n",
            "Epoch 80/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22256516.0000 - mae: 3050.7891 - mse: 22256516.0000 - val_loss: 51.5429 - val_mae: 2.8360 - val_mse: 51.5429 - learning_rate: 0.0010\n",
            "Epoch 81/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 32285272.0000 - mae: 3695.3965 - mse: 32285272.0000 - val_loss: 54.0552 - val_mae: 3.0343 - val_mse: 54.0552 - learning_rate: 0.0010\n",
            "Epoch 82/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 46371036.0000 - mae: 4462.2236 - mse: 46371036.0000 - val_loss: 79.9194 - val_mae: 3.8331 - val_mse: 79.9194 - learning_rate: 0.0010\n",
            "Epoch 83/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 67812536.0000 - mae: 5395.7217 - mse: 67812536.0000 - val_loss: 91.8009 - val_mae: 4.2877 - val_mse: 91.8009 - learning_rate: 0.0010\n",
            "Epoch 84/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 97567992.0000 - mae: 6520.6680 - mse: 97567992.0000 - val_loss: 133.5163 - val_mae: 5.2194 - val_mse: 133.5163 - learning_rate: 0.0010\n",
            "Epoch 85/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 137601968.0000 - mae: 7733.8833 - mse: 137601968.0000 - val_loss: 151.6078 - val_mae: 5.7497 - val_mse: 151.6078 - learning_rate: 0.0010\n",
            "Epoch 86/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 179354368.0000 - mae: 8908.5713 - mse: 179354368.0000 - val_loss: 189.9552 - val_mae: 6.3621 - val_mse: 189.9552 - learning_rate: 0.0010\n",
            "Epoch 87/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 210870944.0000 - mae: 9666.8232 - mse: 210870944.0000 - val_loss: 172.7449 - val_mae: 6.1754 - val_mse: 172.7449 - learning_rate: 0.0010\n",
            "Epoch 88/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 208783360.0000 - mae: 9716.1992 - mse: 208783360.0000 - val_loss: 154.0478 - val_mae: 5.6635 - val_mse: 154.0478 - learning_rate: 0.0010\n",
            "Epoch 89/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 167834032.0000 - mae: 8712.2607 - mse: 167834032.0000 - val_loss: 93.6896 - val_mae: 4.3271 - val_mse: 93.6896 - learning_rate: 0.0010\n",
            "Epoch 90/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 101607056.0000 - mae: 6845.9326 - mse: 101607056.0000 - val_loss: 59.2018 - val_mae: 3.1494 - val_mse: 59.2018 - learning_rate: 0.0010\n",
            "Epoch 91/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 44214544.0000 - mae: 4476.8047 - mse: 44214544.0000 - val_loss: 29.6585 - val_mae: 1.7150 - val_mse: 29.6585 - learning_rate: 0.0010\n",
            "Epoch 92/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11918866.0000 - mae: 2259.8550 - mse: 11918866.0000 - val_loss: 24.8730 - val_mae: 1.3132 - val_mse: 24.8730 - learning_rate: 0.0010\n",
            "Epoch 93/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2595736.2500 - mae: 970.3890 - mse: 2595736.2500 - val_loss: 26.1289 - val_mae: 1.4289 - val_mse: 26.1289 - learning_rate: 0.0010\n",
            "Epoch 94/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3520849.0000 - mae: 1135.7131 - mse: 3520849.0000 - val_loss: 24.5539 - val_mae: 1.3892 - val_mse: 24.5539 - learning_rate: 0.0010\n",
            "Epoch 95/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5766680.0000 - mae: 1484.8086 - mse: 5766680.0000 - val_loss: 30.5897 - val_mae: 1.7277 - val_mse: 30.5897 - learning_rate: 0.0010\n",
            "Epoch 96/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6580182.5000 - mae: 1608.1392 - mse: 6580182.5000 - val_loss: 25.0715 - val_mae: 1.4321 - val_mse: 25.0715 - learning_rate: 0.0010\n",
            "Epoch 97/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6452105.5000 - mae: 1587.5851 - mse: 6452105.5000 - val_loss: 27.0409 - val_mae: 1.5536 - val_mse: 27.0409 - learning_rate: 0.0010\n",
            "Epoch 98/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5613112.5000 - mae: 1479.2527 - mse: 5613112.5000 - val_loss: 24.3028 - val_mae: 1.3113 - val_mse: 24.3028 - learning_rate: 0.0010\n",
            "Epoch 99/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4354378.0000 - mae: 1285.6913 - mse: 4354378.0000 - val_loss: 24.6801 - val_mae: 1.3707 - val_mse: 24.6801 - learning_rate: 0.0010\n",
            "Epoch 100/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3486628.2500 - mae: 1134.0109 - mse: 3486628.2500 - val_loss: 22.8525 - val_mae: 1.2099 - val_mse: 22.8525 - learning_rate: 0.0010\n",
            "Epoch 101/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2810922.7500 - mae: 1014.7932 - mse: 2810922.7500 - val_loss: 23.0652 - val_mae: 1.2561 - val_mse: 23.0652 - learning_rate: 0.0010\n",
            "Epoch 102/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2465067.5000 - mae: 930.1671 - mse: 2465067.5000 - val_loss: 21.8417 - val_mae: 1.1581 - val_mse: 21.8417 - learning_rate: 0.0010\n",
            "Epoch 103/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2245695.0000 - mae: 893.8273 - mse: 2245695.0000 - val_loss: 21.9891 - val_mae: 1.2128 - val_mse: 21.9891 - learning_rate: 0.0010\n",
            "Epoch 104/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2214840.2500 - mae: 871.2923 - mse: 2214840.2500 - val_loss: 21.1917 - val_mae: 1.1465 - val_mse: 21.1917 - learning_rate: 0.0010\n",
            "Epoch 105/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2407468.5000 - mae: 930.2969 - mse: 2407468.5000 - val_loss: 22.1693 - val_mae: 1.2871 - val_mse: 22.1693 - learning_rate: 0.0010\n",
            "Epoch 106/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3005269.0000 - mae: 1043.1903 - mse: 3005269.0000 - val_loss: 22.4555 - val_mae: 1.3284 - val_mse: 22.4555 - learning_rate: 0.0010\n",
            "Epoch 107/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4856154.5000 - mae: 1367.1072 - mse: 4856154.5000 - val_loss: 27.1236 - val_mae: 1.6721 - val_mse: 27.1236 - learning_rate: 0.0010\n",
            "Epoch 108/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8045502.5000 - mae: 1790.0066 - mse: 8045502.5000 - val_loss: 28.6303 - val_mae: 1.8446 - val_mse: 28.6303 - learning_rate: 0.0010\n",
            "Epoch 109/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 13366081.0000 - mae: 2348.5710 - mse: 13366081.0000 - val_loss: 38.3935 - val_mae: 2.3213 - val_mse: 38.3935 - learning_rate: 0.0010\n",
            "Epoch 110/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20653574.0000 - mae: 2935.8584 - mse: 20653574.0000 - val_loss: 40.4885 - val_mae: 2.5140 - val_mse: 40.4885 - learning_rate: 0.0010\n",
            "Epoch 111/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29565202.0000 - mae: 3558.5322 - mse: 29565202.0000 - val_loss: 56.7134 - val_mae: 3.1066 - val_mse: 56.7134 - learning_rate: 0.0010\n",
            "Epoch 112/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 42718196.0000 - mae: 4267.0923 - mse: 42718196.0000 - val_loss: 62.7714 - val_mae: 3.4401 - val_mse: 62.7714 - learning_rate: 0.0010\n",
            "Epoch 113/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 60728724.0000 - mae: 5136.1602 - mse: 60728724.0000 - val_loss: 93.0690 - val_mae: 4.2513 - val_mse: 93.0690 - learning_rate: 0.0010\n",
            "Epoch 114/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 87410784.0000 - mae: 6142.5747 - mse: 87410784.0000 - val_loss: 106.8874 - val_mae: 4.7595 - val_mse: 106.8874 - learning_rate: 0.0010\n",
            "Epoch 115/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 122209472.0000 - mae: 7320.2280 - mse: 122209472.0000 - val_loss: 154.4687 - val_mae: 5.6994 - val_mse: 154.4687 - learning_rate: 0.0010\n",
            "Epoch 116/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 164923744.0000 - mae: 8493.5928 - mse: 164923744.0000 - val_loss: 165.8362 - val_mae: 6.0867 - val_mse: 165.8362 - learning_rate: 0.0010\n",
            "Epoch 117/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 204652704.0000 - mae: 9535.8516 - mse: 204652704.0000 - val_loss: 201.3648 - val_mae: 6.6001 - val_mse: 201.3648 - learning_rate: 0.0010\n",
            "Epoch 118/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 225602928.0000 - mae: 10025.6396 - mse: 225602928.0000 - val_loss: 166.8781 - val_mae: 6.1006 - val_mse: 166.8781 - learning_rate: 0.0010\n",
            "Epoch 119/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 208896208.0000 - mae: 9732.0537 - mse: 208896208.0000 - val_loss: 145.9055 - val_mae: 5.5139 - val_mse: 145.9055 - learning_rate: 0.0010\n",
            "Epoch 120/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 155043984.0000 - mae: 8396.3066 - mse: 155043984.0000 - val_loss: 77.8008 - val_mae: 3.9162 - val_mse: 77.8008 - learning_rate: 0.0010\n",
            "Epoch 121/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 86735184.0000 - mae: 6320.4258 - mse: 86735184.0000 - val_loss: 50.7966 - val_mae: 2.8614 - val_mse: 50.7966 - learning_rate: 0.0010\n",
            "Epoch 122/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 33950600.0000 - mae: 3923.6511 - mse: 33950600.0000 - val_loss: 24.7375 - val_mae: 1.4706 - val_mse: 24.7375 - learning_rate: 0.0010\n",
            "Epoch 123/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8035890.0000 - mae: 1818.9911 - mse: 8035890.0000 - val_loss: 22.5545 - val_mae: 1.2361 - val_mse: 22.5545 - learning_rate: 0.0010\n",
            "Epoch 124/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2250084.2500 - mae: 892.0375 - mse: 2250084.2500 - val_loss: 25.2311 - val_mae: 1.4638 - val_mse: 25.2311 - learning_rate: 0.0010\n",
            "Epoch 125/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4112451.0000 - mae: 1234.3005 - mse: 4112451.0000 - val_loss: 23.0553 - val_mae: 1.3756 - val_mse: 23.0553 - learning_rate: 0.0010\n",
            "Epoch 126/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6023699.0000 - mae: 1525.4894 - mse: 6023699.0000 - val_loss: 27.1240 - val_mae: 1.6105 - val_mse: 27.1240 - learning_rate: 0.0010\n",
            "Epoch 127/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6106606.5000 - mae: 1548.9617 - mse: 6106606.5000 - val_loss: 22.0687 - val_mae: 1.3148 - val_mse: 22.0687 - learning_rate: 0.0010\n",
            "Epoch 128/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5052572.0000 - mae: 1396.6921 - mse: 5052572.0000 - val_loss: 24.0624 - val_mae: 1.4095 - val_mse: 24.0624 - learning_rate: 0.0010\n",
            "Epoch 129/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3805884.2500 - mae: 1193.7700 - mse: 3805884.2500 - val_loss: 20.7914 - val_mae: 1.1803 - val_mse: 20.7914 - learning_rate: 0.0010\n",
            "Epoch 130/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2933956.7500 - mae: 1039.6442 - mse: 2933956.7500 - val_loss: 21.8292 - val_mae: 1.2474 - val_mse: 21.8292 - learning_rate: 0.0010\n",
            "Epoch 131/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2377570.5000 - mae: 910.4078 - mse: 2377570.5000 - val_loss: 20.2508 - val_mae: 1.1255 - val_mse: 20.2508 - learning_rate: 0.0010\n",
            "Epoch 132/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2124917.2500 - mae: 865.7402 - mse: 2124917.2500 - val_loss: 20.7574 - val_mae: 1.1769 - val_mse: 20.7574 - learning_rate: 0.0010\n",
            "Epoch 133/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1981862.5000 - mae: 811.6349 - mse: 1981862.5000 - val_loss: 19.8474 - val_mae: 1.1072 - val_mse: 19.8474 - learning_rate: 0.0010\n",
            "Epoch 134/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1940495.1250 - mae: 814.3102 - mse: 1940495.1250 - val_loss: 20.2347 - val_mae: 1.1573 - val_mse: 20.2347 - learning_rate: 0.0010\n",
            "Epoch 135/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1929875.8750 - mae: 796.8544 - mse: 1929875.8750 - val_loss: 19.4830 - val_mae: 1.0970 - val_mse: 19.4830 - learning_rate: 0.0010\n",
            "Epoch 136/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1988307.1250 - mae: 825.2327 - mse: 1988307.1250 - val_loss: 20.1752 - val_mae: 1.1786 - val_mse: 20.1752 - learning_rate: 0.0010\n",
            "Epoch 137/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2114403.0000 - mae: 844.6306 - mse: 2114403.0000 - val_loss: 19.3821 - val_mae: 1.1144 - val_mse: 19.3821 - learning_rate: 0.0010\n",
            "Epoch 138/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2419618.5000 - mae: 931.2838 - mse: 2419618.5000 - val_loss: 21.0715 - val_mae: 1.2784 - val_mse: 21.0715 - learning_rate: 0.0010\n",
            "Epoch 139/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3025968.5000 - mae: 1047.8124 - mse: 3025968.5000 - val_loss: 20.3160 - val_mae: 1.2661 - val_mse: 20.3160 - learning_rate: 0.0010\n",
            "Epoch 140/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4318018.0000 - mae: 1287.5388 - mse: 4318018.0000 - val_loss: 24.6244 - val_mae: 1.5619 - val_mse: 24.6244 - learning_rate: 0.0010\n",
            "Epoch 141/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6515922.0000 - mae: 1598.6853 - mse: 6515922.0000 - val_loss: 24.3256 - val_mae: 1.6746 - val_mse: 24.3256 - learning_rate: 0.0010\n",
            "Epoch 142/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10305733.0000 - mae: 2050.0032 - mse: 10305733.0000 - val_loss: 33.4012 - val_mae: 2.1091 - val_mse: 33.4012 - learning_rate: 0.0010\n",
            "Epoch 143/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15646265.0000 - mae: 2545.4331 - mse: 15646265.0000 - val_loss: 32.5939 - val_mae: 2.2266 - val_mse: 32.5939 - learning_rate: 0.0010\n",
            "Epoch 144/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 22382908.0000 - mae: 3082.4929 - mse: 22382908.0000 - val_loss: 47.3636 - val_mae: 2.7603 - val_mse: 47.3636 - learning_rate: 0.0010\n",
            "Epoch 145/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 31379428.0000 - mae: 3651.7676 - mse: 31379428.0000 - val_loss: 46.5068 - val_mae: 2.9081 - val_mse: 46.5068 - learning_rate: 0.0010\n",
            "Epoch 146/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 42593784.0000 - mae: 4292.7344 - mse: 42593784.0000 - val_loss: 70.4901 - val_mae: 3.5881 - val_mse: 70.4901 - learning_rate: 0.0010\n",
            "Epoch 147/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 58303944.0000 - mae: 5011.1719 - mse: 58303944.0000 - val_loss: 71.2829 - val_mae: 3.8053 - val_mse: 71.2829 - learning_rate: 0.0010\n",
            "Epoch 148/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 78407672.0000 - mae: 5853.0620 - mse: 78407672.0000 - val_loss: 108.9245 - val_mae: 4.6590 - val_mse: 108.9245 - learning_rate: 0.0010\n",
            "Epoch 149/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 104285280.0000 - mae: 6738.0669 - mse: 104285280.0000 - val_loss: 109.1629 - val_mae: 4.8623 - val_mse: 109.1629 - learning_rate: 0.0010\n",
            "Epoch 150/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 133126808.0000 - mae: 7661.2393 - mse: 133126808.0000 - val_loss: 154.5782 - val_mae: 5.6871 - val_mse: 154.5782 - learning_rate: 0.0010\n",
            "Epoch 151/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 160160640.0000 - mae: 8404.5928 - mse: 160160640.0000 - val_loss: 138.3484 - val_mae: 5.5408 - val_mse: 138.3484 - learning_rate: 0.0010\n",
            "Epoch 152/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 176352416.0000 - mae: 8872.7168 - mse: 176352416.0000 - val_loss: 163.6083 - val_mae: 5.8680 - val_mse: 163.6083 - learning_rate: 0.0010\n",
            "Epoch 153/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 171542448.0000 - mae: 8765.7217 - mse: 171542448.0000 - val_loss: 113.1522 - val_mae: 4.9553 - val_mse: 113.1522 - learning_rate: 0.0010\n",
            "Epoch 154/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 143331248.0000 - mae: 8057.2949 - mse: 143331248.0000 - val_loss: 105.7470 - val_mae: 4.5654 - val_mse: 105.7470 - learning_rate: 0.0010\n",
            "Epoch 155/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 98954904.0000 - mae: 6701.7954 - mse: 98954904.0000 - val_loss: 51.3377 - val_mae: 3.1119 - val_mse: 51.3377 - learning_rate: 0.0010\n",
            "Epoch 156/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 54981956.0000 - mae: 4994.6543 - mse: 54981956.0000 - val_loss: 42.9572 - val_mae: 2.5259 - val_mse: 42.9572 - learning_rate: 0.0010\n",
            "Epoch 157/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23440164.0000 - mae: 3229.9766 - mse: 23440164.0000 - val_loss: 22.0558 - val_mae: 1.4096 - val_mse: 22.0558 - learning_rate: 0.0010\n",
            "Epoch 158/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7508431.5000 - mae: 1744.5724 - mse: 7508431.5000 - val_loss: 22.1240 - val_mae: 1.2712 - val_mse: 22.1240 - learning_rate: 0.0010\n",
            "Epoch 159/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2443119.0000 - mae: 929.8910 - mse: 2443119.0000 - val_loss: 21.9868 - val_mae: 1.2607 - val_mse: 21.9868 - learning_rate: 0.0010\n",
            "Epoch 160/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2294804.5000 - mae: 892.7271 - mse: 2294804.5000 - val_loss: 20.3182 - val_mae: 1.1902 - val_mse: 20.3182 - learning_rate: 0.0010\n",
            "Epoch 161/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3235110.7500 - mae: 1090.7013 - mse: 3235110.7500 - val_loss: 24.0344 - val_mae: 1.4193 - val_mse: 24.0344 - learning_rate: 0.0010\n",
            "Epoch 162/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3645202.0000 - mae: 1159.9773 - mse: 3645202.0000 - val_loss: 20.1194 - val_mae: 1.2040 - val_mse: 20.1194 - learning_rate: 0.0010\n",
            "Epoch 163/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3639345.5000 - mae: 1167.1230 - mse: 3639345.5000 - val_loss: 22.6165 - val_mae: 1.3475 - val_mse: 22.6165 - learning_rate: 0.0010\n",
            "Epoch 164/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3229895.5000 - mae: 1085.9922 - mse: 3229895.5000 - val_loss: 19.5953 - val_mae: 1.1541 - val_mse: 19.5953 - learning_rate: 0.0010\n",
            "Epoch 165/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2867513.0000 - mae: 1025.4036 - mse: 2867513.0000 - val_loss: 21.0217 - val_mae: 1.2451 - val_mse: 21.0217 - learning_rate: 0.0010\n",
            "Epoch 166/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2516788.7500 - mae: 941.8829 - mse: 2516788.7500 - val_loss: 19.1634 - val_mae: 1.1132 - val_mse: 19.1634 - learning_rate: 0.0010\n",
            "Epoch 167/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2305983.7500 - mae: 907.3116 - mse: 2305983.7500 - val_loss: 20.0304 - val_mae: 1.1813 - val_mse: 20.0304 - learning_rate: 0.0010\n",
            "Epoch 168/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2151884.7500 - mae: 856.4487 - mse: 2151884.7500 - val_loss: 18.8463 - val_mae: 1.0917 - val_mse: 18.8463 - learning_rate: 0.0010\n",
            "Epoch 169/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2087003.7500 - mae: 853.9022 - mse: 2087003.7500 - val_loss: 19.5432 - val_mae: 1.1581 - val_mse: 19.5432 - learning_rate: 0.0010\n",
            "Epoch 170/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2069749.0000 - mae: 835.6066 - mse: 2069749.0000 - val_loss: 18.6344 - val_mae: 1.0916 - val_mse: 18.6344 - learning_rate: 0.0010\n",
            "Epoch 171/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2117184.2500 - mae: 861.0898 - mse: 2117184.2500 - val_loss: 19.5294 - val_mae: 1.1787 - val_mse: 19.5294 - learning_rate: 0.0010\n",
            "Epoch 172/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2277443.2500 - mae: 886.7760 - mse: 2277443.2500 - val_loss: 18.6189 - val_mae: 1.1272 - val_mse: 18.6189 - learning_rate: 0.0010\n",
            "Epoch 173/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2559396.7500 - mae: 966.4695 - mse: 2559396.7500 - val_loss: 20.3541 - val_mae: 1.2738 - val_mse: 20.3541 - learning_rate: 0.0010\n",
            "Epoch 174/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3144659.2500 - mae: 1070.9795 - mse: 3144659.2500 - val_loss: 19.2286 - val_mae: 1.2433 - val_mse: 19.2286 - learning_rate: 0.0010\n",
            "Epoch 175/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4058049.0000 - mae: 1248.5625 - mse: 4058049.0000 - val_loss: 22.8312 - val_mae: 1.4827 - val_mse: 22.8312 - learning_rate: 0.0010\n",
            "Epoch 176/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5537744.0000 - mae: 1465.0350 - mse: 5537744.0000 - val_loss: 21.3150 - val_mae: 1.4939 - val_mse: 21.3150 - learning_rate: 0.0010\n",
            "Epoch 177/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7787889.5000 - mae: 1768.5018 - mse: 7787889.5000 - val_loss: 28.1406 - val_mae: 1.8495 - val_mse: 28.1406 - learning_rate: 0.0010\n",
            "Epoch 178/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10988726.0000 - mae: 2116.4490 - mse: 10988726.0000 - val_loss: 26.4540 - val_mae: 1.9129 - val_mse: 26.4540 - learning_rate: 0.0010\n",
            "Epoch 179/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15745836.0000 - mae: 2563.7832 - mse: 15745836.0000 - val_loss: 38.5006 - val_mae: 2.4175 - val_mse: 38.5006 - learning_rate: 0.0010\n",
            "Epoch 180/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 22404424.0000 - mae: 3072.8367 - mse: 22404424.0000 - val_loss: 37.3106 - val_mae: 2.5347 - val_mse: 37.3106 - learning_rate: 0.0010\n",
            "Epoch 181/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31680232.0000 - mae: 3683.5674 - mse: 31680232.0000 - val_loss: 57.8111 - val_mae: 3.2074 - val_mse: 57.8111 - learning_rate: 0.0010\n",
            "Epoch 182/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 44882608.0000 - mae: 4387.7935 - mse: 44882608.0000 - val_loss: 58.9453 - val_mae: 3.4193 - val_mse: 58.9453 - learning_rate: 0.0010\n",
            "Epoch 183/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 62898200.0000 - mae: 5226.1973 - mse: 62898200.0000 - val_loss: 93.5892 - val_mae: 4.3034 - val_mse: 93.5892 - learning_rate: 0.0010\n",
            "Epoch 184/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 87263472.0000 - mae: 6154.7720 - mse: 87263472.0000 - val_loss: 97.2752 - val_mae: 4.5608 - val_mse: 97.2752 - learning_rate: 0.0010\n",
            "Epoch 185/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 117857216.0000 - mae: 7189.3882 - mse: 117857216.0000 - val_loss: 145.8622 - val_mae: 5.5462 - val_mse: 145.8622 - learning_rate: 0.0010\n",
            "Epoch 186/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 151418704.0000 - mae: 8155.3789 - mse: 151418704.0000 - val_loss: 141.6567 - val_mae: 5.6296 - val_mse: 141.6567 - learning_rate: 0.0010\n",
            "Epoch 187/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 181478304.0000 - mae: 8976.2354 - mse: 181478304.0000 - val_loss: 179.3961 - val_mae: 6.2140 - val_mse: 179.3961 - learning_rate: 0.0010\n",
            "Epoch 188/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 194083392.0000 - mae: 9305.2598 - mse: 194083392.0000 - val_loss: 139.3469 - val_mae: 5.5722 - val_mse: 139.3469 - learning_rate: 0.0010\n",
            "Epoch 189/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 180838112.0000 - mae: 9034.1357 - mse: 180838112.0000 - val_loss: 134.5784 - val_mae: 5.3051 - val_mse: 134.5784 - learning_rate: 0.0010\n",
            "Epoch 190/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 138594240.0000 - mae: 7931.8765 - mse: 138594240.0000 - val_loss: 71.1870 - val_mae: 3.7906 - val_mse: 71.1870 - learning_rate: 0.0010\n",
            "Epoch 191/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 85360840.0000 - mae: 6243.0840 - mse: 85360840.0000 - val_loss: 54.0023 - val_mae: 3.0548 - val_mse: 54.0023 - learning_rate: 0.0010\n",
            "Epoch 192/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 39190680.0000 - mae: 4219.8892 - mse: 39190680.0000 - val_loss: 23.5282 - val_mae: 1.6327 - val_mse: 23.5282 - learning_rate: 0.0010\n",
            "Epoch 193/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12595761.0000 - mae: 2319.9604 - mse: 12595761.0000 - val_loss: 21.3537 - val_mae: 1.3070 - val_mse: 21.3537 - learning_rate: 0.0010\n",
            "Epoch 194/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3015243.7500 - mae: 1052.3425 - mse: 3015243.7500 - val_loss: 20.5655 - val_mae: 1.2438 - val_mse: 20.5655 - learning_rate: 0.0010\n",
            "Epoch 195/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2362333.5000 - mae: 907.0790 - mse: 2362333.5000 - val_loss: 19.1723 - val_mae: 1.1961 - val_mse: 19.1723 - learning_rate: 0.0010\n",
            "Epoch 196/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3897905.0000 - mae: 1205.7559 - mse: 3897905.0000 - val_loss: 23.5150 - val_mae: 1.4790 - val_mse: 23.5150 - learning_rate: 0.0010\n",
            "Epoch 197/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4542683.0000 - mae: 1312.6704 - mse: 4542683.0000 - val_loss: 19.1496 - val_mae: 1.2133 - val_mse: 19.1496 - learning_rate: 0.0010\n",
            "Epoch 198/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4314613.0000 - mae: 1280.7736 - mse: 4314613.0000 - val_loss: 21.7059 - val_mae: 1.3576 - val_mse: 21.7059 - learning_rate: 0.0010\n",
            "Epoch 199/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3468789.2500 - mae: 1130.8032 - mse: 3468789.2500 - val_loss: 18.5038 - val_mae: 1.1274 - val_mse: 18.5038 - learning_rate: 0.0010\n",
            "Epoch 200/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2788966.7500 - mae: 1009.1484 - mse: 2788966.7500 - val_loss: 19.4925 - val_mae: 1.1929 - val_mse: 19.4925 - learning_rate: 0.0010\n",
            "Epoch 201/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2259490.0000 - mae: 883.0261 - mse: 2259490.0000 - val_loss: 18.1322 - val_mae: 1.0795 - val_mse: 18.1322 - learning_rate: 0.0010\n",
            "Epoch 202/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1995724.7500 - mae: 830.8281 - mse: 1995724.7500 - val_loss: 18.3958 - val_mae: 1.1072 - val_mse: 18.3958 - learning_rate: 0.0010\n",
            "Epoch 203/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1852945.0000 - mae: 779.3127 - mse: 1852945.0000 - val_loss: 17.9271 - val_mae: 1.0681 - val_mse: 17.9271 - learning_rate: 0.0010\n",
            "Epoch 204/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1792700.8750 - mae: 766.5482 - mse: 1792700.8750 - val_loss: 17.8334 - val_mae: 1.0708 - val_mse: 17.8334 - learning_rate: 0.0010\n",
            "Epoch 205/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1760824.3750 - mae: 754.3920 - mse: 1760824.3750 - val_loss: 17.6459 - val_mae: 1.0632 - val_mse: 17.6459 - learning_rate: 0.0010\n",
            "Epoch 206/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1743709.3750 - mae: 749.1785 - mse: 1743709.3750 - val_loss: 17.4739 - val_mae: 1.0572 - val_mse: 17.4739 - learning_rate: 0.0010\n",
            "Epoch 207/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1733752.2500 - mae: 746.6239 - mse: 1733752.2500 - val_loss: 17.3795 - val_mae: 1.0586 - val_mse: 17.3795 - learning_rate: 0.0010\n",
            "Epoch 208/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1727070.0000 - mae: 743.3986 - mse: 1727070.0000 - val_loss: 17.1679 - val_mae: 1.0477 - val_mse: 17.1679 - learning_rate: 0.0010\n",
            "Epoch 209/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1723402.3750 - mae: 744.0994 - mse: 1723402.3750 - val_loss: 16.9028 - val_mae: 1.0457 - val_mse: 16.9028 - learning_rate: 0.0010\n",
            "Epoch 210/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1723184.8750 - mae: 743.1575 - mse: 1723184.8750 - val_loss: 17.3008 - val_mae: 1.1541 - val_mse: 17.3008 - learning_rate: 0.0010\n",
            "Epoch 211/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3266781.7500 - mae: 1117.1569 - mse: 3266781.7500 - val_loss: 28.6301 - val_mae: 1.9602 - val_mse: 28.6301 - learning_rate: 0.0010\n",
            "Epoch 212/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13681238.0000 - mae: 2347.0439 - mse: 13681238.0000 - val_loss: 40.4311 - val_mae: 2.6805 - val_mse: 40.4311 - learning_rate: 0.0010\n",
            "Epoch 213/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 34757892.0000 - mae: 3849.4707 - mse: 34757892.0000 - val_loss: 66.2713 - val_mae: 3.5286 - val_mse: 66.2713 - learning_rate: 0.0010\n",
            "Epoch 214/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 56631008.0000 - mae: 4950.3115 - mse: 56631008.0000 - val_loss: 65.8824 - val_mae: 3.6451 - val_mse: 65.8824 - learning_rate: 0.0010\n",
            "Epoch 215/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 74886952.0000 - mae: 5730.3267 - mse: 74886952.0000 - val_loss: 91.9592 - val_mae: 4.2676 - val_mse: 91.9592 - learning_rate: 0.0010\n",
            "Epoch 216/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 85245552.0000 - mae: 6126.7798 - mse: 85245552.0000 - val_loss: 74.3035 - val_mae: 3.9050 - val_mse: 74.3035 - learning_rate: 0.0010\n",
            "Epoch 217/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 88501200.0000 - mae: 6268.5361 - mse: 88501200.0000 - val_loss: 88.3267 - val_mae: 4.1528 - val_mse: 88.3267 - learning_rate: 0.0010\n",
            "Epoch 218/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 80045432.0000 - mae: 5978.0122 - mse: 80045432.0000 - val_loss: 56.6799 - val_mae: 3.3211 - val_mse: 56.6799 - learning_rate: 0.0010\n",
            "Epoch 219/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 62944228.0000 - mae: 5306.9434 - mse: 62944228.0000 - val_loss: 56.9439 - val_mae: 3.1597 - val_mse: 56.9439 - learning_rate: 0.0010\n",
            "Epoch 220/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 43088764.0000 - mae: 4381.2749 - mse: 43088764.0000 - val_loss: 32.0284 - val_mae: 2.2381 - val_mse: 32.0284 - learning_rate: 0.0010\n",
            "Epoch 221/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 26076352.0000 - mae: 3383.3584 - mse: 26076352.0000 - val_loss: 32.0543 - val_mae: 2.0487 - val_mse: 32.0543 - learning_rate: 0.0010\n",
            "Epoch 222/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 14049798.0000 - mae: 2447.1909 - mse: 14049798.0000 - val_loss: 20.5721 - val_mae: 1.3753 - val_mse: 20.5721 - learning_rate: 0.0010\n",
            "Epoch 223/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7082052.0000 - mae: 1684.0077 - mse: 7082052.0000 - val_loss: 21.9132 - val_mae: 1.3625 - val_mse: 21.9132 - learning_rate: 0.0010\n",
            "Epoch 224/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3667466.0000 - mae: 1169.3878 - mse: 3667466.0000 - val_loss: 18.8050 - val_mae: 1.1086 - val_mse: 18.8050 - learning_rate: 0.0010\n",
            "Epoch 225/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2356894.0000 - mae: 913.2692 - mse: 2356894.0000 - val_loss: 19.3324 - val_mae: 1.1369 - val_mse: 19.3324 - learning_rate: 0.0010\n",
            "Epoch 226/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1988103.6250 - mae: 816.7684 - mse: 1988103.6250 - val_loss: 19.2427 - val_mae: 1.1323 - val_mse: 19.2427 - learning_rate: 0.0010\n",
            "Epoch 227/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1964791.8750 - mae: 809.8997 - mse: 1964791.8750 - val_loss: 18.6904 - val_mae: 1.0950 - val_mse: 18.6904 - learning_rate: 0.0010\n",
            "Epoch 228/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2022255.5000 - mae: 832.0577 - mse: 2022255.5000 - val_loss: 19.3103 - val_mae: 1.1524 - val_mse: 19.3103 - learning_rate: 0.0010\n",
            "Epoch 229/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2046478.3750 - mae: 827.1017 - mse: 2046478.3750 - val_loss: 18.3777 - val_mae: 1.0850 - val_mse: 18.3777 - learning_rate: 0.0010\n",
            "Epoch 230/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2063619.7500 - mae: 842.2490 - mse: 2063619.7500 - val_loss: 19.0392 - val_mae: 1.1439 - val_mse: 19.0392 - learning_rate: 0.0010\n",
            "Epoch 231/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2044112.3750 - mae: 825.3644 - mse: 2044112.3750 - val_loss: 18.1433 - val_mae: 1.0766 - val_mse: 18.1433 - learning_rate: 0.0010\n",
            "Epoch 232/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2035361.1250 - mae: 835.3068 - mse: 2035361.1250 - val_loss: 18.7601 - val_mae: 1.1305 - val_mse: 18.7601 - learning_rate: 0.0010\n",
            "Epoch 233/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2013240.1250 - mae: 817.0859 - mse: 2013240.1250 - val_loss: 17.9429 - val_mae: 1.0697 - val_mse: 17.9429 - learning_rate: 0.0010\n",
            "Epoch 234/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2010128.2500 - mae: 828.5922 - mse: 2010128.2500 - val_loss: 18.5470 - val_mae: 1.1223 - val_mse: 18.5470 - learning_rate: 0.0010\n",
            "Epoch 235/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2003355.2500 - mae: 813.9691 - mse: 2003355.2500 - val_loss: 17.7554 - val_mae: 1.0646 - val_mse: 17.7554 - learning_rate: 0.0010\n",
            "Epoch 236/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2016702.0000 - mae: 829.8884 - mse: 2016702.0000 - val_loss: 18.4252 - val_mae: 1.1221 - val_mse: 18.4252 - learning_rate: 0.0010\n",
            "Epoch 237/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2033122.6250 - mae: 821.1964 - mse: 2033122.6250 - val_loss: 17.5850 - val_mae: 1.0625 - val_mse: 17.5850 - learning_rate: 0.0010\n",
            "Epoch 238/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2076354.1250 - mae: 844.9088 - mse: 2076354.1250 - val_loss: 18.4353 - val_mae: 1.1345 - val_mse: 18.4353 - learning_rate: 0.0010\n",
            "Epoch 239/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2134676.0000 - mae: 847.0798 - mse: 2134676.0000 - val_loss: 17.4517 - val_mae: 1.0686 - val_mse: 17.4517 - learning_rate: 0.0010\n",
            "Epoch 240/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2243940.7500 - mae: 886.5315 - mse: 2243940.7500 - val_loss: 18.6754 - val_mae: 1.1689 - val_mse: 18.6754 - learning_rate: 0.0010\n",
            "Epoch 241/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2403935.7500 - mae: 912.6865 - mse: 2403935.7500 - val_loss: 17.4451 - val_mae: 1.0966 - val_mse: 17.4451 - learning_rate: 0.0010\n",
            "Epoch 242/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2679764.2500 - mae: 987.1263 - mse: 2679764.2500 - val_loss: 19.4232 - val_mae: 1.2520 - val_mse: 19.4232 - learning_rate: 0.0010\n",
            "Epoch 243/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3108631.5000 - mae: 1061.8119 - mse: 3108631.5000 - val_loss: 17.8495 - val_mae: 1.1839 - val_mse: 17.8495 - learning_rate: 0.0010\n",
            "Epoch 244/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3853087.2500 - mae: 1210.1344 - mse: 3853087.2500 - val_loss: 21.4541 - val_mae: 1.4295 - val_mse: 21.4541 - learning_rate: 0.0010\n",
            "Epoch 245/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5063361.0000 - mae: 1394.2153 - mse: 5063361.0000 - val_loss: 19.6238 - val_mae: 1.4179 - val_mse: 19.6238 - learning_rate: 0.0010\n",
            "Epoch 246/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7195440.0000 - mae: 1693.3467 - mse: 7195440.0000 - val_loss: 26.9613 - val_mae: 1.8244 - val_mse: 26.9613 - learning_rate: 0.0010\n",
            "Epoch 247/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10749857.0000 - mae: 2089.8606 - mse: 10749857.0000 - val_loss: 25.7685 - val_mae: 1.9306 - val_mse: 25.7685 - learning_rate: 0.0010\n",
            "Epoch 248/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16940016.0000 - mae: 2655.0601 - mse: 16940016.0000 - val_loss: 41.8826 - val_mae: 2.6120 - val_mse: 41.8826 - learning_rate: 0.0010\n",
            "Epoch 249/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 27269420.0000 - mae: 3395.1006 - mse: 27269420.0000 - val_loss: 44.6794 - val_mae: 2.8908 - val_mse: 44.6794 - learning_rate: 0.0010\n",
            "Epoch 250/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 44658684.0000 - mae: 4367.1709 - mse: 44658684.0000 - val_loss: 80.5061 - val_mae: 3.9730 - val_mse: 80.5061 - learning_rate: 0.0010\n",
            "Epoch 251/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 72541672.0000 - mae: 5584.9492 - mse: 72541672.0000 - val_loss: 94.7538 - val_mae: 4.5071 - val_mse: 94.7538 - learning_rate: 0.0010\n",
            "Epoch 252/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 115422544.0000 - mae: 7076.4121 - mse: 115422544.0000 - val_loss: 163.6692 - val_mae: 5.9364 - val_mse: 163.6692 - learning_rate: 0.0010\n",
            "Epoch 253/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 174371952.0000 - mae: 8717.0947 - mse: 174371952.0000 - val_loss: 187.1780 - val_mae: 6.5741 - val_mse: 187.1780 - learning_rate: 0.0010\n",
            "Epoch 254/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 244777488.0000 - mae: 10387.5352 - mse: 244777488.0000 - val_loss: 259.9212 - val_mae: 7.6212 - val_mse: 259.9212 - learning_rate: 0.0010\n",
            "Epoch 255/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 299488576.0000 - mae: 11538.5029 - mse: 299488576.0000 - val_loss: 228.7453 - val_mae: 7.3128 - val_mse: 228.7453 - learning_rate: 0.0010\n",
            "Epoch 256/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 305700384.0000 - mae: 11758.3154 - mse: 305700384.0000 - val_loss: 207.6730 - val_mae: 6.7550 - val_mse: 207.6730 - learning_rate: 0.0010\n",
            "Epoch 257/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 235487760.0000 - mae: 10384.6084 - mse: 235487760.0000 - val_loss: 98.0451 - val_mae: 4.5698 - val_mse: 98.0451 - learning_rate: 0.0010\n",
            "Epoch 258/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124718296.0000 - mae: 7513.5923 - mse: 124718296.0000 - val_loss: 129.2711 - val_mae: 5.1650 - val_mse: 129.2711 - learning_rate: 0.0010\n",
            "Epoch 259/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 126168360.0000 - mae: 7303.7651 - mse: 126168360.0000 - val_loss: 192.9238 - val_mae: 6.6789 - val_mse: 192.9238 - learning_rate: 0.0010\n",
            "Epoch 260/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 258191680.0000 - mae: 10687.8496 - mse: 258191680.0000 - val_loss: 242.1414 - val_mae: 7.3390 - val_mse: 242.1414 - learning_rate: 0.0010\n",
            "Epoch 261/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 280232032.0000 - mae: 11369.8223 - mse: 280232032.0000 - val_loss: 96.7259 - val_mae: 4.5175 - val_mse: 96.7259 - learning_rate: 0.0010\n",
            "Epoch 262/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 123437824.0000 - mae: 7684.0830 - mse: 123437824.0000 - val_loss: 27.9570 - val_mae: 1.8805 - val_mse: 27.9570 - learning_rate: 0.0010\n",
            "Epoch 263/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12407125.0000 - mae: 2398.7905 - mse: 12407125.0000 - val_loss: 27.4056 - val_mae: 1.8487 - val_mse: 27.4056 - learning_rate: 0.0010\n",
            "Epoch 264/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10441822.0000 - mae: 2030.0542 - mse: 10441822.0000 - val_loss: 33.9753 - val_mae: 2.2982 - val_mse: 33.9753 - learning_rate: 0.0010\n",
            "Epoch 265/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 28387544.0000 - mae: 3510.5034 - mse: 28387544.0000 - val_loss: 35.0959 - val_mae: 2.2888 - val_mse: 35.0959 - learning_rate: 0.0010\n",
            "Epoch 266/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20031504.0000 - mae: 2972.1338 - mse: 20031504.0000 - val_loss: 19.0980 - val_mae: 1.2530 - val_mse: 19.0980 - learning_rate: 0.0010\n",
            "Epoch 267/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5497331.0000 - mae: 1485.7458 - mse: 5497331.0000 - val_loss: 17.9425 - val_mae: 1.1021 - val_mse: 17.9425 - learning_rate: 0.0010\n",
            "Epoch 268/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2196382.2500 - mae: 876.5667 - mse: 2196382.2500 - val_loss: 21.4489 - val_mae: 1.3989 - val_mse: 21.4489 - learning_rate: 0.0010\n",
            "Epoch 269/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4313646.0000 - mae: 1270.3934 - mse: 4313646.0000 - val_loss: 18.3327 - val_mae: 1.2017 - val_mse: 18.3327 - learning_rate: 0.0010\n",
            "Epoch 270/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4414908.0000 - mae: 1300.5862 - mse: 4414908.0000 - val_loss: 19.8973 - val_mae: 1.2503 - val_mse: 19.8973 - learning_rate: 0.0010\n",
            "Epoch 271/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2825294.2500 - mae: 1006.4592 - mse: 2825294.2500 - val_loss: 18.0005 - val_mae: 1.0827 - val_mse: 18.0005 - learning_rate: 0.0010\n",
            "Epoch 272/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1947463.3750 - mae: 813.4387 - mse: 1947463.3750 - val_loss: 17.8778 - val_mae: 1.0753 - val_mse: 17.8778 - learning_rate: 0.0010\n",
            "Epoch 273/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1983097.0000 - mae: 821.6617 - mse: 1983097.0000 - val_loss: 18.8143 - val_mae: 1.1491 - val_mse: 18.8143 - learning_rate: 0.0010\n",
            "Epoch 274/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2099843.0000 - mae: 838.6912 - mse: 2099843.0000 - val_loss: 17.5581 - val_mae: 1.0657 - val_mse: 17.5581 - learning_rate: 0.0010\n",
            "Epoch 275/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2039810.6250 - mae: 836.0884 - mse: 2039810.6250 - val_loss: 17.9473 - val_mae: 1.0909 - val_mse: 17.9473 - learning_rate: 0.0010\n",
            "Epoch 276/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1886596.6250 - mae: 784.2541 - mse: 1886596.6250 - val_loss: 17.4355 - val_mae: 1.0576 - val_mse: 17.4355 - learning_rate: 0.0010\n",
            "Epoch 277/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1820965.7500 - mae: 769.7823 - mse: 1820965.7500 - val_loss: 17.2519 - val_mae: 1.0509 - val_mse: 17.2519 - learning_rate: 0.0010\n",
            "Epoch 278/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1815488.3750 - mae: 768.1453 - mse: 1815488.3750 - val_loss: 17.2939 - val_mae: 1.0602 - val_mse: 17.2939 - learning_rate: 0.0010\n",
            "Epoch 279/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1817539.7500 - mae: 765.2638 - mse: 1817539.7500 - val_loss: 16.9639 - val_mae: 1.0404 - val_mse: 16.9639 - learning_rate: 0.0010\n",
            "Epoch 280/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1811575.2500 - mae: 767.1581 - mse: 1811575.2500 - val_loss: 17.0263 - val_mae: 1.0496 - val_mse: 17.0263 - learning_rate: 0.0010\n",
            "Epoch 281/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1798255.7500 - mae: 759.6713 - mse: 1798255.7500 - val_loss: 16.8416 - val_mae: 1.0378 - val_mse: 16.8416 - learning_rate: 0.0010\n",
            "Epoch 282/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1787069.1250 - mae: 758.3496 - mse: 1787069.1250 - val_loss: 16.8115 - val_mae: 1.0386 - val_mse: 16.8115 - learning_rate: 0.0010\n",
            "Epoch 283/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1780132.2500 - mae: 755.6387 - mse: 1780132.2500 - val_loss: 16.7612 - val_mae: 1.0370 - val_mse: 16.7612 - learning_rate: 0.0010\n",
            "Epoch 284/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1776034.3750 - mae: 754.3989 - mse: 1776034.3750 - val_loss: 16.6816 - val_mae: 1.0325 - val_mse: 16.6816 - learning_rate: 0.0010\n",
            "Epoch 285/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1772280.7500 - mae: 754.2632 - mse: 1772280.7500 - val_loss: 16.6803 - val_mae: 1.0344 - val_mse: 16.6803 - learning_rate: 0.0010\n",
            "Epoch 286/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1768172.1250 - mae: 752.2274 - mse: 1768172.1250 - val_loss: 16.6023 - val_mae: 1.0295 - val_mse: 16.6023 - learning_rate: 0.0010\n",
            "Epoch 287/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1763272.0000 - mae: 752.2245 - mse: 1763272.0000 - val_loss: 16.5985 - val_mae: 1.0308 - val_mse: 16.5985 - learning_rate: 0.0010\n",
            "Epoch 288/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1758331.1250 - mae: 750.0173 - mse: 1758331.1250 - val_loss: 16.5445 - val_mae: 1.0277 - val_mse: 16.5445 - learning_rate: 0.0010\n",
            "Epoch 289/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1753056.3750 - mae: 749.5565 - mse: 1753056.3750 - val_loss: 16.5371 - val_mae: 1.0278 - val_mse: 16.5371 - learning_rate: 0.0010\n",
            "Epoch 290/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1747529.1250 - mae: 747.7954 - mse: 1747529.1250 - val_loss: 16.5100 - val_mae: 1.0265 - val_mse: 16.5100 - learning_rate: 0.0010\n",
            "Epoch 291/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1741198.0000 - mae: 746.5620 - mse: 1741198.0000 - val_loss: 16.4908 - val_mae: 1.0259 - val_mse: 16.4908 - learning_rate: 0.0010\n",
            "Epoch 292/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1734771.5000 - mae: 745.1183 - mse: 1734771.5000 - val_loss: 16.4687 - val_mae: 1.0253 - val_mse: 16.4687 - learning_rate: 0.0010\n",
            "Epoch 293/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1728393.0000 - mae: 743.6505 - mse: 1728393.0000 - val_loss: 16.4390 - val_mae: 1.0242 - val_mse: 16.4390 - learning_rate: 0.0010\n",
            "Epoch 294/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1721977.7500 - mae: 742.3146 - mse: 1721977.7500 - val_loss: 16.4149 - val_mae: 1.0237 - val_mse: 16.4149 - learning_rate: 0.0010\n",
            "Epoch 295/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1716031.5000 - mae: 740.8434 - mse: 1716031.5000 - val_loss: 16.3768 - val_mae: 1.0222 - val_mse: 16.3768 - learning_rate: 0.0010\n",
            "Epoch 296/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1709713.8750 - mae: 739.3517 - mse: 1709713.8750 - val_loss: 16.3411 - val_mae: 1.0210 - val_mse: 16.3411 - learning_rate: 0.0010\n",
            "Epoch 297/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1702625.0000 - mae: 737.4530 - mse: 1702625.0000 - val_loss: 16.3055 - val_mae: 1.0199 - val_mse: 16.3055 - learning_rate: 0.0010\n",
            "Epoch 298/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1695328.1250 - mae: 735.6802 - mse: 1695328.1250 - val_loss: 16.2810 - val_mae: 1.0195 - val_mse: 16.2810 - learning_rate: 0.0010\n",
            "Epoch 299/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1688441.7500 - mae: 733.8320 - mse: 1688441.7500 - val_loss: 16.2480 - val_mae: 1.0183 - val_mse: 16.2480 - learning_rate: 0.0010\n",
            "Epoch 300/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1682171.8750 - mae: 732.2914 - mse: 1682171.8750 - val_loss: 16.2223 - val_mae: 1.0177 - val_mse: 16.2223 - learning_rate: 0.0010\n",
            "Epoch 301/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1677021.5000 - mae: 730.8692 - mse: 1677021.5000 - val_loss: 16.1844 - val_mae: 1.0160 - val_mse: 16.1844 - learning_rate: 0.0010\n",
            "Epoch 302/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1672064.2500 - mae: 729.7094 - mse: 1672064.2500 - val_loss: 16.1634 - val_mae: 1.0156 - val_mse: 16.1634 - learning_rate: 0.0010\n",
            "Epoch 303/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1667122.2500 - mae: 728.5667 - mse: 1667122.2500 - val_loss: 16.1295 - val_mae: 1.0139 - val_mse: 16.1295 - learning_rate: 0.0010\n",
            "Epoch 304/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1662417.5000 - mae: 727.6996 - mse: 1662417.5000 - val_loss: 16.1055 - val_mae: 1.0137 - val_mse: 16.1055 - learning_rate: 0.0010\n",
            "Epoch 305/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1657752.7500 - mae: 726.6094 - mse: 1657752.7500 - val_loss: 16.0571 - val_mae: 1.0117 - val_mse: 16.0571 - learning_rate: 0.0010\n",
            "Epoch 306/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1653733.0000 - mae: 725.9483 - mse: 1653733.0000 - val_loss: 16.0318 - val_mae: 1.0118 - val_mse: 16.0318 - learning_rate: 0.0010\n",
            "Epoch 307/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1650158.2500 - mae: 724.9463 - mse: 1650158.2500 - val_loss: 15.9806 - val_mae: 1.0095 - val_mse: 15.9806 - learning_rate: 0.0010\n",
            "Epoch 308/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1647121.0000 - mae: 724.3807 - mse: 1647121.0000 - val_loss: 15.9635 - val_mae: 1.0102 - val_mse: 15.9635 - learning_rate: 0.0010\n",
            "Epoch 309/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1644476.7500 - mae: 723.4505 - mse: 1644476.7500 - val_loss: 15.9108 - val_mae: 1.0075 - val_mse: 15.9108 - learning_rate: 0.0010\n",
            "Epoch 310/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1642177.5000 - mae: 723.1766 - mse: 1642177.5000 - val_loss: 15.9106 - val_mae: 1.0095 - val_mse: 15.9106 - learning_rate: 0.0010\n",
            "Epoch 311/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1640301.2500 - mae: 722.3041 - mse: 1640301.2500 - val_loss: 15.8278 - val_mae: 1.0048 - val_mse: 15.8278 - learning_rate: 0.0010\n",
            "Epoch 312/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1638822.0000 - mae: 722.3835 - mse: 1638822.0000 - val_loss: 15.8224 - val_mae: 1.0089 - val_mse: 15.8224 - learning_rate: 0.0010\n",
            "Epoch 313/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1637942.5000 - mae: 721.6901 - mse: 1637942.5000 - val_loss: 15.6822 - val_mae: 1.0007 - val_mse: 15.6822 - learning_rate: 0.0010\n",
            "Epoch 314/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1637947.6250 - mae: 722.4154 - mse: 1637947.6250 - val_loss: 15.7407 - val_mae: 1.0105 - val_mse: 15.7407 - learning_rate: 0.0010\n",
            "Epoch 315/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1640176.7500 - mae: 722.5306 - mse: 1640176.7500 - val_loss: 15.5567 - val_mae: 0.9956 - val_mse: 15.5567 - learning_rate: 0.0010\n",
            "Epoch 316/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1646130.7500 - mae: 725.6501 - mse: 1646130.7500 - val_loss: 15.7682 - val_mae: 1.0191 - val_mse: 15.7682 - learning_rate: 0.0010\n",
            "Epoch 317/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1661318.2500 - mae: 728.9606 - mse: 1661318.2500 - val_loss: 15.4496 - val_mae: 0.9915 - val_mse: 15.4496 - learning_rate: 0.0010\n",
            "Epoch 318/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1694771.1250 - mae: 742.5615 - mse: 1694771.1250 - val_loss: 15.9642 - val_mae: 1.0478 - val_mse: 15.9642 - learning_rate: 0.0010\n",
            "Epoch 319/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1775836.5000 - mae: 762.2150 - mse: 1775836.5000 - val_loss: 15.3813 - val_mae: 1.0025 - val_mse: 15.3813 - learning_rate: 0.0010\n",
            "Epoch 320/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1955973.1250 - mae: 821.1187 - mse: 1955973.1250 - val_loss: 16.7692 - val_mae: 1.1475 - val_mse: 16.7692 - learning_rate: 0.0010\n",
            "Epoch 321/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2404008.2500 - mae: 921.3990 - mse: 2404008.2500 - val_loss: 15.9358 - val_mae: 1.1031 - val_mse: 15.9358 - learning_rate: 0.0010\n",
            "Epoch 322/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3412573.0000 - mae: 1135.7335 - mse: 3412573.0000 - val_loss: 20.3516 - val_mae: 1.4791 - val_mse: 20.3516 - learning_rate: 0.0010\n",
            "Epoch 323/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5898294.5000 - mae: 1513.8586 - mse: 5898294.5000 - val_loss: 20.4762 - val_mae: 1.5889 - val_mse: 20.4762 - learning_rate: 0.0010\n",
            "Epoch 324/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10823808.0000 - mae: 2097.8108 - mse: 10823808.0000 - val_loss: 34.8300 - val_mae: 2.3686 - val_mse: 34.8300 - learning_rate: 0.0010\n",
            "Epoch 325/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20972392.0000 - mae: 2962.6611 - mse: 20972392.0000 - val_loss: 37.2557 - val_mae: 2.5539 - val_mse: 37.2557 - learning_rate: 0.0010\n",
            "Epoch 326/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 36705116.0000 - mae: 3947.3723 - mse: 36705116.0000 - val_loss: 66.7340 - val_mae: 3.5982 - val_mse: 66.7340 - learning_rate: 0.0010\n",
            "Epoch 327/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 56618312.0000 - mae: 4941.6172 - mse: 56618312.0000 - val_loss: 69.6762 - val_mae: 3.7670 - val_mse: 69.6762 - learning_rate: 0.0010\n",
            "Epoch 328/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 83718784.0000 - mae: 6030.6431 - mse: 83718784.0000 - val_loss: 108.7556 - val_mae: 4.7814 - val_mse: 108.7556 - learning_rate: 0.0010\n",
            "Epoch 329/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 109221048.0000 - mae: 6925.4590 - mse: 109221048.0000 - val_loss: 101.4193 - val_mae: 4.6782 - val_mse: 101.4193 - learning_rate: 0.0010\n",
            "Epoch 330/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 126757128.0000 - mae: 7497.9600 - mse: 126757128.0000 - val_loss: 123.0030 - val_mae: 5.1251 - val_mse: 123.0030 - learning_rate: 0.0010\n",
            "Epoch 331/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 130481192.0000 - mae: 7618.4189 - mse: 130481192.0000 - val_loss: 95.3834 - val_mae: 4.5113 - val_mse: 95.3834 - learning_rate: 0.0010\n",
            "Epoch 332/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 117673520.0000 - mae: 7278.6641 - mse: 117673520.0000 - val_loss: 90.3563 - val_mae: 4.3069 - val_mse: 90.3563 - learning_rate: 0.0010\n",
            "Epoch 333/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 90756848.0000 - mae: 6387.6636 - mse: 90756848.0000 - val_loss: 53.1200 - val_mae: 3.1669 - val_mse: 53.1200 - learning_rate: 0.0010\n",
            "Epoch 334/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 58027088.0000 - mae: 5126.3364 - mse: 58027088.0000 - val_loss: 41.6735 - val_mae: 2.6539 - val_mse: 41.6735 - learning_rate: 0.0010\n",
            "Epoch 335/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30137012.0000 - mae: 3662.4009 - mse: 30137012.0000 - val_loss: 21.8818 - val_mae: 1.6069 - val_mse: 21.8818 - learning_rate: 0.0010\n",
            "Epoch 336/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 12021602.0000 - mae: 2263.0820 - mse: 12021602.0000 - val_loss: 19.5620 - val_mae: 1.3350 - val_mse: 19.5620 - learning_rate: 0.0010\n",
            "Epoch 337/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4004429.2500 - mae: 1230.9170 - mse: 4004429.2500 - val_loss: 16.7965 - val_mae: 1.0763 - val_mse: 16.7965 - learning_rate: 0.0010\n",
            "Epoch 338/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1992562.8750 - mae: 822.4960 - mse: 1992562.8750 - val_loss: 16.6279 - val_mae: 1.0676 - val_mse: 16.6279 - learning_rate: 0.0010\n",
            "Epoch 339/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2332669.7500 - mae: 907.0271 - mse: 2332669.7500 - val_loss: 19.2192 - val_mae: 1.2646 - val_mse: 19.2192 - learning_rate: 0.0010\n",
            "Epoch 340/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2865229.2500 - mae: 1013.1279 - mse: 2865229.2500 - val_loss: 16.5296 - val_mae: 1.0988 - val_mse: 16.5296 - learning_rate: 0.0010\n",
            "Epoch 341/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3137700.7500 - mae: 1075.0322 - mse: 3137700.7500 - val_loss: 18.1734 - val_mae: 1.2289 - val_mse: 18.1734 - learning_rate: 0.0010\n",
            "Epoch 342/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2961406.5000 - mae: 1033.1322 - mse: 2961406.5000 - val_loss: 16.1984 - val_mae: 1.0670 - val_mse: 16.1984 - learning_rate: 0.0010\n",
            "Epoch 343/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2638936.5000 - mae: 977.6822 - mse: 2638936.5000 - val_loss: 16.9696 - val_mae: 1.1314 - val_mse: 16.9696 - learning_rate: 0.0010\n",
            "Epoch 344/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2321179.2500 - mae: 896.7721 - mse: 2321179.2500 - val_loss: 15.9022 - val_mae: 1.0306 - val_mse: 15.9022 - learning_rate: 0.0010\n",
            "Epoch 345/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2087706.6250 - mae: 848.3015 - mse: 2087706.6250 - val_loss: 16.2779 - val_mae: 1.0660 - val_mse: 16.2779 - learning_rate: 0.0010\n",
            "Epoch 346/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1942770.6250 - mae: 799.7947 - mse: 1942770.6250 - val_loss: 15.7564 - val_mae: 1.0157 - val_mse: 15.7564 - learning_rate: 0.0010\n",
            "Epoch 347/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1858714.7500 - mae: 785.0652 - mse: 1858714.7500 - val_loss: 15.9182 - val_mae: 1.0351 - val_mse: 15.9182 - learning_rate: 0.0010\n",
            "Epoch 348/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1815055.1250 - mae: 763.9069 - mse: 1815055.1250 - val_loss: 15.5998 - val_mae: 1.0082 - val_mse: 15.5998 - learning_rate: 0.0010\n",
            "Epoch 349/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1788577.3750 - mae: 759.7517 - mse: 1788577.3750 - val_loss: 15.6280 - val_mae: 1.0188 - val_mse: 15.6280 - learning_rate: 0.0010\n",
            "Epoch 350/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1775241.0000 - mae: 752.4336 - mse: 1775241.0000 - val_loss: 15.4004 - val_mae: 1.0002 - val_mse: 15.4004 - learning_rate: 0.0010\n",
            "Epoch 351/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1764046.6250 - mae: 750.9440 - mse: 1764046.6250 - val_loss: 15.4002 - val_mae: 1.0095 - val_mse: 15.4002 - learning_rate: 0.0010\n",
            "Epoch 352/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1761758.1250 - mae: 748.4656 - mse: 1761758.1250 - val_loss: 15.2156 - val_mae: 0.9932 - val_mse: 15.2156 - learning_rate: 0.0010\n",
            "Epoch 353/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1756134.7500 - mae: 748.4992 - mse: 1756134.7500 - val_loss: 15.2315 - val_mae: 1.0044 - val_mse: 15.2315 - learning_rate: 0.0010\n",
            "Epoch 354/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1758870.7500 - mae: 747.8379 - mse: 1758870.7500 - val_loss: 15.0625 - val_mae: 0.9876 - val_mse: 15.0625 - learning_rate: 0.0010\n",
            "Epoch 355/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1755882.3750 - mae: 748.6335 - mse: 1755882.3750 - val_loss: 15.1133 - val_mae: 1.0026 - val_mse: 15.1133 - learning_rate: 0.0010\n",
            "Epoch 356/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1763013.5000 - mae: 749.3767 - mse: 1763013.5000 - val_loss: 14.9318 - val_mae: 0.9832 - val_mse: 14.9318 - learning_rate: 0.0010\n",
            "Epoch 357/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1763151.0000 - mae: 751.3575 - mse: 1763151.0000 - val_loss: 15.0319 - val_mae: 1.0036 - val_mse: 15.0319 - learning_rate: 0.0010\n",
            "Epoch 358/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1777222.0000 - mae: 753.9999 - mse: 1777222.0000 - val_loss: 14.8170 - val_mae: 0.9796 - val_mse: 14.8170 - learning_rate: 0.0010\n",
            "Epoch 359/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1784643.1250 - mae: 758.3918 - mse: 1784643.1250 - val_loss: 14.9887 - val_mae: 1.0093 - val_mse: 14.9887 - learning_rate: 0.0010\n",
            "Epoch 360/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1814103.0000 - mae: 765.3490 - mse: 1814103.0000 - val_loss: 14.7312 - val_mae: 0.9771 - val_mse: 14.7312 - learning_rate: 0.0010\n",
            "Epoch 361/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1838146.2500 - mae: 775.5012 - mse: 1838146.2500 - val_loss: 15.0182 - val_mae: 1.0237 - val_mse: 15.0182 - learning_rate: 0.0010\n",
            "Epoch 362/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1904141.8750 - mae: 790.9751 - mse: 1904141.8750 - val_loss: 14.6967 - val_mae: 0.9823 - val_mse: 14.6967 - learning_rate: 0.0010\n",
            "Epoch 363/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1974836.5000 - mae: 815.4484 - mse: 1974836.5000 - val_loss: 15.2151 - val_mae: 1.0586 - val_mse: 15.2151 - learning_rate: 0.0010\n",
            "Epoch 364/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2137396.5000 - mae: 850.8406 - mse: 2137396.5000 - val_loss: 14.8134 - val_mae: 1.0059 - val_mse: 14.8134 - learning_rate: 0.0010\n",
            "Epoch 365/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2348996.0000 - mae: 911.7391 - mse: 2348996.0000 - val_loss: 15.8205 - val_mae: 1.1400 - val_mse: 15.8205 - learning_rate: 0.0010\n",
            "Epoch 366/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2780742.5000 - mae: 995.6674 - mse: 2780742.5000 - val_loss: 15.4357 - val_mae: 1.0920 - val_mse: 15.4357 - learning_rate: 0.0010\n",
            "Epoch 367/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3420353.5000 - mae: 1137.2267 - mse: 3420353.5000 - val_loss: 17.5723 - val_mae: 1.3206 - val_mse: 17.5723 - learning_rate: 0.0010\n",
            "Epoch 368/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4652356.0000 - mae: 1328.2732 - mse: 4652356.0000 - val_loss: 17.5795 - val_mae: 1.3325 - val_mse: 17.5795 - learning_rate: 0.0010\n",
            "Epoch 369/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6575710.0000 - mae: 1620.9863 - mse: 6575710.0000 - val_loss: 22.5030 - val_mae: 1.7136 - val_mse: 22.5030 - learning_rate: 0.0010\n",
            "Epoch 370/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10040727.0000 - mae: 2011.8536 - mse: 10040727.0000 - val_loss: 23.7172 - val_mae: 1.8085 - val_mse: 23.7172 - learning_rate: 0.0010\n",
            "Epoch 371/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15269537.0000 - mae: 2525.6816 - mse: 15269537.0000 - val_loss: 34.6951 - val_mae: 2.4191 - val_mse: 34.6951 - learning_rate: 0.0010\n",
            "Epoch 372/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23630232.0000 - mae: 3154.2280 - mse: 23630232.0000 - val_loss: 37.9968 - val_mae: 2.5560 - val_mse: 37.9968 - learning_rate: 0.0010\n",
            "Epoch 373/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 35411508.0000 - mae: 3896.1787 - mse: 35411508.0000 - val_loss: 58.3791 - val_mae: 3.3791 - val_mse: 58.3791 - learning_rate: 0.0010\n",
            "Epoch 374/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 51973960.0000 - mae: 4726.4116 - mse: 51973960.0000 - val_loss: 65.0377 - val_mae: 3.5935 - val_mse: 65.0377 - learning_rate: 0.0010\n",
            "Epoch 375/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 72703632.0000 - mae: 5630.5146 - mse: 72703632.0000 - val_loss: 94.2008 - val_mae: 4.4659 - val_mse: 94.2008 - learning_rate: 0.0010\n",
            "Epoch 376/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 96895904.0000 - mae: 6497.0796 - mse: 96895904.0000 - val_loss: 99.4515 - val_mae: 4.6130 - val_mse: 99.4515 - learning_rate: 0.0010\n",
            "Epoch 377/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 120548808.0000 - mae: 7297.3052 - mse: 120548808.0000 - val_loss: 125.4120 - val_mae: 5.2220 - val_mse: 125.4120 - learning_rate: 0.0010\n",
            "Epoch 378/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 136133040.0000 - mae: 7761.5425 - mse: 136133040.0000 - val_loss: 109.4374 - val_mae: 4.8705 - val_mse: 109.4374 - learning_rate: 0.0010\n",
            "Epoch 379/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 135644736.0000 - mae: 7804.3564 - mse: 135644736.0000 - val_loss: 106.9360 - val_mae: 4.7744 - val_mse: 106.9360 - learning_rate: 0.0010\n",
            "Epoch 380/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 112670128.0000 - mae: 7119.6006 - mse: 112670128.0000 - val_loss: 66.5245 - val_mae: 3.6320 - val_mse: 66.5245 - learning_rate: 0.0010\n",
            "Epoch 381/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 77640496.0000 - mae: 5935.8530 - mse: 77640496.0000 - val_loss: 50.7401 - val_mae: 3.0638 - val_mse: 50.7401 - learning_rate: 0.0010\n",
            "Epoch 382/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 42035956.0000 - mae: 4351.9976 - mse: 42035956.0000 - val_loss: 24.4372 - val_mae: 1.8009 - val_mse: 24.4372 - learning_rate: 0.0010\n",
            "Epoch 383/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 17186374.0000 - mae: 2734.7561 - mse: 17186374.0000 - val_loss: 19.9397 - val_mae: 1.4381 - val_mse: 19.9397 - learning_rate: 0.0010\n",
            "Epoch 384/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5259102.5000 - mae: 1433.8230 - mse: 5259102.5000 - val_loss: 15.9264 - val_mae: 1.0622 - val_mse: 15.9264 - learning_rate: 0.0010\n",
            "Epoch 385/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2075588.6250 - mae: 844.7744 - mse: 2075588.6250 - val_loss: 15.7418 - val_mae: 1.0522 - val_mse: 15.7418 - learning_rate: 0.0010\n",
            "Epoch 386/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2490221.5000 - mae: 939.5610 - mse: 2490221.5000 - val_loss: 18.3955 - val_mae: 1.2853 - val_mse: 18.3955 - learning_rate: 0.0010\n",
            "Epoch 387/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3268439.5000 - mae: 1086.7307 - mse: 3268439.5000 - val_loss: 15.9777 - val_mae: 1.1038 - val_mse: 15.9777 - learning_rate: 0.0010\n",
            "Epoch 388/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3567421.0000 - mae: 1156.9468 - mse: 3567421.0000 - val_loss: 17.5783 - val_mae: 1.2463 - val_mse: 17.5783 - learning_rate: 0.0010\n",
            "Epoch 389/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3233824.2500 - mae: 1083.8759 - mse: 3233824.2500 - val_loss: 15.5403 - val_mae: 1.0579 - val_mse: 15.5403 - learning_rate: 0.0010\n",
            "Epoch 390/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2782514.2500 - mae: 1008.1344 - mse: 2782514.2500 - val_loss: 16.0034 - val_mae: 1.1146 - val_mse: 16.0034 - learning_rate: 0.0010\n",
            "Epoch 391/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2356233.5000 - mae: 903.2945 - mse: 2356233.5000 - val_loss: 15.1055 - val_mae: 1.0088 - val_mse: 15.1055 - learning_rate: 0.0010\n",
            "Epoch 392/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2069712.6250 - mae: 844.0663 - mse: 2069712.6250 - val_loss: 15.2150 - val_mae: 1.0339 - val_mse: 15.2150 - learning_rate: 0.0010\n",
            "Epoch 393/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1906417.1250 - mae: 790.6608 - mse: 1906417.1250 - val_loss: 14.8702 - val_mae: 0.9882 - val_mse: 14.8702 - learning_rate: 0.0010\n",
            "Epoch 394/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1813006.0000 - mae: 771.5070 - mse: 1813006.0000 - val_loss: 14.8784 - val_mae: 0.9994 - val_mse: 14.8784 - learning_rate: 0.0010\n",
            "Epoch 395/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1771591.5000 - mae: 753.2076 - mse: 1771591.5000 - val_loss: 14.7239 - val_mae: 0.9780 - val_mse: 14.7239 - learning_rate: 0.0010\n",
            "Epoch 396/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1742822.5000 - mae: 748.0562 - mse: 1742822.5000 - val_loss: 14.7025 - val_mae: 0.9837 - val_mse: 14.7025 - learning_rate: 0.0010\n",
            "Epoch 397/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1731347.2500 - mae: 742.5042 - mse: 1731347.2500 - val_loss: 14.6103 - val_mae: 0.9694 - val_mse: 14.6103 - learning_rate: 0.0010\n",
            "Epoch 398/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1718036.2500 - mae: 741.2838 - mse: 1718036.2500 - val_loss: 14.5925 - val_mae: 0.9752 - val_mse: 14.5925 - learning_rate: 0.0010\n",
            "Epoch 399/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1714560.0000 - mae: 738.8016 - mse: 1714560.0000 - val_loss: 14.5188 - val_mae: 0.9618 - val_mse: 14.5188 - learning_rate: 0.0010\n",
            "Epoch 400/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1705907.6250 - mae: 738.9691 - mse: 1705907.6250 - val_loss: 14.5180 - val_mae: 0.9713 - val_mse: 14.5180 - learning_rate: 0.0010\n",
            "Epoch 401/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1709406.3750 - mae: 737.9673 - mse: 1709406.3750 - val_loss: 14.4467 - val_mae: 0.9551 - val_mse: 14.4467 - learning_rate: 0.0010\n",
            "Epoch 402/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1706996.3750 - mae: 741.2532 - mse: 1706996.3750 - val_loss: 14.4863 - val_mae: 0.9736 - val_mse: 14.4863 - learning_rate: 0.0010\n",
            "Epoch 403/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1727611.0000 - mae: 744.3443 - mse: 1727611.0000 - val_loss: 14.4078 - val_mae: 0.9509 - val_mse: 14.4078 - learning_rate: 0.0010\n",
            "Epoch 404/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1749073.7500 - mae: 755.9247 - mse: 1749073.7500 - val_loss: 14.5535 - val_mae: 0.9928 - val_mse: 14.5535 - learning_rate: 0.0010\n",
            "Epoch 405/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1829982.0000 - mae: 773.9959 - mse: 1829982.0000 - val_loss: 14.4700 - val_mae: 0.9595 - val_mse: 14.4700 - learning_rate: 0.0010\n",
            "Epoch 406/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1948600.3750 - mae: 816.9257 - mse: 1948600.3750 - val_loss: 14.9321 - val_mae: 1.0562 - val_mse: 14.9321 - learning_rate: 0.0010\n",
            "Epoch 407/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2260192.2500 - mae: 883.8517 - mse: 2260192.2500 - val_loss: 14.9753 - val_mae: 1.0329 - val_mse: 14.9753 - learning_rate: 0.0010\n",
            "Epoch 408/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2805473.0000 - mae: 1020.6501 - mse: 2805473.0000 - val_loss: 16.5731 - val_mae: 1.2538 - val_mse: 16.5731 - learning_rate: 0.0010\n",
            "Epoch 409/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4120184.2500 - mae: 1243.9065 - mse: 4120184.2500 - val_loss: 17.4271 - val_mae: 1.3061 - val_mse: 17.4271 - learning_rate: 0.0010\n",
            "Epoch 410/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6308769.0000 - mae: 1585.4834 - mse: 6308769.0000 - val_loss: 22.5971 - val_mae: 1.7439 - val_mse: 22.5971 - learning_rate: 0.0010\n",
            "Epoch 411/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10796953.0000 - mae: 2090.5510 - mse: 10796953.0000 - val_loss: 24.4416 - val_mae: 1.8313 - val_mse: 24.4416 - learning_rate: 0.0010\n",
            "Epoch 412/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 16217957.0000 - mae: 2609.6960 - mse: 16217957.0000 - val_loss: 33.3526 - val_mae: 2.3645 - val_mse: 33.3526 - learning_rate: 0.0010\n",
            "Epoch 413/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 22359668.0000 - mae: 3080.4287 - mse: 22359668.0000 - val_loss: 32.5077 - val_mae: 2.2777 - val_mse: 32.5077 - learning_rate: 0.0010\n",
            "Epoch 414/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28768192.0000 - mae: 3507.6716 - mse: 28768192.0000 - val_loss: 44.3280 - val_mae: 2.8550 - val_mse: 44.3280 - learning_rate: 0.0010\n",
            "Epoch 415/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 34853792.0000 - mae: 3880.6479 - mse: 34853792.0000 - val_loss: 41.4557 - val_mae: 2.6922 - val_mse: 41.4557 - learning_rate: 0.0010\n",
            "Epoch 416/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41317740.0000 - mae: 4231.3960 - mse: 41317740.0000 - val_loss: 54.3176 - val_mae: 3.2334 - val_mse: 54.3176 - learning_rate: 0.0010\n",
            "Epoch 417/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 47162528.0000 - mae: 4531.1367 - mse: 47162528.0000 - val_loss: 50.0596 - val_mae: 3.0478 - val_mse: 50.0596 - learning_rate: 0.0010\n",
            "Epoch 418/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 52668984.0000 - mae: 4801.3711 - mse: 52668984.0000 - val_loss: 61.1564 - val_mae: 3.4854 - val_mse: 61.1564 - learning_rate: 0.0010\n",
            "Epoch 419/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56514672.0000 - mae: 4975.6499 - mse: 56514672.0000 - val_loss: 54.5099 - val_mae: 3.2198 - val_mse: 54.5099 - learning_rate: 0.0010\n",
            "Epoch 420/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58622628.0000 - mae: 5084.8154 - mse: 58622628.0000 - val_loss: 62.0122 - val_mae: 3.5107 - val_mse: 62.0122 - learning_rate: 0.0010\n",
            "Epoch 421/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 57626052.0000 - mae: 5037.4995 - mse: 57626052.0000 - val_loss: 51.0704 - val_mae: 3.0860 - val_mse: 51.0704 - learning_rate: 0.0010\n",
            "Epoch 422/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 53876576.0000 - mae: 4884.9492 - mse: 53876576.0000 - val_loss: 53.2562 - val_mae: 3.1981 - val_mse: 53.2562 - learning_rate: 0.0010\n",
            "Epoch 423/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 47108396.0000 - mae: 4558.1553 - mse: 47108396.0000 - val_loss: 40.1910 - val_mae: 2.6335 - val_mse: 40.1910 - learning_rate: 0.0010\n",
            "Epoch 424/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 38694948.0000 - mae: 4135.2515 - mse: 38694948.0000 - val_loss: 39.2710 - val_mae: 2.6275 - val_mse: 39.2710 - learning_rate: 0.0010\n",
            "Epoch 425/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 29780204.0000 - mae: 3611.4854 - mse: 29780204.0000 - val_loss: 28.0254 - val_mae: 2.0397 - val_mse: 28.0254 - learning_rate: 0.0010\n",
            "Epoch 426/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 21607436.0000 - mae: 3063.8447 - mse: 21607436.0000 - val_loss: 27.2065 - val_mae: 1.9971 - val_mse: 27.2065 - learning_rate: 0.0010\n",
            "Epoch 427/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15008190.0000 - mae: 2527.3499 - mse: 15008190.0000 - val_loss: 20.0889 - val_mae: 1.5141 - val_mse: 20.0889 - learning_rate: 0.0010\n",
            "Epoch 428/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 10103232.0000 - mae: 2050.2048 - mse: 10103232.0000 - val_loss: 20.2117 - val_mae: 1.5194 - val_mse: 20.2117 - learning_rate: 0.0010\n",
            "Epoch 429/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6825840.0000 - mae: 1652.1331 - mse: 6825840.0000 - val_loss: 16.5860 - val_mae: 1.1839 - val_mse: 16.5860 - learning_rate: 0.0010\n",
            "Epoch 430/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4733556.5000 - mae: 1363.0657 - mse: 4733556.5000 - val_loss: 17.0706 - val_mae: 1.2477 - val_mse: 17.0706 - learning_rate: 0.0010\n",
            "Epoch 431/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3498943.0000 - mae: 1136.5994 - mse: 3498943.0000 - val_loss: 15.3955 - val_mae: 1.0539 - val_mse: 15.3955 - learning_rate: 0.0010\n",
            "Epoch 432/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2779194.7500 - mae: 1011.9789 - mse: 2779194.7500 - val_loss: 15.7976 - val_mae: 1.1184 - val_mse: 15.7976 - learning_rate: 0.0010\n",
            "Epoch 433/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2380682.5000 - mae: 910.8403 - mse: 2380682.5000 - val_loss: 14.9964 - val_mae: 1.0115 - val_mse: 14.9964 - learning_rate: 0.0010\n",
            "Epoch 434/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2153237.5000 - mae: 867.3566 - mse: 2153237.5000 - val_loss: 15.2302 - val_mae: 1.0611 - val_mse: 15.2302 - learning_rate: 0.0010\n",
            "Epoch 435/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2034704.1250 - mae: 826.5306 - mse: 2034704.1250 - val_loss: 14.8072 - val_mae: 0.9958 - val_mse: 14.8072 - learning_rate: 0.0010\n",
            "Epoch 436/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1964062.1250 - mae: 819.1270 - mse: 1964062.1250 - val_loss: 14.9435 - val_mae: 1.0374 - val_mse: 14.9435 - learning_rate: 0.0010\n",
            "Epoch 437/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1946009.8750 - mae: 803.0647 - mse: 1946009.8750 - val_loss: 14.6927 - val_mae: 0.9886 - val_mse: 14.6927 - learning_rate: 0.0010\n",
            "Epoch 438/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1937572.6250 - mae: 811.8362 - mse: 1937572.6250 - val_loss: 14.8158 - val_mae: 1.0336 - val_mse: 14.8158 - learning_rate: 0.0010\n",
            "Epoch 439/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1978591.2500 - mae: 812.3918 - mse: 1978591.2500 - val_loss: 14.6721 - val_mae: 0.9896 - val_mse: 14.6721 - learning_rate: 0.0010\n",
            "Epoch 440/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2018315.8750 - mae: 833.5471 - mse: 2018315.8750 - val_loss: 14.8482 - val_mae: 1.0510 - val_mse: 14.8482 - learning_rate: 0.0010\n",
            "Epoch 441/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2133340.2500 - mae: 851.7108 - mse: 2133340.2500 - val_loss: 14.7842 - val_mae: 1.0062 - val_mse: 14.7842 - learning_rate: 0.0010\n",
            "Epoch 442/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2257412.7500 - mae: 894.7856 - mse: 2257412.7500 - val_loss: 15.1330 - val_mae: 1.0997 - val_mse: 15.1330 - learning_rate: 0.0010\n",
            "Epoch 443/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2525651.2500 - mae: 943.1962 - mse: 2525651.2500 - val_loss: 15.1509 - val_mae: 1.0527 - val_mse: 15.1509 - learning_rate: 0.0010\n",
            "Epoch 444/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2852907.2500 - mae: 1028.9760 - mse: 2852907.2500 - val_loss: 15.9331 - val_mae: 1.2014 - val_mse: 15.9331 - learning_rate: 0.0010\n",
            "Epoch 445/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3478029.5000 - mae: 1133.1099 - mse: 3478029.5000 - val_loss: 16.1465 - val_mae: 1.1689 - val_mse: 16.1465 - learning_rate: 0.0010\n",
            "Epoch 446/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4312512.0000 - mae: 1296.0190 - mse: 4312512.0000 - val_loss: 17.9255 - val_mae: 1.3973 - val_mse: 17.9255 - learning_rate: 0.0010\n",
            "Epoch 447/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5769544.0000 - mae: 1498.3572 - mse: 5769544.0000 - val_loss: 18.5681 - val_mae: 1.4040 - val_mse: 18.5681 - learning_rate: 0.0010\n",
            "Epoch 448/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7769294.0000 - mae: 1775.5549 - mse: 7769294.0000 - val_loss: 22.4752 - val_mae: 1.7498 - val_mse: 22.4752 - learning_rate: 0.0010\n",
            "Epoch 449/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10932005.0000 - mae: 2113.4973 - mse: 10932005.0000 - val_loss: 23.7897 - val_mae: 1.7965 - val_mse: 23.7897 - learning_rate: 0.0010\n",
            "Epoch 450/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15271315.0000 - mae: 2527.7852 - mse: 15271315.0000 - val_loss: 31.5829 - val_mae: 2.2981 - val_mse: 31.5829 - learning_rate: 0.0010\n",
            "Epoch 451/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21326760.0000 - mae: 3004.4670 - mse: 21326760.0000 - val_loss: 33.9312 - val_mae: 2.3519 - val_mse: 33.9312 - learning_rate: 0.0010\n",
            "Epoch 452/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29710930.0000 - mae: 3562.4463 - mse: 29710930.0000 - val_loss: 47.5225 - val_mae: 3.0105 - val_mse: 47.5225 - learning_rate: 0.0010\n",
            "Epoch 453/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 40530672.0000 - mae: 4179.2271 - mse: 40530672.0000 - val_loss: 52.2452 - val_mae: 3.1390 - val_mse: 52.2452 - learning_rate: 0.0010\n",
            "Epoch 454/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 54862112.0000 - mae: 4878.2051 - mse: 54862112.0000 - val_loss: 72.5641 - val_mae: 3.8808 - val_mse: 72.5641 - learning_rate: 0.0010\n",
            "Epoch 455/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 71680424.0000 - mae: 5588.2871 - mse: 71680424.0000 - val_loss: 78.9165 - val_mae: 4.0333 - val_mse: 78.9165 - learning_rate: 0.0010\n",
            "Epoch 456/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 90926288.0000 - mae: 6320.9619 - mse: 90926288.0000 - val_loss: 100.1142 - val_mae: 4.6550 - val_mse: 100.1142 - learning_rate: 0.0010\n",
            "Epoch 457/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 107390368.0000 - mae: 6877.2744 - mse: 107390368.0000 - val_loss: 98.3393 - val_mae: 4.5814 - val_mse: 98.3393 - learning_rate: 0.0010\n",
            "Epoch 458/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 117865976.0000 - mae: 7244.7861 - mse: 117865976.0000 - val_loss: 104.9676 - val_mae: 4.7730 - val_mse: 104.9676 - learning_rate: 0.0010\n",
            "Epoch 459/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 114079208.0000 - mae: 7135.7192 - mse: 114079208.0000 - val_loss: 81.8995 - val_mae: 4.1131 - val_mse: 81.8995 - learning_rate: 0.0010\n",
            "Epoch 460/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 96923344.0000 - mae: 6610.1265 - mse: 96923344.0000 - val_loss: 69.6143 - val_mae: 3.7719 - val_mse: 69.6143 - learning_rate: 0.0010\n",
            "Epoch 461/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 68517536.0000 - mae: 5559.4175 - mse: 68517536.0000 - val_loss: 40.4092 - val_mae: 2.6284 - val_mse: 40.4092 - learning_rate: 0.0010\n",
            "Epoch 462/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 39894888.0000 - mae: 4235.6226 - mse: 39894888.0000 - val_loss: 29.7305 - val_mae: 2.1536 - val_mse: 29.7305 - learning_rate: 0.0010\n",
            "Epoch 463/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18220770.0000 - mae: 2830.1516 - mse: 18220770.0000 - val_loss: 17.5391 - val_mae: 1.2646 - val_mse: 17.5391 - learning_rate: 0.0010\n",
            "Epoch 464/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6482536.0000 - mae: 1620.3245 - mse: 6482536.0000 - val_loss: 15.9944 - val_mae: 1.1331 - val_mse: 15.9944 - learning_rate: 0.0010\n",
            "Epoch 465/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2335782.2500 - mae: 905.3076 - mse: 2335782.2500 - val_loss: 15.5117 - val_mae: 1.0782 - val_mse: 15.5117 - learning_rate: 0.0010\n",
            "Epoch 466/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1942597.6250 - mae: 806.7783 - mse: 1942597.6250 - val_loss: 15.1976 - val_mae: 1.0352 - val_mse: 15.1976 - learning_rate: 0.0010\n",
            "Epoch 467/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2529951.0000 - mae: 952.8329 - mse: 2529951.0000 - val_loss: 16.6137 - val_mae: 1.2069 - val_mse: 16.6137 - learning_rate: 0.0010\n",
            "Epoch 468/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2831622.7500 - mae: 1005.9185 - mse: 2831622.7500 - val_loss: 15.2920 - val_mae: 1.0531 - val_mse: 15.2920 - learning_rate: 0.0010\n",
            "Epoch 469/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2804214.2500 - mae: 1015.4058 - mse: 2804214.2500 - val_loss: 15.8500 - val_mae: 1.1467 - val_mse: 15.8500 - learning_rate: 0.0010\n",
            "Epoch 470/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2499010.5000 - mae: 937.7873 - mse: 2499010.5000 - val_loss: 14.9778 - val_mae: 1.0169 - val_mse: 14.9778 - learning_rate: 0.0010\n",
            "Epoch 471/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2212863.2500 - mae: 884.7062 - mse: 2212863.2500 - val_loss: 15.0211 - val_mae: 1.0547 - val_mse: 15.0211 - learning_rate: 0.0010\n",
            "Epoch 472/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1976836.3750 - mae: 813.6608 - mse: 1976836.3750 - val_loss: 14.7290 - val_mae: 0.9908 - val_mse: 14.7290 - learning_rate: 0.0010\n",
            "Epoch 473/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1831748.8750 - mae: 783.2794 - mse: 1831748.8750 - val_loss: 14.6709 - val_mae: 1.0033 - val_mse: 14.6709 - learning_rate: 0.0010\n",
            "Epoch 474/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1752499.7500 - mae: 751.3220 - mse: 1752499.7500 - val_loss: 14.5506 - val_mae: 0.9865 - val_mse: 14.5506 - learning_rate: 0.0010\n",
            "Epoch 475/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1697504.2500 - mae: 737.5679 - mse: 1697504.2500 - val_loss: 14.6747 - val_mae: 0.9867 - val_mse: 14.6747 - learning_rate: 0.0010\n",
            "Epoch 476/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1881913.2500 - mae: 798.2094 - mse: 1881913.2500 - val_loss: 14.9160 - val_mae: 1.0781 - val_mse: 14.9160 - learning_rate: 0.0010\n",
            "Epoch 477/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2312702.2500 - mae: 895.0179 - mse: 2312702.2500 - val_loss: 15.2192 - val_mae: 1.0423 - val_mse: 15.2192 - learning_rate: 0.0010\n",
            "Epoch 478/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2608146.5000 - mae: 978.1423 - mse: 2608146.5000 - val_loss: 15.2172 - val_mae: 1.1299 - val_mse: 15.2172 - learning_rate: 0.0010\n",
            "Epoch 479/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2809908.0000 - mae: 1003.9420 - mse: 2809908.0000 - val_loss: 15.3801 - val_mae: 1.0595 - val_mse: 15.3801 - learning_rate: 0.0010\n",
            "Epoch 480/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2871908.7500 - mae: 1036.0352 - mse: 2871908.7500 - val_loss: 15.2912 - val_mae: 1.1431 - val_mse: 15.2912 - learning_rate: 0.0010\n",
            "Epoch 481/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2958306.5000 - mae: 1034.4587 - mse: 2958306.5000 - val_loss: 15.3951 - val_mae: 1.0640 - val_mse: 15.3951 - learning_rate: 0.0010\n",
            "Epoch 482/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2972427.5000 - mae: 1057.1725 - mse: 2972427.5000 - val_loss: 15.3695 - val_mae: 1.1547 - val_mse: 15.3695 - learning_rate: 0.0010\n",
            "Epoch 483/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3067238.0000 - mae: 1056.2832 - mse: 3067238.0000 - val_loss: 15.4378 - val_mae: 1.0724 - val_mse: 15.4378 - learning_rate: 0.0010\n",
            "Epoch 484/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3115491.5000 - mae: 1085.9746 - mse: 3115491.5000 - val_loss: 15.5544 - val_mae: 1.1789 - val_mse: 15.5544 - learning_rate: 0.0010\n",
            "Epoch 485/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3273581.7500 - mae: 1096.4830 - mse: 3273581.7500 - val_loss: 15.5869 - val_mae: 1.0936 - val_mse: 15.5869 - learning_rate: 0.0010\n",
            "Epoch 486/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3406838.2500 - mae: 1141.3805 - mse: 3406838.2500 - val_loss: 15.8979 - val_mae: 1.2197 - val_mse: 15.8979 - learning_rate: 0.0010\n",
            "Epoch 487/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3677495.5000 - mae: 1171.4346 - mse: 3677495.5000 - val_loss: 15.9574 - val_mae: 1.1357 - val_mse: 15.9574 - learning_rate: 0.0010\n",
            "Epoch 488/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3957243.5000 - mae: 1239.3750 - mse: 3957243.5000 - val_loss: 16.5104 - val_mae: 1.2847 - val_mse: 16.5104 - learning_rate: 0.0010\n",
            "Epoch 489/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4428849.5000 - mae: 1298.1675 - mse: 4428849.5000 - val_loss: 16.6897 - val_mae: 1.2121 - val_mse: 16.6897 - learning_rate: 0.0010\n",
            "Epoch 490/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4971539.0000 - mae: 1402.4778 - mse: 4971539.0000 - val_loss: 17.6767 - val_mae: 1.3951 - val_mse: 17.6767 - learning_rate: 0.0010\n",
            "Epoch 491/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5811188.0000 - mae: 1508.6621 - mse: 5811188.0000 - val_loss: 18.0113 - val_mae: 1.3390 - val_mse: 18.0113 - learning_rate: 0.0010\n",
            "Epoch 492/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6822107.5000 - mae: 1660.5229 - mse: 6822107.5000 - val_loss: 19.7602 - val_mae: 1.5691 - val_mse: 19.7602 - learning_rate: 0.0010\n",
            "Epoch 493/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8257868.0000 - mae: 1825.3749 - mse: 8257868.0000 - val_loss: 20.3089 - val_mae: 1.5311 - val_mse: 20.3089 - learning_rate: 0.0010\n",
            "Epoch 494/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10024678.0000 - mae: 2034.5499 - mse: 10024678.0000 - val_loss: 23.2513 - val_mae: 1.8228 - val_mse: 23.2513 - learning_rate: 0.0010\n",
            "Epoch 495/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12329773.0000 - mae: 2260.7734 - mse: 12329773.0000 - val_loss: 24.0376 - val_mae: 1.7956 - val_mse: 24.0376 - learning_rate: 0.0010\n",
            "Epoch 496/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15244680.0000 - mae: 2531.0117 - mse: 15244680.0000 - val_loss: 28.7001 - val_mae: 2.1598 - val_mse: 28.7001 - learning_rate: 0.0010\n",
            "Epoch 497/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 18829840.0000 - mae: 2823.8167 - mse: 18829840.0000 - val_loss: 30.0144 - val_mae: 2.1390 - val_mse: 30.0144 - learning_rate: 0.0010\n",
            "Epoch 498/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23350720.0000 - mae: 3157.1943 - mse: 23350720.0000 - val_loss: 36.6586 - val_mae: 2.5649 - val_mse: 36.6586 - learning_rate: 0.0010\n",
            "Epoch 499/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 28716178.0000 - mae: 3511.8145 - mse: 28716178.0000 - val_loss: 38.7657 - val_mae: 2.5651 - val_mse: 38.7657 - learning_rate: 0.0010\n",
            "Epoch 500/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 35169008.0000 - mae: 3900.0793 - mse: 35169008.0000 - val_loss: 47.5110 - val_mae: 3.0285 - val_mse: 47.5110 - learning_rate: 0.0010\n",
            "Epoch 501/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 42274684.0000 - mae: 4282.8799 - mse: 42274684.0000 - val_loss: 49.5273 - val_mae: 3.0190 - val_mse: 49.5273 - learning_rate: 0.0010\n",
            "Epoch 502/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 49884092.0000 - mae: 4668.0015 - mse: 49884092.0000 - val_loss: 58.7729 - val_mae: 3.4450 - val_mse: 58.7729 - learning_rate: 0.0010\n",
            "Epoch 503/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 125737216.0000 - mae: 9868.4580 - mse: 125737216.0000\n",
            "Epoch 503: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 56610512.0000 - mae: 4976.4956 - mse: 56610512.0000 - val_loss: 58.2064 - val_mae: 3.3442 - val_mse: 58.2064 - learning_rate: 0.0010\n",
            "Epoch 504/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 66767548.0000 - mae: 5824.4829 - mse: 66767548.0000 - val_loss: 40.3866 - val_mae: 2.6327 - val_mse: 40.3866 - learning_rate: 1.0000e-04\n",
            "Epoch 505/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 40041892.0000 - mae: 4417.5269 - mse: 40041892.0000 - val_loss: 19.9330 - val_mae: 1.4881 - val_mse: 19.9330 - learning_rate: 1.0000e-04\n",
            "Epoch 506/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10021690.0000 - mae: 2072.2747 - mse: 10021690.0000 - val_loss: 14.8126 - val_mae: 1.0139 - val_mse: 14.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 507/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1804665.5000 - mae: 780.0027 - mse: 1804665.5000 - val_loss: 17.7865 - val_mae: 1.3647 - val_mse: 17.7865 - learning_rate: 1.0000e-04\n",
            "Epoch 508/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5195478.0000 - mae: 1475.3743 - mse: 5195478.0000 - val_loss: 19.0190 - val_mae: 1.4747 - val_mse: 19.0190 - learning_rate: 1.0000e-04\n",
            "Epoch 509/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6632765.5000 - mae: 1681.8770 - mse: 6632765.5000 - val_loss: 17.2543 - val_mae: 1.3148 - val_mse: 17.2543 - learning_rate: 1.0000e-04\n",
            "Epoch 510/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4391368.5000 - mae: 1316.0483 - mse: 4391368.5000 - val_loss: 15.3707 - val_mae: 1.1036 - val_mse: 15.3707 - learning_rate: 1.0000e-04\n",
            "Epoch 511/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2235952.7500 - mae: 881.3582 - mse: 2235952.7500 - val_loss: 14.7324 - val_mae: 1.0009 - val_mse: 14.7324 - learning_rate: 1.0000e-04\n",
            "Epoch 512/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1770519.8750 - mae: 764.6024 - mse: 1770519.8750 - val_loss: 14.7725 - val_mae: 0.9955 - val_mse: 14.7725 - learning_rate: 1.0000e-04\n",
            "Epoch 513/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2051219.3750 - mae: 846.7054 - mse: 2051219.3750 - val_loss: 14.7934 - val_mae: 0.9979 - val_mse: 14.7934 - learning_rate: 1.0000e-04\n",
            "Epoch 514/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2112971.5000 - mae: 861.7298 - mse: 2112971.5000 - val_loss: 14.7124 - val_mae: 0.9923 - val_mse: 14.7124 - learning_rate: 1.0000e-04\n",
            "Epoch 515/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1919493.0000 - mae: 810.0410 - mse: 1919493.0000 - val_loss: 14.6860 - val_mae: 0.9959 - val_mse: 14.6860 - learning_rate: 1.0000e-04\n",
            "Epoch 516/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1767159.5000 - mae: 763.9749 - mse: 1767159.5000 - val_loss: 14.7373 - val_mae: 1.0097 - val_mse: 14.7373 - learning_rate: 1.0000e-04\n",
            "Epoch 517/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1744854.5000 - mae: 756.1479 - mse: 1744854.5000 - val_loss: 14.7831 - val_mae: 1.0203 - val_mse: 14.7831 - learning_rate: 1.0000e-04\n",
            "Epoch 518/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1765285.6250 - mae: 761.6703 - mse: 1765285.6250 - val_loss: 14.7767 - val_mae: 1.0203 - val_mse: 14.7767 - learning_rate: 1.0000e-04\n",
            "Epoch 519/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1762964.5000 - mae: 760.8142 - mse: 1762964.5000 - val_loss: 14.7362 - val_mae: 1.0133 - val_mse: 14.7362 - learning_rate: 1.0000e-04\n",
            "Epoch 520/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1744153.6250 - mae: 755.2772 - mse: 1744153.6250 - val_loss: 14.6946 - val_mae: 1.0059 - val_mse: 14.6946 - learning_rate: 1.0000e-04\n",
            "Epoch 521/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1731706.2500 - mae: 751.9642 - mse: 1731706.2500 - val_loss: 14.6669 - val_mae: 1.0011 - val_mse: 14.6669 - learning_rate: 1.0000e-04\n",
            "Epoch 522/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1729119.3750 - mae: 751.6839 - mse: 1729119.3750 - val_loss: 14.6525 - val_mae: 0.9991 - val_mse: 14.6525 - learning_rate: 1.0000e-04\n",
            "Epoch 523/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1728578.0000 - mae: 751.8094 - mse: 1728578.0000 - val_loss: 14.6469 - val_mae: 0.9989 - val_mse: 14.6469 - learning_rate: 1.0000e-04\n",
            "Epoch 524/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1725944.5000 - mae: 750.9982 - mse: 1725944.5000 - val_loss: 14.6455 - val_mae: 0.9998 - val_mse: 14.6455 - learning_rate: 1.0000e-04\n",
            "Epoch 525/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1722450.7500 - mae: 749.7664 - mse: 1722450.7500 - val_loss: 14.6454 - val_mae: 1.0009 - val_mse: 14.6454 - learning_rate: 1.0000e-04\n",
            "Epoch 526/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1719765.8750 - mae: 748.6328 - mse: 1719765.8750 - val_loss: 14.6433 - val_mae: 1.0016 - val_mse: 14.6433 - learning_rate: 1.0000e-04\n",
            "Epoch 527/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1717853.8750 - mae: 747.8997 - mse: 1717853.8750 - val_loss: 14.6383 - val_mae: 1.0014 - val_mse: 14.6383 - learning_rate: 1.0000e-04\n",
            "Epoch 528/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1716014.1250 - mae: 747.3010 - mse: 1716014.1250 - val_loss: 14.6307 - val_mae: 1.0007 - val_mse: 14.6307 - learning_rate: 1.0000e-04\n",
            "Epoch 529/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1714064.6250 - mae: 746.7360 - mse: 1714064.6250 - val_loss: 14.6219 - val_mae: 0.9998 - val_mse: 14.6219 - learning_rate: 1.0000e-04\n",
            "Epoch 530/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1712140.7500 - mae: 746.2101 - mse: 1712140.7500 - val_loss: 14.6133 - val_mae: 0.9988 - val_mse: 14.6133 - learning_rate: 1.0000e-04\n",
            "Epoch 531/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1710271.7500 - mae: 745.6992 - mse: 1710271.7500 - val_loss: 14.6054 - val_mae: 0.9980 - val_mse: 14.6054 - learning_rate: 1.0000e-04\n",
            "Epoch 532/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1708444.7500 - mae: 745.1796 - mse: 1708444.7500 - val_loss: 14.5984 - val_mae: 0.9974 - val_mse: 14.5984 - learning_rate: 1.0000e-04\n",
            "Epoch 533/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1706649.8750 - mae: 744.6304 - mse: 1706649.8750 - val_loss: 14.5920 - val_mae: 0.9969 - val_mse: 14.5920 - learning_rate: 1.0000e-04\n",
            "Epoch 534/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1704869.7500 - mae: 744.0563 - mse: 1704869.7500 - val_loss: 14.5858 - val_mae: 0.9965 - val_mse: 14.5858 - learning_rate: 1.0000e-04\n",
            "Epoch 535/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1703133.1250 - mae: 743.4845 - mse: 1703133.1250 - val_loss: 14.5794 - val_mae: 0.9961 - val_mse: 14.5794 - learning_rate: 1.0000e-04\n",
            "Epoch 536/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1701447.1250 - mae: 742.9288 - mse: 1701447.1250 - val_loss: 14.5728 - val_mae: 0.9956 - val_mse: 14.5728 - learning_rate: 1.0000e-04\n",
            "Epoch 537/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1699761.3750 - mae: 742.3837 - mse: 1699761.3750 - val_loss: 14.5658 - val_mae: 0.9950 - val_mse: 14.5658 - learning_rate: 1.0000e-04\n",
            "Epoch 538/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1698062.3750 - mae: 741.8433 - mse: 1698062.3750 - val_loss: 14.5586 - val_mae: 0.9944 - val_mse: 14.5586 - learning_rate: 1.0000e-04\n",
            "Epoch 539/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1696372.0000 - mae: 741.3032 - mse: 1696372.0000 - val_loss: 14.5514 - val_mae: 0.9938 - val_mse: 14.5514 - learning_rate: 1.0000e-04\n",
            "Epoch 540/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1694694.2500 - mae: 740.7519 - mse: 1694694.2500 - val_loss: 14.5438 - val_mae: 0.9931 - val_mse: 14.5438 - learning_rate: 1.0000e-04\n",
            "Epoch 541/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1693025.7500 - mae: 740.1849 - mse: 1693025.7500 - val_loss: 14.5361 - val_mae: 0.9924 - val_mse: 14.5361 - learning_rate: 1.0000e-04\n",
            "Epoch 542/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1691375.0000 - mae: 739.6063 - mse: 1691375.0000 - val_loss: 14.5285 - val_mae: 0.9918 - val_mse: 14.5285 - learning_rate: 1.0000e-04\n",
            "Epoch 543/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1689753.5000 - mae: 739.0299 - mse: 1689753.5000 - val_loss: 14.5210 - val_mae: 0.9911 - val_mse: 14.5210 - learning_rate: 1.0000e-04\n",
            "Epoch 544/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1688204.6250 - mae: 738.4667 - mse: 1688204.6250 - val_loss: 14.5139 - val_mae: 0.9905 - val_mse: 14.5139 - learning_rate: 1.0000e-04\n",
            "Epoch 545/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1686704.0000 - mae: 737.9136 - mse: 1686704.0000 - val_loss: 14.5069 - val_mae: 0.9899 - val_mse: 14.5069 - learning_rate: 1.0000e-04\n",
            "Epoch 546/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1685181.6250 - mae: 737.3610 - mse: 1685181.6250 - val_loss: 14.5000 - val_mae: 0.9894 - val_mse: 14.5000 - learning_rate: 1.0000e-04\n",
            "Epoch 547/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1683659.0000 - mae: 736.8223 - mse: 1683659.0000 - val_loss: 14.4930 - val_mae: 0.9889 - val_mse: 14.4930 - learning_rate: 1.0000e-04\n",
            "Epoch 548/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1682147.1250 - mae: 736.2968 - mse: 1682147.1250 - val_loss: 14.4867 - val_mae: 0.9885 - val_mse: 14.4867 - learning_rate: 1.0000e-04\n",
            "Epoch 549/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1680658.0000 - mae: 735.7855 - mse: 1680658.0000 - val_loss: 14.4809 - val_mae: 0.9881 - val_mse: 14.4809 - learning_rate: 1.0000e-04\n",
            "Epoch 550/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1679213.8750 - mae: 735.2949 - mse: 1679213.8750 - val_loss: 14.4753 - val_mae: 0.9877 - val_mse: 14.4753 - learning_rate: 1.0000e-04\n",
            "Epoch 551/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1677815.5000 - mae: 734.8455 - mse: 1677815.5000 - val_loss: 14.4700 - val_mae: 0.9874 - val_mse: 14.4700 - learning_rate: 1.0000e-04\n",
            "Epoch 552/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1676450.0000 - mae: 734.4001 - mse: 1676450.0000 - val_loss: 14.4648 - val_mae: 0.9870 - val_mse: 14.4648 - learning_rate: 1.0000e-04\n",
            "Epoch 553/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1675122.2500 - mae: 733.9674 - mse: 1675122.2500 - val_loss: 14.4597 - val_mae: 0.9866 - val_mse: 14.4597 - learning_rate: 1.0000e-04\n",
            "Epoch 554/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1673877.7500 - mae: 733.5531 - mse: 1673877.7500 - val_loss: 14.4548 - val_mae: 0.9863 - val_mse: 14.4548 - learning_rate: 1.0000e-04\n",
            "Epoch 555/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1672720.3750 - mae: 733.1609 - mse: 1672720.3750 - val_loss: 14.4500 - val_mae: 0.9860 - val_mse: 14.4500 - learning_rate: 1.0000e-04\n",
            "Epoch 556/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1671608.8750 - mae: 732.7776 - mse: 1671608.8750 - val_loss: 14.4447 - val_mae: 0.9856 - val_mse: 14.4447 - learning_rate: 1.0000e-04\n",
            "Epoch 557/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1670492.1250 - mae: 732.3867 - mse: 1670492.1250 - val_loss: 14.4395 - val_mae: 0.9852 - val_mse: 14.4395 - learning_rate: 1.0000e-04\n",
            "Epoch 558/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1669397.2500 - mae: 731.9958 - mse: 1669397.2500 - val_loss: 14.4345 - val_mae: 0.9848 - val_mse: 14.4345 - learning_rate: 1.0000e-04\n",
            "Epoch 559/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1668332.0000 - mae: 731.6246 - mse: 1668332.0000 - val_loss: 14.4291 - val_mae: 0.9844 - val_mse: 14.4291 - learning_rate: 1.0000e-04\n",
            "Epoch 560/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1667262.2500 - mae: 731.2506 - mse: 1667262.2500 - val_loss: 14.4240 - val_mae: 0.9840 - val_mse: 14.4240 - learning_rate: 1.0000e-04\n",
            "Epoch 561/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1666198.2500 - mae: 730.8781 - mse: 1666198.2500 - val_loss: 14.4191 - val_mae: 0.9836 - val_mse: 14.4191 - learning_rate: 1.0000e-04\n",
            "Epoch 562/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1665184.2500 - mae: 730.5139 - mse: 1665184.2500 - val_loss: 14.4144 - val_mae: 0.9832 - val_mse: 14.4144 - learning_rate: 1.0000e-04\n",
            "Epoch 563/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1664162.5000 - mae: 730.1536 - mse: 1664162.5000 - val_loss: 14.4090 - val_mae: 0.9828 - val_mse: 14.4090 - learning_rate: 1.0000e-04\n",
            "Epoch 564/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1663193.2500 - mae: 729.7990 - mse: 1663193.2500 - val_loss: 14.4040 - val_mae: 0.9824 - val_mse: 14.4040 - learning_rate: 1.0000e-04\n",
            "Epoch 565/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1662273.1250 - mae: 729.4538 - mse: 1662273.1250 - val_loss: 14.3992 - val_mae: 0.9820 - val_mse: 14.3992 - learning_rate: 1.0000e-04\n",
            "Epoch 566/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1661383.5000 - mae: 729.1184 - mse: 1661383.5000 - val_loss: 14.3946 - val_mae: 0.9816 - val_mse: 14.3946 - learning_rate: 1.0000e-04\n",
            "Epoch 567/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1660502.2500 - mae: 728.7843 - mse: 1660502.2500 - val_loss: 14.3895 - val_mae: 0.9812 - val_mse: 14.3895 - learning_rate: 1.0000e-04\n",
            "Epoch 568/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1659640.2500 - mae: 728.4485 - mse: 1659640.2500 - val_loss: 14.3846 - val_mae: 0.9808 - val_mse: 14.3846 - learning_rate: 1.0000e-04\n",
            "Epoch 569/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1658790.5000 - mae: 728.1122 - mse: 1658790.5000 - val_loss: 14.3800 - val_mae: 0.9804 - val_mse: 14.3800 - learning_rate: 1.0000e-04\n",
            "Epoch 570/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1657954.5000 - mae: 727.7755 - mse: 1657954.5000 - val_loss: 14.3752 - val_mae: 0.9801 - val_mse: 14.3752 - learning_rate: 1.0000e-04\n",
            "Epoch 571/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1657158.7500 - mae: 727.4461 - mse: 1657158.7500 - val_loss: 14.3704 - val_mae: 0.9797 - val_mse: 14.3704 - learning_rate: 1.0000e-04\n",
            "Epoch 572/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1656391.7500 - mae: 727.1272 - mse: 1656391.7500 - val_loss: 14.3659 - val_mae: 0.9793 - val_mse: 14.3659 - learning_rate: 1.0000e-04\n",
            "Epoch 573/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1655655.8750 - mae: 726.8193 - mse: 1655655.8750 - val_loss: 14.3615 - val_mae: 0.9789 - val_mse: 14.3615 - learning_rate: 1.0000e-04\n",
            "Epoch 574/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1654951.1250 - mae: 726.5175 - mse: 1654951.1250 - val_loss: 14.3571 - val_mae: 0.9785 - val_mse: 14.3571 - learning_rate: 1.0000e-04\n",
            "Epoch 575/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1654263.2500 - mae: 726.2233 - mse: 1654263.2500 - val_loss: 14.3530 - val_mae: 0.9781 - val_mse: 14.3530 - learning_rate: 1.0000e-04\n",
            "Epoch 576/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1653586.3750 - mae: 725.9327 - mse: 1653586.3750 - val_loss: 14.3488 - val_mae: 0.9778 - val_mse: 14.3488 - learning_rate: 1.0000e-04\n",
            "Epoch 577/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1652925.7500 - mae: 725.6455 - mse: 1652925.7500 - val_loss: 14.3446 - val_mae: 0.9774 - val_mse: 14.3446 - learning_rate: 1.0000e-04\n",
            "Epoch 578/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1652286.7500 - mae: 725.3616 - mse: 1652286.7500 - val_loss: 14.3407 - val_mae: 0.9770 - val_mse: 14.3407 - learning_rate: 1.0000e-04\n",
            "Epoch 579/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1651674.5000 - mae: 725.0832 - mse: 1651674.5000 - val_loss: 14.3366 - val_mae: 0.9766 - val_mse: 14.3366 - learning_rate: 1.0000e-04\n",
            "Epoch 580/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1651090.1250 - mae: 724.8152 - mse: 1651090.1250 - val_loss: 14.3330 - val_mae: 0.9763 - val_mse: 14.3330 - learning_rate: 1.0000e-04\n",
            "Epoch 581/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1650510.3750 - mae: 724.5526 - mse: 1650510.3750 - val_loss: 14.3296 - val_mae: 0.9760 - val_mse: 14.3296 - learning_rate: 1.0000e-04\n",
            "Epoch 582/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1649937.6250 - mae: 724.2899 - mse: 1649937.6250 - val_loss: 14.3264 - val_mae: 0.9757 - val_mse: 14.3264 - learning_rate: 1.0000e-04\n",
            "Epoch 583/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1649375.5000 - mae: 724.0292 - mse: 1649375.5000 - val_loss: 14.3229 - val_mae: 0.9753 - val_mse: 14.3229 - learning_rate: 1.0000e-04\n",
            "Epoch 584/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1648802.8750 - mae: 723.7596 - mse: 1648802.8750 - val_loss: 14.3194 - val_mae: 0.9750 - val_mse: 14.3194 - learning_rate: 1.0000e-04\n",
            "Epoch 585/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1648213.3750 - mae: 723.4873 - mse: 1648213.3750 - val_loss: 14.3161 - val_mae: 0.9746 - val_mse: 14.3161 - learning_rate: 1.0000e-04\n",
            "Epoch 586/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1647616.3750 - mae: 723.2209 - mse: 1647616.3750 - val_loss: 14.3130 - val_mae: 0.9743 - val_mse: 14.3130 - learning_rate: 1.0000e-04\n",
            "Epoch 587/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1647016.6250 - mae: 722.9615 - mse: 1647016.6250 - val_loss: 14.3096 - val_mae: 0.9740 - val_mse: 14.3096 - learning_rate: 1.0000e-04\n",
            "Epoch 588/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1646442.7500 - mae: 722.7067 - mse: 1646442.7500 - val_loss: 14.3064 - val_mae: 0.9737 - val_mse: 14.3064 - learning_rate: 1.0000e-04\n",
            "Epoch 589/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1645904.7500 - mae: 722.4577 - mse: 1645904.7500 - val_loss: 14.3032 - val_mae: 0.9733 - val_mse: 14.3032 - learning_rate: 1.0000e-04\n",
            "Epoch 590/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1645377.2500 - mae: 722.2100 - mse: 1645377.2500 - val_loss: 14.3001 - val_mae: 0.9730 - val_mse: 14.3001 - learning_rate: 1.0000e-04\n",
            "Epoch 591/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1644864.3750 - mae: 721.9747 - mse: 1644864.3750 - val_loss: 14.2971 - val_mae: 0.9727 - val_mse: 14.2971 - learning_rate: 1.0000e-04\n",
            "Epoch 592/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1644350.5000 - mae: 721.7590 - mse: 1644350.5000 - val_loss: 14.2938 - val_mae: 0.9724 - val_mse: 14.2938 - learning_rate: 1.0000e-04\n",
            "Epoch 593/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1643842.8750 - mae: 721.5400 - mse: 1643842.8750 - val_loss: 14.2908 - val_mae: 0.9721 - val_mse: 14.2908 - learning_rate: 1.0000e-04\n",
            "Epoch 594/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1643345.1250 - mae: 721.3267 - mse: 1643345.1250 - val_loss: 14.2879 - val_mae: 0.9718 - val_mse: 14.2879 - learning_rate: 1.0000e-04\n",
            "Epoch 595/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1642861.5000 - mae: 721.1252 - mse: 1642861.5000 - val_loss: 14.2847 - val_mae: 0.9715 - val_mse: 14.2847 - learning_rate: 1.0000e-04\n",
            "Epoch 596/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1642400.5000 - mae: 720.9360 - mse: 1642400.5000 - val_loss: 14.2815 - val_mae: 0.9712 - val_mse: 14.2815 - learning_rate: 1.0000e-04\n",
            "Epoch 597/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1641970.7500 - mae: 720.7659 - mse: 1641970.7500 - val_loss: 14.2785 - val_mae: 0.9709 - val_mse: 14.2785 - learning_rate: 1.0000e-04\n",
            "Epoch 598/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1641499.6250 - mae: 720.6007 - mse: 1641499.6250 - val_loss: 14.2754 - val_mae: 0.9706 - val_mse: 14.2754 - learning_rate: 1.0000e-04\n",
            "Epoch 599/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1641009.3750 - mae: 720.4282 - mse: 1641009.3750 - val_loss: 14.2721 - val_mae: 0.9703 - val_mse: 14.2721 - learning_rate: 1.0000e-04\n",
            "Epoch 600/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1640532.8750 - mae: 720.2536 - mse: 1640532.8750 - val_loss: 14.2689 - val_mae: 0.9700 - val_mse: 14.2689 - learning_rate: 1.0000e-04\n",
            "Epoch 601/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1640048.6250 - mae: 720.0797 - mse: 1640048.6250 - val_loss: 14.2659 - val_mae: 0.9697 - val_mse: 14.2659 - learning_rate: 1.0000e-04\n",
            "Epoch 602/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1639569.2500 - mae: 719.9105 - mse: 1639569.2500 - val_loss: 14.2626 - val_mae: 0.9694 - val_mse: 14.2626 - learning_rate: 1.0000e-04\n",
            "Epoch 603/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1639099.0000 - mae: 719.7404 - mse: 1639099.0000 - val_loss: 14.2594 - val_mae: 0.9691 - val_mse: 14.2594 - learning_rate: 1.0000e-04\n",
            "Epoch 604/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1638636.3750 - mae: 719.5765 - mse: 1638636.3750 - val_loss: 14.2564 - val_mae: 0.9689 - val_mse: 14.2564 - learning_rate: 1.0000e-04\n",
            "Epoch 605/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1638193.8750 - mae: 719.4182 - mse: 1638193.8750 - val_loss: 14.2532 - val_mae: 0.9686 - val_mse: 14.2532 - learning_rate: 1.0000e-04\n",
            "Epoch 606/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1637777.3750 - mae: 719.2629 - mse: 1637777.3750 - val_loss: 14.2498 - val_mae: 0.9682 - val_mse: 14.2498 - learning_rate: 1.0000e-04\n",
            "Epoch 607/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1637392.0000 - mae: 719.1125 - mse: 1637392.0000 - val_loss: 14.2467 - val_mae: 0.9679 - val_mse: 14.2467 - learning_rate: 1.0000e-04\n",
            "Epoch 608/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1637012.0000 - mae: 718.9676 - mse: 1637012.0000 - val_loss: 14.2436 - val_mae: 0.9677 - val_mse: 14.2436 - learning_rate: 1.0000e-04\n",
            "Epoch 609/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1636625.8750 - mae: 718.8273 - mse: 1636625.8750 - val_loss: 14.2408 - val_mae: 0.9674 - val_mse: 14.2408 - learning_rate: 1.0000e-04\n",
            "Epoch 610/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1636246.7500 - mae: 718.6888 - mse: 1636246.7500 - val_loss: 14.2379 - val_mae: 0.9671 - val_mse: 14.2379 - learning_rate: 1.0000e-04\n",
            "Epoch 611/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1635859.0000 - mae: 718.5525 - mse: 1635859.0000 - val_loss: 14.2348 - val_mae: 0.9668 - val_mse: 14.2348 - learning_rate: 1.0000e-04\n",
            "Epoch 612/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1635449.6250 - mae: 718.4101 - mse: 1635449.6250 - val_loss: 14.2319 - val_mae: 0.9664 - val_mse: 14.2319 - learning_rate: 1.0000e-04\n",
            "Epoch 613/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1635046.8750 - mae: 718.2669 - mse: 1635046.8750 - val_loss: 14.2291 - val_mae: 0.9662 - val_mse: 14.2291 - learning_rate: 1.0000e-04\n",
            "Epoch 614/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1634644.7500 - mae: 718.1233 - mse: 1634644.7500 - val_loss: 14.2262 - val_mae: 0.9659 - val_mse: 14.2262 - learning_rate: 1.0000e-04\n",
            "Epoch 615/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1634254.0000 - mae: 717.9772 - mse: 1634254.0000 - val_loss: 14.2235 - val_mae: 0.9656 - val_mse: 14.2235 - learning_rate: 1.0000e-04\n",
            "Epoch 616/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1633864.7500 - mae: 717.8307 - mse: 1633864.7500 - val_loss: 14.2206 - val_mae: 0.9653 - val_mse: 14.2206 - learning_rate: 1.0000e-04\n",
            "Epoch 617/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1633488.1250 - mae: 717.6866 - mse: 1633488.1250 - val_loss: 14.2179 - val_mae: 0.9651 - val_mse: 14.2179 - learning_rate: 1.0000e-04\n",
            "Epoch 618/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1633106.6250 - mae: 717.5454 - mse: 1633106.6250 - val_loss: 14.2153 - val_mae: 0.9649 - val_mse: 14.2153 - learning_rate: 1.0000e-04\n",
            "Epoch 619/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1632736.0000 - mae: 717.4069 - mse: 1632736.0000 - val_loss: 14.2125 - val_mae: 0.9646 - val_mse: 14.2125 - learning_rate: 1.0000e-04\n",
            "Epoch 620/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1632365.0000 - mae: 717.2697 - mse: 1632365.0000 - val_loss: 14.2096 - val_mae: 0.9643 - val_mse: 14.2096 - learning_rate: 1.0000e-04\n",
            "Epoch 621/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1632000.0000 - mae: 717.1376 - mse: 1632000.0000 - val_loss: 14.2068 - val_mae: 0.9641 - val_mse: 14.2068 - learning_rate: 1.0000e-04\n",
            "Epoch 622/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1631627.8750 - mae: 717.0080 - mse: 1631627.8750 - val_loss: 14.2041 - val_mae: 0.9639 - val_mse: 14.2041 - learning_rate: 1.0000e-04\n",
            "Epoch 623/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1631244.0000 - mae: 716.8821 - mse: 1631244.0000 - val_loss: 14.2013 - val_mae: 0.9637 - val_mse: 14.2013 - learning_rate: 1.0000e-04\n",
            "Epoch 624/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1630842.8750 - mae: 716.7505 - mse: 1630842.8750 - val_loss: 14.1983 - val_mae: 0.9634 - val_mse: 14.1983 - learning_rate: 1.0000e-04\n",
            "Epoch 625/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1630441.7500 - mae: 716.6155 - mse: 1630441.7500 - val_loss: 14.1956 - val_mae: 0.9631 - val_mse: 14.1956 - learning_rate: 1.0000e-04\n",
            "Epoch 626/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1630053.3750 - mae: 716.4824 - mse: 1630053.3750 - val_loss: 14.1930 - val_mae: 0.9629 - val_mse: 14.1930 - learning_rate: 1.0000e-04\n",
            "Epoch 627/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1629683.0000 - mae: 716.3529 - mse: 1629683.0000 - val_loss: 14.1902 - val_mae: 0.9627 - val_mse: 14.1902 - learning_rate: 1.0000e-04\n",
            "Epoch 628/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1629342.3750 - mae: 716.2268 - mse: 1629342.3750 - val_loss: 14.1874 - val_mae: 0.9625 - val_mse: 14.1874 - learning_rate: 1.0000e-04\n",
            "Epoch 629/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1629019.0000 - mae: 716.1060 - mse: 1629019.0000 - val_loss: 14.1845 - val_mae: 0.9623 - val_mse: 14.1845 - learning_rate: 1.0000e-04\n",
            "Epoch 630/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1628723.1250 - mae: 715.9921 - mse: 1628723.1250 - val_loss: 14.1814 - val_mae: 0.9620 - val_mse: 14.1814 - learning_rate: 1.0000e-04\n",
            "Epoch 631/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1628439.5000 - mae: 715.8829 - mse: 1628439.5000 - val_loss: 14.1785 - val_mae: 0.9618 - val_mse: 14.1785 - learning_rate: 1.0000e-04\n",
            "Epoch 632/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1628145.2500 - mae: 715.7763 - mse: 1628145.2500 - val_loss: 14.1757 - val_mae: 0.9616 - val_mse: 14.1757 - learning_rate: 1.0000e-04\n",
            "Epoch 633/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1627838.3750 - mae: 715.6718 - mse: 1627838.3750 - val_loss: 14.1729 - val_mae: 0.9614 - val_mse: 14.1729 - learning_rate: 1.0000e-04\n",
            "Epoch 634/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1627518.1250 - mae: 715.5657 - mse: 1627518.1250 - val_loss: 14.1702 - val_mae: 0.9612 - val_mse: 14.1702 - learning_rate: 1.0000e-04\n",
            "Epoch 635/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1627191.1250 - mae: 715.4587 - mse: 1627191.1250 - val_loss: 14.1674 - val_mae: 0.9609 - val_mse: 14.1674 - learning_rate: 1.0000e-04\n",
            "Epoch 636/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1626856.5000 - mae: 715.3469 - mse: 1626856.5000 - val_loss: 14.1647 - val_mae: 0.9606 - val_mse: 14.1647 - learning_rate: 1.0000e-04\n",
            "Epoch 637/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1626531.5000 - mae: 715.2328 - mse: 1626531.5000 - val_loss: 14.1622 - val_mae: 0.9604 - val_mse: 14.1622 - learning_rate: 1.0000e-04\n",
            "Epoch 638/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1626204.8750 - mae: 715.1187 - mse: 1626204.8750 - val_loss: 14.1598 - val_mae: 0.9602 - val_mse: 14.1598 - learning_rate: 1.0000e-04\n",
            "Epoch 639/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1625873.5000 - mae: 715.0097 - mse: 1625873.5000 - val_loss: 14.1574 - val_mae: 0.9600 - val_mse: 14.1574 - learning_rate: 1.0000e-04\n",
            "Epoch 640/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1625552.7500 - mae: 714.9061 - mse: 1625552.7500 - val_loss: 14.1550 - val_mae: 0.9597 - val_mse: 14.1550 - learning_rate: 1.0000e-04\n",
            "Epoch 641/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1625236.0000 - mae: 714.8006 - mse: 1625236.0000 - val_loss: 14.1527 - val_mae: 0.9594 - val_mse: 14.1527 - learning_rate: 1.0000e-04\n",
            "Epoch 642/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1624917.3750 - mae: 714.6967 - mse: 1624917.3750 - val_loss: 14.1504 - val_mae: 0.9593 - val_mse: 14.1504 - learning_rate: 1.0000e-04\n",
            "Epoch 643/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1624609.7500 - mae: 714.5972 - mse: 1624609.7500 - val_loss: 14.1479 - val_mae: 0.9591 - val_mse: 14.1479 - learning_rate: 1.0000e-04\n",
            "Epoch 644/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1624306.2500 - mae: 714.4980 - mse: 1624306.2500 - val_loss: 14.1454 - val_mae: 0.9589 - val_mse: 14.1454 - learning_rate: 1.0000e-04\n",
            "Epoch 645/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1623988.5000 - mae: 714.3954 - mse: 1623988.5000 - val_loss: 14.1429 - val_mae: 0.9587 - val_mse: 14.1429 - learning_rate: 1.0000e-04\n",
            "Epoch 646/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1623668.3750 - mae: 714.2930 - mse: 1623668.3750 - val_loss: 14.1404 - val_mae: 0.9585 - val_mse: 14.1404 - learning_rate: 1.0000e-04\n",
            "Epoch 647/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1623321.5000 - mae: 714.1808 - mse: 1623321.5000 - val_loss: 14.1379 - val_mae: 0.9583 - val_mse: 14.1379 - learning_rate: 1.0000e-04\n",
            "Epoch 648/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1622936.7500 - mae: 714.0649 - mse: 1622936.7500 - val_loss: 14.1354 - val_mae: 0.9581 - val_mse: 14.1354 - learning_rate: 1.0000e-04\n",
            "Epoch 649/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1622529.8750 - mae: 713.9462 - mse: 1622529.8750 - val_loss: 14.1330 - val_mae: 0.9578 - val_mse: 14.1330 - learning_rate: 1.0000e-04\n",
            "Epoch 650/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1622123.8750 - mae: 713.8314 - mse: 1622123.8750 - val_loss: 14.1304 - val_mae: 0.9576 - val_mse: 14.1304 - learning_rate: 1.0000e-04\n",
            "Epoch 651/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1621710.5000 - mae: 713.7123 - mse: 1621710.5000 - val_loss: 14.1277 - val_mae: 0.9574 - val_mse: 14.1277 - learning_rate: 1.0000e-04\n",
            "Epoch 652/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1621274.8750 - mae: 713.5855 - mse: 1621274.8750 - val_loss: 14.1250 - val_mae: 0.9572 - val_mse: 14.1250 - learning_rate: 1.0000e-04\n",
            "Epoch 653/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1620835.1250 - mae: 713.4543 - mse: 1620835.1250 - val_loss: 14.1223 - val_mae: 0.9570 - val_mse: 14.1223 - learning_rate: 1.0000e-04\n",
            "Epoch 654/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1620395.3750 - mae: 713.3210 - mse: 1620395.3750 - val_loss: 14.1195 - val_mae: 0.9567 - val_mse: 14.1195 - learning_rate: 1.0000e-04\n",
            "Epoch 655/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1619975.2500 - mae: 713.1894 - mse: 1619975.2500 - val_loss: 14.1169 - val_mae: 0.9565 - val_mse: 14.1169 - learning_rate: 1.0000e-04\n",
            "Epoch 656/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1619536.2500 - mae: 713.0584 - mse: 1619536.2500 - val_loss: 14.1144 - val_mae: 0.9563 - val_mse: 14.1144 - learning_rate: 1.0000e-04\n",
            "Epoch 657/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1619095.0000 - mae: 712.9281 - mse: 1619095.0000 - val_loss: 14.1118 - val_mae: 0.9561 - val_mse: 14.1118 - learning_rate: 1.0000e-04\n",
            "Epoch 658/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1618655.0000 - mae: 712.7925 - mse: 1618655.0000 - val_loss: 14.1092 - val_mae: 0.9559 - val_mse: 14.1092 - learning_rate: 1.0000e-04\n",
            "Epoch 659/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1618216.1250 - mae: 712.6539 - mse: 1618216.1250 - val_loss: 14.1067 - val_mae: 0.9557 - val_mse: 14.1067 - learning_rate: 1.0000e-04\n",
            "Epoch 660/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1617761.5000 - mae: 712.5170 - mse: 1617761.5000 - val_loss: 14.1041 - val_mae: 0.9555 - val_mse: 14.1041 - learning_rate: 1.0000e-04\n",
            "Epoch 661/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1617308.1250 - mae: 712.3781 - mse: 1617308.1250 - val_loss: 14.1015 - val_mae: 0.9553 - val_mse: 14.1015 - learning_rate: 1.0000e-04\n",
            "Epoch 662/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1616848.0000 - mae: 712.2407 - mse: 1616848.0000 - val_loss: 14.0989 - val_mae: 0.9551 - val_mse: 14.0989 - learning_rate: 1.0000e-04\n",
            "Epoch 663/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1616398.1250 - mae: 712.1047 - mse: 1616398.1250 - val_loss: 14.0961 - val_mae: 0.9549 - val_mse: 14.0961 - learning_rate: 1.0000e-04\n",
            "Epoch 664/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1615951.6250 - mae: 711.9676 - mse: 1615951.6250 - val_loss: 14.0934 - val_mae: 0.9547 - val_mse: 14.0934 - learning_rate: 1.0000e-04\n",
            "Epoch 665/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1615488.8750 - mae: 711.8354 - mse: 1615488.8750 - val_loss: 14.0906 - val_mae: 0.9546 - val_mse: 14.0906 - learning_rate: 1.0000e-04\n",
            "Epoch 666/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1615040.0000 - mae: 711.7073 - mse: 1615040.0000 - val_loss: 14.0878 - val_mae: 0.9544 - val_mse: 14.0878 - learning_rate: 1.0000e-04\n",
            "Epoch 667/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1614618.5000 - mae: 711.5792 - mse: 1614618.5000 - val_loss: 14.0851 - val_mae: 0.9542 - val_mse: 14.0851 - learning_rate: 1.0000e-04\n",
            "Epoch 668/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1614182.0000 - mae: 711.4449 - mse: 1614182.0000 - val_loss: 14.0823 - val_mae: 0.9539 - val_mse: 14.0823 - learning_rate: 1.0000e-04\n",
            "Epoch 669/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1613755.7500 - mae: 711.3102 - mse: 1613755.7500 - val_loss: 14.0794 - val_mae: 0.9538 - val_mse: 14.0794 - learning_rate: 1.0000e-04\n",
            "Epoch 670/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1613311.6250 - mae: 711.1793 - mse: 1613311.6250 - val_loss: 14.0765 - val_mae: 0.9536 - val_mse: 14.0765 - learning_rate: 1.0000e-04\n",
            "Epoch 671/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1612816.3750 - mae: 711.0458 - mse: 1612816.3750 - val_loss: 14.0736 - val_mae: 0.9534 - val_mse: 14.0736 - learning_rate: 1.0000e-04\n",
            "Epoch 672/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1612280.1250 - mae: 710.9056 - mse: 1612280.1250 - val_loss: 14.0708 - val_mae: 0.9532 - val_mse: 14.0708 - learning_rate: 1.0000e-04\n",
            "Epoch 673/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1611743.8750 - mae: 710.7632 - mse: 1611743.8750 - val_loss: 14.0679 - val_mae: 0.9529 - val_mse: 14.0679 - learning_rate: 1.0000e-04\n",
            "Epoch 674/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1611232.8750 - mae: 710.6241 - mse: 1611232.8750 - val_loss: 14.0650 - val_mae: 0.9527 - val_mse: 14.0650 - learning_rate: 1.0000e-04\n",
            "Epoch 675/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1610717.2500 - mae: 710.4863 - mse: 1610717.2500 - val_loss: 14.0620 - val_mae: 0.9526 - val_mse: 14.0620 - learning_rate: 1.0000e-04\n",
            "Epoch 676/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1610206.7500 - mae: 710.3525 - mse: 1610206.7500 - val_loss: 14.0591 - val_mae: 0.9524 - val_mse: 14.0591 - learning_rate: 1.0000e-04\n",
            "Epoch 677/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1609704.7500 - mae: 710.2203 - mse: 1609704.7500 - val_loss: 14.0563 - val_mae: 0.9522 - val_mse: 14.0563 - learning_rate: 1.0000e-04\n",
            "Epoch 678/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1609213.0000 - mae: 710.0932 - mse: 1609213.0000 - val_loss: 14.0535 - val_mae: 0.9520 - val_mse: 14.0535 - learning_rate: 1.0000e-04\n",
            "Epoch 679/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1608696.2500 - mae: 709.9641 - mse: 1608696.2500 - val_loss: 14.0506 - val_mae: 0.9518 - val_mse: 14.0506 - learning_rate: 1.0000e-04\n",
            "Epoch 680/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1608169.6250 - mae: 709.8347 - mse: 1608169.6250 - val_loss: 14.0477 - val_mae: 0.9516 - val_mse: 14.0477 - learning_rate: 1.0000e-04\n",
            "Epoch 681/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1607645.1250 - mae: 709.7090 - mse: 1607645.1250 - val_loss: 14.0447 - val_mae: 0.9514 - val_mse: 14.0447 - learning_rate: 1.0000e-04\n",
            "Epoch 682/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1607100.0000 - mae: 709.5737 - mse: 1607100.0000 - val_loss: 14.0417 - val_mae: 0.9512 - val_mse: 14.0417 - learning_rate: 1.0000e-04\n",
            "Epoch 683/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1606578.2500 - mae: 709.4495 - mse: 1606578.2500 - val_loss: 14.0389 - val_mae: 0.9510 - val_mse: 14.0389 - learning_rate: 1.0000e-04\n",
            "Epoch 684/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1606069.2500 - mae: 709.3311 - mse: 1606069.2500 - val_loss: 14.0362 - val_mae: 0.9507 - val_mse: 14.0362 - learning_rate: 1.0000e-04\n",
            "Epoch 685/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1605592.1250 - mae: 709.2188 - mse: 1605592.1250 - val_loss: 14.0334 - val_mae: 0.9506 - val_mse: 14.0334 - learning_rate: 1.0000e-04\n",
            "Epoch 686/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1605109.7500 - mae: 709.1095 - mse: 1605109.7500 - val_loss: 14.0306 - val_mae: 0.9503 - val_mse: 14.0306 - learning_rate: 1.0000e-04\n",
            "Epoch 687/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1604625.2500 - mae: 709.0005 - mse: 1604625.2500 - val_loss: 14.0279 - val_mae: 0.9501 - val_mse: 14.0279 - learning_rate: 1.0000e-04\n",
            "Epoch 688/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1604149.7500 - mae: 708.8944 - mse: 1604149.7500 - val_loss: 14.0250 - val_mae: 0.9499 - val_mse: 14.0250 - learning_rate: 1.0000e-04\n",
            "Epoch 689/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1603667.0000 - mae: 708.7864 - mse: 1603667.0000 - val_loss: 14.0223 - val_mae: 0.9498 - val_mse: 14.0223 - learning_rate: 1.0000e-04\n",
            "Epoch 690/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1603217.5000 - mae: 708.6840 - mse: 1603217.5000 - val_loss: 14.0197 - val_mae: 0.9496 - val_mse: 14.0197 - learning_rate: 1.0000e-04\n",
            "Epoch 691/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1602791.3750 - mae: 708.5851 - mse: 1602791.3750 - val_loss: 14.0172 - val_mae: 0.9494 - val_mse: 14.0172 - learning_rate: 1.0000e-04\n",
            "Epoch 692/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1602372.1250 - mae: 708.4849 - mse: 1602372.1250 - val_loss: 14.0148 - val_mae: 0.9492 - val_mse: 14.0148 - learning_rate: 1.0000e-04\n",
            "Epoch 693/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1601956.6250 - mae: 708.3841 - mse: 1601956.6250 - val_loss: 14.0123 - val_mae: 0.9490 - val_mse: 14.0123 - learning_rate: 1.0000e-04\n",
            "Epoch 694/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1601573.2500 - mae: 708.2941 - mse: 1601573.2500 - val_loss: 14.0100 - val_mae: 0.9490 - val_mse: 14.0100 - learning_rate: 1.0000e-04\n",
            "Epoch 695/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1601203.7500 - mae: 708.2086 - mse: 1601203.7500 - val_loss: 14.0077 - val_mae: 0.9488 - val_mse: 14.0077 - learning_rate: 1.0000e-04\n",
            "Epoch 696/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1600840.7500 - mae: 708.1199 - mse: 1600840.7500 - val_loss: 14.0055 - val_mae: 0.9487 - val_mse: 14.0055 - learning_rate: 1.0000e-04\n",
            "Epoch 697/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1600476.8750 - mae: 708.0325 - mse: 1600476.8750 - val_loss: 14.0033 - val_mae: 0.9486 - val_mse: 14.0033 - learning_rate: 1.0000e-04\n",
            "Epoch 698/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1600114.0000 - mae: 707.9503 - mse: 1600114.0000 - val_loss: 14.0011 - val_mae: 0.9484 - val_mse: 14.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 699/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1599752.0000 - mae: 707.8644 - mse: 1599752.0000 - val_loss: 13.9990 - val_mae: 0.9482 - val_mse: 13.9990 - learning_rate: 1.0000e-04\n",
            "Epoch 700/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1599402.1250 - mae: 707.7780 - mse: 1599402.1250 - val_loss: 13.9968 - val_mae: 0.9481 - val_mse: 13.9968 - learning_rate: 1.0000e-04\n",
            "Epoch 701/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1599037.1250 - mae: 707.6881 - mse: 1599037.1250 - val_loss: 13.9947 - val_mae: 0.9481 - val_mse: 13.9947 - learning_rate: 1.0000e-04\n",
            "Epoch 702/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1598731.7500 - mae: 707.6107 - mse: 1598731.7500 - val_loss: 13.9928 - val_mae: 0.9480 - val_mse: 13.9928 - learning_rate: 1.0000e-04\n",
            "Epoch 703/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1598440.6250 - mae: 707.5392 - mse: 1598440.6250 - val_loss: 13.9908 - val_mae: 0.9478 - val_mse: 13.9908 - learning_rate: 1.0000e-04\n",
            "Epoch 704/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1598117.7500 - mae: 707.4592 - mse: 1598117.7500 - val_loss: 13.9888 - val_mae: 0.9477 - val_mse: 13.9888 - learning_rate: 1.0000e-04\n",
            "Epoch 705/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1597811.3750 - mae: 707.3763 - mse: 1597811.3750 - val_loss: 13.9868 - val_mae: 0.9476 - val_mse: 13.9868 - learning_rate: 1.0000e-04\n",
            "Epoch 706/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1597492.8750 - mae: 707.2944 - mse: 1597492.8750 - val_loss: 13.9848 - val_mae: 0.9475 - val_mse: 13.9848 - learning_rate: 1.0000e-04\n",
            "Epoch 707/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1597186.6250 - mae: 707.2178 - mse: 1597186.6250 - val_loss: 13.9829 - val_mae: 0.9475 - val_mse: 13.9829 - learning_rate: 1.0000e-04\n",
            "Epoch 708/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1596912.1250 - mae: 707.1438 - mse: 1596912.1250 - val_loss: 13.9811 - val_mae: 0.9473 - val_mse: 13.9811 - learning_rate: 1.0000e-04\n",
            "Epoch 709/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1596667.2500 - mae: 707.0750 - mse: 1596667.2500 - val_loss: 13.9794 - val_mae: 0.9472 - val_mse: 13.9794 - learning_rate: 1.0000e-04\n",
            "Epoch 710/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1596472.8750 - mae: 707.0201 - mse: 1596472.8750 - val_loss: 13.9778 - val_mae: 0.9471 - val_mse: 13.9778 - learning_rate: 1.0000e-04\n",
            "Epoch 711/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1596282.1250 - mae: 706.9634 - mse: 1596282.1250 - val_loss: 13.9762 - val_mae: 0.9470 - val_mse: 13.9762 - learning_rate: 1.0000e-04\n",
            "Epoch 712/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1596105.2500 - mae: 706.9073 - mse: 1596105.2500 - val_loss: 13.9747 - val_mae: 0.9469 - val_mse: 13.9747 - learning_rate: 1.0000e-04\n",
            "Epoch 713/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1595919.3750 - mae: 706.8554 - mse: 1595919.3750 - val_loss: 13.9731 - val_mae: 0.9469 - val_mse: 13.9731 - learning_rate: 1.0000e-04\n",
            "Epoch 714/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1595736.2500 - mae: 706.8076 - mse: 1595736.2500 - val_loss: 13.9715 - val_mae: 0.9468 - val_mse: 13.9715 - learning_rate: 1.0000e-04\n",
            "Epoch 715/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1595544.1250 - mae: 706.7515 - mse: 1595544.1250 - val_loss: 13.9699 - val_mae: 0.9467 - val_mse: 13.9699 - learning_rate: 1.0000e-04\n",
            "Epoch 716/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1595319.6250 - mae: 706.6853 - mse: 1595319.6250 - val_loss: 13.9684 - val_mae: 0.9465 - val_mse: 13.9684 - learning_rate: 1.0000e-04\n",
            "Epoch 717/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1595080.0000 - mae: 706.6188 - mse: 1595080.0000 - val_loss: 13.9668 - val_mae: 0.9464 - val_mse: 13.9668 - learning_rate: 1.0000e-04\n",
            "Epoch 718/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1594818.5000 - mae: 706.5546 - mse: 1594818.5000 - val_loss: 13.9650 - val_mae: 0.9463 - val_mse: 13.9650 - learning_rate: 1.0000e-04\n",
            "Epoch 719/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1594571.0000 - mae: 706.4948 - mse: 1594571.0000 - val_loss: 13.9635 - val_mae: 0.9462 - val_mse: 13.9635 - learning_rate: 1.0000e-04\n",
            "Epoch 720/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1594323.7500 - mae: 706.4327 - mse: 1594323.7500 - val_loss: 13.9619 - val_mae: 0.9461 - val_mse: 13.9619 - learning_rate: 1.0000e-04\n",
            "Epoch 721/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1593997.0000 - mae: 706.3645 - mse: 1593997.0000 - val_loss: 13.9601 - val_mae: 0.9459 - val_mse: 13.9601 - learning_rate: 1.0000e-04\n",
            "Epoch 722/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1593669.2500 - mae: 706.2980 - mse: 1593669.2500 - val_loss: 13.9584 - val_mae: 0.9458 - val_mse: 13.9584 - learning_rate: 1.0000e-04\n",
            "Epoch 723/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1593313.6250 - mae: 706.2234 - mse: 1593313.6250 - val_loss: 13.9567 - val_mae: 0.9456 - val_mse: 13.9567 - learning_rate: 1.0000e-04\n",
            "Epoch 724/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1592975.2500 - mae: 706.1450 - mse: 1592975.2500 - val_loss: 13.9550 - val_mae: 0.9454 - val_mse: 13.9550 - learning_rate: 1.0000e-04\n",
            "Epoch 725/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1592643.2500 - mae: 706.0704 - mse: 1592643.2500 - val_loss: 13.9533 - val_mae: 0.9454 - val_mse: 13.9533 - learning_rate: 1.0000e-04\n",
            "Epoch 726/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1592323.2500 - mae: 705.9958 - mse: 1592323.2500 - val_loss: 13.9516 - val_mae: 0.9453 - val_mse: 13.9516 - learning_rate: 1.0000e-04\n",
            "Epoch 727/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1592014.8750 - mae: 705.9199 - mse: 1592014.8750 - val_loss: 13.9500 - val_mae: 0.9451 - val_mse: 13.9500 - learning_rate: 1.0000e-04\n",
            "Epoch 728/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1591710.8750 - mae: 705.8403 - mse: 1591710.8750 - val_loss: 13.9486 - val_mae: 0.9449 - val_mse: 13.9486 - learning_rate: 1.0000e-04\n",
            "Epoch 729/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1591421.6250 - mae: 705.7643 - mse: 1591421.6250 - val_loss: 13.9471 - val_mae: 0.9448 - val_mse: 13.9471 - learning_rate: 1.0000e-04\n",
            "Epoch 730/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1591099.5000 - mae: 705.6841 - mse: 1591099.5000 - val_loss: 13.9454 - val_mae: 0.9448 - val_mse: 13.9454 - learning_rate: 1.0000e-04\n",
            "Epoch 731/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1590782.6250 - mae: 705.6019 - mse: 1590782.6250 - val_loss: 13.9439 - val_mae: 0.9447 - val_mse: 13.9439 - learning_rate: 1.0000e-04\n",
            "Epoch 732/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1590488.3750 - mae: 705.5194 - mse: 1590488.3750 - val_loss: 13.9424 - val_mae: 0.9445 - val_mse: 13.9424 - learning_rate: 1.0000e-04\n",
            "Epoch 733/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1590175.5000 - mae: 705.4384 - mse: 1590175.5000 - val_loss: 13.9408 - val_mae: 0.9444 - val_mse: 13.9408 - learning_rate: 1.0000e-04\n",
            "Epoch 734/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1589840.7500 - mae: 705.3715 - mse: 1589840.7500 - val_loss: 13.9393 - val_mae: 0.9443 - val_mse: 13.9393 - learning_rate: 1.0000e-04\n",
            "Epoch 735/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1589473.6250 - mae: 705.3047 - mse: 1589473.6250 - val_loss: 13.9379 - val_mae: 0.9442 - val_mse: 13.9379 - learning_rate: 1.0000e-04\n",
            "Epoch 736/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1589083.5000 - mae: 705.2292 - mse: 1589083.5000 - val_loss: 13.9364 - val_mae: 0.9440 - val_mse: 13.9364 - learning_rate: 1.0000e-04\n",
            "Epoch 737/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1588642.3750 - mae: 705.1486 - mse: 1588642.3750 - val_loss: 13.9348 - val_mae: 0.9439 - val_mse: 13.9348 - learning_rate: 1.0000e-04\n",
            "Epoch 738/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1588183.2500 - mae: 705.0682 - mse: 1588183.2500 - val_loss: 13.9331 - val_mae: 0.9439 - val_mse: 13.9331 - learning_rate: 1.0000e-04\n",
            "Epoch 739/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1587757.1250 - mae: 704.9896 - mse: 1587757.1250 - val_loss: 13.9316 - val_mae: 0.9438 - val_mse: 13.9316 - learning_rate: 1.0000e-04\n",
            "Epoch 740/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1587306.6250 - mae: 704.9031 - mse: 1587306.6250 - val_loss: 13.9302 - val_mae: 0.9437 - val_mse: 13.9302 - learning_rate: 1.0000e-04\n",
            "Epoch 741/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1586822.3750 - mae: 704.8064 - mse: 1586822.3750 - val_loss: 13.9288 - val_mae: 0.9435 - val_mse: 13.9288 - learning_rate: 1.0000e-04\n",
            "Epoch 742/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1586360.7500 - mae: 704.7178 - mse: 1586360.7500 - val_loss: 13.9273 - val_mae: 0.9434 - val_mse: 13.9273 - learning_rate: 1.0000e-04\n",
            "Epoch 743/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1585886.1250 - mae: 704.6406 - mse: 1585886.1250 - val_loss: 13.9256 - val_mae: 0.9433 - val_mse: 13.9256 - learning_rate: 1.0000e-04\n",
            "Epoch 744/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1585414.7500 - mae: 704.5722 - mse: 1585414.7500 - val_loss: 13.9242 - val_mae: 0.9432 - val_mse: 13.9242 - learning_rate: 1.0000e-04\n",
            "Epoch 745/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1584969.2500 - mae: 704.5057 - mse: 1584969.2500 - val_loss: 13.9228 - val_mae: 0.9430 - val_mse: 13.9228 - learning_rate: 1.0000e-04\n",
            "Epoch 746/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1584536.0000 - mae: 704.4421 - mse: 1584536.0000 - val_loss: 13.9215 - val_mae: 0.9428 - val_mse: 13.9215 - learning_rate: 1.0000e-04\n",
            "Epoch 747/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1584101.6250 - mae: 704.3770 - mse: 1584101.6250 - val_loss: 13.9202 - val_mae: 0.9427 - val_mse: 13.9202 - learning_rate: 1.0000e-04\n",
            "Epoch 748/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1583658.6250 - mae: 704.3134 - mse: 1583658.6250 - val_loss: 13.9188 - val_mae: 0.9426 - val_mse: 13.9188 - learning_rate: 1.0000e-04\n",
            "Epoch 749/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1583235.7500 - mae: 704.2646 - mse: 1583235.7500 - val_loss: 13.9176 - val_mae: 0.9425 - val_mse: 13.9176 - learning_rate: 1.0000e-04\n",
            "Epoch 750/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1582734.7500 - mae: 704.1984 - mse: 1582734.7500 - val_loss: 13.9164 - val_mae: 0.9423 - val_mse: 13.9164 - learning_rate: 1.0000e-04\n",
            "Epoch 751/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1582239.3750 - mae: 704.1368 - mse: 1582239.3750 - val_loss: 13.9152 - val_mae: 0.9421 - val_mse: 13.9152 - learning_rate: 1.0000e-04\n",
            "Epoch 752/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1581763.3750 - mae: 704.0789 - mse: 1581763.3750 - val_loss: 13.9140 - val_mae: 0.9420 - val_mse: 13.9140 - learning_rate: 1.0000e-04\n",
            "Epoch 753/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1581295.6250 - mae: 704.0233 - mse: 1581295.6250 - val_loss: 13.9127 - val_mae: 0.9419 - val_mse: 13.9127 - learning_rate: 1.0000e-04\n",
            "Epoch 754/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1580890.1250 - mae: 703.9818 - mse: 1580890.1250 - val_loss: 13.9115 - val_mae: 0.9418 - val_mse: 13.9115 - learning_rate: 1.0000e-04\n",
            "Epoch 755/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1580527.0000 - mae: 703.9413 - mse: 1580527.0000 - val_loss: 13.9105 - val_mae: 0.9416 - val_mse: 13.9105 - learning_rate: 1.0000e-04\n",
            "Epoch 756/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1580204.0000 - mae: 703.9052 - mse: 1580204.0000 - val_loss: 13.9096 - val_mae: 0.9414 - val_mse: 13.9096 - learning_rate: 1.0000e-04\n",
            "Epoch 757/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1579912.8750 - mae: 703.8806 - mse: 1579912.8750 - val_loss: 13.9086 - val_mae: 0.9413 - val_mse: 13.9086 - learning_rate: 1.0000e-04\n",
            "Epoch 758/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1579645.7500 - mae: 703.8616 - mse: 1579645.7500 - val_loss: 13.9077 - val_mae: 0.9412 - val_mse: 13.9077 - learning_rate: 1.0000e-04\n",
            "Epoch 759/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1579406.2500 - mae: 703.8447 - mse: 1579406.2500 - val_loss: 13.9068 - val_mae: 0.9410 - val_mse: 13.9068 - learning_rate: 1.0000e-04\n",
            "Epoch 760/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1579193.6250 - mae: 703.8281 - mse: 1579193.6250 - val_loss: 13.9058 - val_mae: 0.9409 - val_mse: 13.9058 - learning_rate: 1.0000e-04\n",
            "Epoch 761/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1578986.8750 - mae: 703.8134 - mse: 1578986.8750 - val_loss: 13.9047 - val_mae: 0.9409 - val_mse: 13.9047 - learning_rate: 1.0000e-04\n",
            "Epoch 762/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1578795.6250 - mae: 703.8096 - mse: 1578795.6250 - val_loss: 13.9038 - val_mae: 0.9408 - val_mse: 13.9038 - learning_rate: 1.0000e-04\n",
            "Epoch 763/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1578593.8750 - mae: 703.7956 - mse: 1578593.8750 - val_loss: 13.9030 - val_mae: 0.9406 - val_mse: 13.9030 - learning_rate: 1.0000e-04\n",
            "Epoch 764/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1578411.0000 - mae: 703.7744 - mse: 1578411.0000 - val_loss: 13.9024 - val_mae: 0.9404 - val_mse: 13.9024 - learning_rate: 1.0000e-04\n",
            "Epoch 765/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1578246.2500 - mae: 703.7501 - mse: 1578246.2500 - val_loss: 13.9017 - val_mae: 0.9404 - val_mse: 13.9017 - learning_rate: 1.0000e-04\n",
            "Epoch 766/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1578088.2500 - mae: 703.7311 - mse: 1578088.2500 - val_loss: 13.9010 - val_mae: 0.9403 - val_mse: 13.9010 - learning_rate: 1.0000e-04\n",
            "Epoch 767/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1577941.3750 - mae: 703.7148 - mse: 1577941.3750 - val_loss: 13.9001 - val_mae: 0.9402 - val_mse: 13.9001 - learning_rate: 1.0000e-04\n",
            "Epoch 768/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1577809.3750 - mae: 703.7001 - mse: 1577809.3750 - val_loss: 13.8994 - val_mae: 0.9401 - val_mse: 13.8994 - learning_rate: 1.0000e-04\n",
            "Epoch 769/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1577686.6250 - mae: 703.6841 - mse: 1577686.6250 - val_loss: 13.8989 - val_mae: 0.9400 - val_mse: 13.8989 - learning_rate: 1.0000e-04\n",
            "Epoch 770/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1577577.5000 - mae: 703.6678 - mse: 1577577.5000 - val_loss: 13.8982 - val_mae: 0.9400 - val_mse: 13.8982 - learning_rate: 1.0000e-04\n",
            "Epoch 771/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1577458.2500 - mae: 703.6532 - mse: 1577458.2500 - val_loss: 13.8975 - val_mae: 0.9399 - val_mse: 13.8975 - learning_rate: 1.0000e-04\n",
            "Epoch 772/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1577337.7500 - mae: 703.6368 - mse: 1577337.7500 - val_loss: 13.8970 - val_mae: 0.9398 - val_mse: 13.8970 - learning_rate: 1.0000e-04\n",
            "Epoch 773/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1577216.7500 - mae: 703.6176 - mse: 1577216.7500 - val_loss: 13.8963 - val_mae: 0.9398 - val_mse: 13.8963 - learning_rate: 1.0000e-04\n",
            "Epoch 774/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1577093.7500 - mae: 703.5974 - mse: 1577093.7500 - val_loss: 13.8955 - val_mae: 0.9397 - val_mse: 13.8955 - learning_rate: 1.0000e-04\n",
            "Epoch 775/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1576963.3750 - mae: 703.5792 - mse: 1576963.3750 - val_loss: 13.8948 - val_mae: 0.9397 - val_mse: 13.8948 - learning_rate: 1.0000e-04\n",
            "Epoch 776/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1576831.0000 - mae: 703.5565 - mse: 1576831.0000 - val_loss: 13.8944 - val_mae: 0.9395 - val_mse: 13.8944 - learning_rate: 1.0000e-04\n",
            "Epoch 777/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1576699.3750 - mae: 703.5308 - mse: 1576699.3750 - val_loss: 13.8936 - val_mae: 0.9395 - val_mse: 13.8936 - learning_rate: 1.0000e-04\n",
            "Epoch 778/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1576560.0000 - mae: 703.5095 - mse: 1576560.0000 - val_loss: 13.8932 - val_mae: 0.9394 - val_mse: 13.8932 - learning_rate: 1.0000e-04\n",
            "Epoch 779/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1576416.7500 - mae: 703.4871 - mse: 1576416.7500 - val_loss: 13.8928 - val_mae: 0.9392 - val_mse: 13.8928 - learning_rate: 1.0000e-04\n",
            "Epoch 780/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1576273.7500 - mae: 703.4624 - mse: 1576273.7500 - val_loss: 13.8921 - val_mae: 0.9391 - val_mse: 13.8921 - learning_rate: 1.0000e-04\n",
            "Epoch 781/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1576039.5000 - mae: 703.4402 - mse: 1576039.5000 - val_loss: 13.8909 - val_mae: 0.9390 - val_mse: 13.8909 - learning_rate: 1.0000e-04\n",
            "Epoch 782/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1575788.0000 - mae: 703.4139 - mse: 1575788.0000 - val_loss: 13.8900 - val_mae: 0.9389 - val_mse: 13.8900 - learning_rate: 1.0000e-04\n",
            "Epoch 783/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1575517.6250 - mae: 703.3756 - mse: 1575517.6250 - val_loss: 13.8891 - val_mae: 0.9387 - val_mse: 13.8891 - learning_rate: 1.0000e-04\n",
            "Epoch 784/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1575243.6250 - mae: 703.3349 - mse: 1575243.6250 - val_loss: 13.8882 - val_mae: 0.9385 - val_mse: 13.8882 - learning_rate: 1.0000e-04\n",
            "Epoch 785/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1574975.5000 - mae: 703.2856 - mse: 1574975.5000 - val_loss: 13.8875 - val_mae: 0.9383 - val_mse: 13.8875 - learning_rate: 1.0000e-04\n",
            "Epoch 786/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1574696.2500 - mae: 703.2413 - mse: 1574696.2500 - val_loss: 13.8868 - val_mae: 0.9381 - val_mse: 13.8868 - learning_rate: 1.0000e-04\n",
            "Epoch 787/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1574436.1250 - mae: 703.1939 - mse: 1574436.1250 - val_loss: 13.8858 - val_mae: 0.9380 - val_mse: 13.8858 - learning_rate: 1.0000e-04\n",
            "Epoch 788/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1574183.3750 - mae: 703.1476 - mse: 1574183.3750 - val_loss: 13.8850 - val_mae: 0.9379 - val_mse: 13.8850 - learning_rate: 1.0000e-04\n",
            "Epoch 789/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1573927.5000 - mae: 703.1009 - mse: 1573927.5000 - val_loss: 13.8842 - val_mae: 0.9377 - val_mse: 13.8842 - learning_rate: 1.0000e-04\n",
            "Epoch 790/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1573676.6250 - mae: 703.0522 - mse: 1573676.6250 - val_loss: 13.8829 - val_mae: 0.9376 - val_mse: 13.8829 - learning_rate: 1.0000e-04\n",
            "Epoch 791/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1573417.7500 - mae: 703.0077 - mse: 1573417.7500 - val_loss: 13.8819 - val_mae: 0.9374 - val_mse: 13.8819 - learning_rate: 1.0000e-04\n",
            "Epoch 792/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1573131.1250 - mae: 702.9585 - mse: 1573131.1250 - val_loss: 13.8804 - val_mae: 0.9373 - val_mse: 13.8804 - learning_rate: 1.0000e-04\n",
            "Epoch 793/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1572825.3750 - mae: 702.9064 - mse: 1572825.3750 - val_loss: 13.8795 - val_mae: 0.9372 - val_mse: 13.8795 - learning_rate: 1.0000e-04\n",
            "Epoch 794/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1572516.0000 - mae: 702.8547 - mse: 1572516.0000 - val_loss: 13.8785 - val_mae: 0.9370 - val_mse: 13.8785 - learning_rate: 1.0000e-04\n",
            "Epoch 795/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1572223.3750 - mae: 702.8142 - mse: 1572223.3750 - val_loss: 13.8771 - val_mae: 0.9369 - val_mse: 13.8771 - learning_rate: 1.0000e-04\n",
            "Epoch 796/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1571939.1250 - mae: 702.7817 - mse: 1571939.1250 - val_loss: 13.8759 - val_mae: 0.9367 - val_mse: 13.8759 - learning_rate: 1.0000e-04\n",
            "Epoch 797/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1571672.2500 - mae: 702.7486 - mse: 1571672.2500 - val_loss: 13.8748 - val_mae: 0.9366 - val_mse: 13.8748 - learning_rate: 1.0000e-04\n",
            "Epoch 798/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1571413.6250 - mae: 702.7203 - mse: 1571413.6250 - val_loss: 13.8734 - val_mae: 0.9366 - val_mse: 13.8734 - learning_rate: 1.0000e-04\n",
            "Epoch 799/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1571163.6250 - mae: 702.6902 - mse: 1571163.6250 - val_loss: 13.8723 - val_mae: 0.9365 - val_mse: 13.8723 - learning_rate: 1.0000e-04\n",
            "Epoch 800/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1570907.2500 - mae: 702.6511 - mse: 1570907.2500 - val_loss: 13.8714 - val_mae: 0.9363 - val_mse: 13.8714 - learning_rate: 1.0000e-04\n",
            "Epoch 801/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1570629.5000 - mae: 702.6133 - mse: 1570629.5000 - val_loss: 13.8709 - val_mae: 0.9362 - val_mse: 13.8709 - learning_rate: 1.0000e-04\n",
            "Epoch 802/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1570320.5000 - mae: 702.5800 - mse: 1570320.5000 - val_loss: 13.8700 - val_mae: 0.9361 - val_mse: 13.8700 - learning_rate: 1.0000e-04\n",
            "Epoch 803/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1570005.6250 - mae: 702.5495 - mse: 1570005.6250 - val_loss: 13.8693 - val_mae: 0.9360 - val_mse: 13.8693 - learning_rate: 1.0000e-04\n",
            "Epoch 804/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1569709.5000 - mae: 702.5111 - mse: 1569709.5000 - val_loss: 13.8691 - val_mae: 0.9359 - val_mse: 13.8691 - learning_rate: 1.0000e-04\n",
            "Epoch 805/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1569418.8750 - mae: 702.4733 - mse: 1569418.8750 - val_loss: 13.8682 - val_mae: 0.9358 - val_mse: 13.8682 - learning_rate: 1.0000e-04\n",
            "Epoch 806/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1569096.2500 - mae: 702.4402 - mse: 1569096.2500 - val_loss: 13.8675 - val_mae: 0.9357 - val_mse: 13.8675 - learning_rate: 1.0000e-04\n",
            "Epoch 807/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1568759.1250 - mae: 702.3974 - mse: 1568759.1250 - val_loss: 13.8666 - val_mae: 0.9356 - val_mse: 13.8666 - learning_rate: 1.0000e-04\n",
            "Epoch 808/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1568424.7500 - mae: 702.3484 - mse: 1568424.7500 - val_loss: 13.8654 - val_mae: 0.9356 - val_mse: 13.8654 - learning_rate: 1.0000e-04\n",
            "Epoch 809/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1568099.2500 - mae: 702.3054 - mse: 1568099.2500 - val_loss: 13.8646 - val_mae: 0.9355 - val_mse: 13.8646 - learning_rate: 1.0000e-04\n",
            "Epoch 810/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1567742.2500 - mae: 702.2526 - mse: 1567742.2500 - val_loss: 13.8643 - val_mae: 0.9354 - val_mse: 13.8643 - learning_rate: 1.0000e-04\n",
            "Epoch 811/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1567404.1250 - mae: 702.2014 - mse: 1567404.1250 - val_loss: 13.8638 - val_mae: 0.9352 - val_mse: 13.8638 - learning_rate: 1.0000e-04\n",
            "Epoch 812/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1567083.8750 - mae: 702.1492 - mse: 1567083.8750 - val_loss: 13.8626 - val_mae: 0.9351 - val_mse: 13.8626 - learning_rate: 1.0000e-04\n",
            "Epoch 813/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1566738.2500 - mae: 702.0936 - mse: 1566738.2500 - val_loss: 13.8609 - val_mae: 0.9351 - val_mse: 13.8609 - learning_rate: 1.0000e-04\n",
            "Epoch 814/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1566382.5000 - mae: 702.0366 - mse: 1566382.5000 - val_loss: 13.8594 - val_mae: 0.9350 - val_mse: 13.8594 - learning_rate: 1.0000e-04\n",
            "Epoch 815/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1566006.8750 - mae: 701.9683 - mse: 1566006.8750 - val_loss: 13.8585 - val_mae: 0.9349 - val_mse: 13.8585 - learning_rate: 1.0000e-04\n",
            "Epoch 816/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1565621.7500 - mae: 701.8911 - mse: 1565621.7500 - val_loss: 13.8580 - val_mae: 0.9346 - val_mse: 13.8580 - learning_rate: 1.0000e-04\n",
            "Epoch 817/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1565262.0000 - mae: 701.8172 - mse: 1565262.0000 - val_loss: 13.8567 - val_mae: 0.9346 - val_mse: 13.8567 - learning_rate: 1.0000e-04\n",
            "Epoch 818/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1564941.6250 - mae: 701.7573 - mse: 1564941.6250 - val_loss: 13.8555 - val_mae: 0.9345 - val_mse: 13.8555 - learning_rate: 1.0000e-04\n",
            "Epoch 819/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1564677.2500 - mae: 701.7053 - mse: 1564677.2500 - val_loss: 13.8549 - val_mae: 0.9344 - val_mse: 13.8549 - learning_rate: 1.0000e-04\n",
            "Epoch 820/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1564449.1250 - mae: 701.6638 - mse: 1564449.1250 - val_loss: 13.8538 - val_mae: 0.9344 - val_mse: 13.8538 - learning_rate: 1.0000e-04\n",
            "Epoch 821/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1564234.2500 - mae: 701.6322 - mse: 1564234.2500 - val_loss: 13.8530 - val_mae: 0.9344 - val_mse: 13.8530 - learning_rate: 1.0000e-04\n",
            "Epoch 822/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1564024.2500 - mae: 701.5991 - mse: 1564024.2500 - val_loss: 13.8527 - val_mae: 0.9342 - val_mse: 13.8527 - learning_rate: 1.0000e-04\n",
            "Epoch 823/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1563817.5000 - mae: 701.5674 - mse: 1563817.5000 - val_loss: 13.8517 - val_mae: 0.9342 - val_mse: 13.8517 - learning_rate: 1.0000e-04\n",
            "Epoch 824/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1563608.8750 - mae: 701.5363 - mse: 1563608.8750 - val_loss: 13.8511 - val_mae: 0.9342 - val_mse: 13.8511 - learning_rate: 1.0000e-04\n",
            "Epoch 825/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1563403.3750 - mae: 701.4995 - mse: 1563403.3750 - val_loss: 13.8502 - val_mae: 0.9341 - val_mse: 13.8502 - learning_rate: 1.0000e-04\n",
            "Epoch 826/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1563192.8750 - mae: 701.4609 - mse: 1563192.8750 - val_loss: 13.8491 - val_mae: 0.9341 - val_mse: 13.8491 - learning_rate: 1.0000e-04\n",
            "Epoch 827/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1562994.7500 - mae: 701.4233 - mse: 1562994.7500 - val_loss: 13.8481 - val_mae: 0.9340 - val_mse: 13.8481 - learning_rate: 1.0000e-04\n",
            "Epoch 828/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1562790.5000 - mae: 701.3912 - mse: 1562790.5000 - val_loss: 13.8473 - val_mae: 0.9339 - val_mse: 13.8473 - learning_rate: 1.0000e-04\n",
            "Epoch 829/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1562588.3750 - mae: 701.3621 - mse: 1562588.3750 - val_loss: 13.8463 - val_mae: 0.9339 - val_mse: 13.8463 - learning_rate: 1.0000e-04\n",
            "Epoch 830/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1562393.2500 - mae: 701.3261 - mse: 1562393.2500 - val_loss: 13.8454 - val_mae: 0.9338 - val_mse: 13.8454 - learning_rate: 1.0000e-04\n",
            "Epoch 831/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1562200.5000 - mae: 701.2911 - mse: 1562200.5000 - val_loss: 13.8443 - val_mae: 0.9338 - val_mse: 13.8443 - learning_rate: 1.0000e-04\n",
            "Epoch 832/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1562013.8750 - mae: 701.2646 - mse: 1562013.8750 - val_loss: 13.8439 - val_mae: 0.9337 - val_mse: 13.8439 - learning_rate: 1.0000e-04\n",
            "Epoch 833/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1561849.5000 - mae: 701.2325 - mse: 1561849.5000 - val_loss: 13.8432 - val_mae: 0.9337 - val_mse: 13.8432 - learning_rate: 1.0000e-04\n",
            "Epoch 834/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1561686.1250 - mae: 701.2031 - mse: 1561686.1250 - val_loss: 13.8423 - val_mae: 0.9336 - val_mse: 13.8423 - learning_rate: 1.0000e-04\n",
            "Epoch 835/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1561541.1250 - mae: 701.1819 - mse: 1561541.1250 - val_loss: 13.8418 - val_mae: 0.9336 - val_mse: 13.8418 - learning_rate: 1.0000e-04\n",
            "Epoch 836/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1561410.0000 - mae: 701.1680 - mse: 1561410.0000 - val_loss: 13.8415 - val_mae: 0.9336 - val_mse: 13.8415 - learning_rate: 1.0000e-04\n",
            "Epoch 837/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1561284.5000 - mae: 701.1555 - mse: 1561284.5000 - val_loss: 13.8412 - val_mae: 0.9335 - val_mse: 13.8412 - learning_rate: 1.0000e-04\n",
            "Epoch 838/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1561163.0000 - mae: 701.1381 - mse: 1561163.0000 - val_loss: 13.8403 - val_mae: 0.9336 - val_mse: 13.8403 - learning_rate: 1.0000e-04\n",
            "Epoch 839/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1561034.7500 - mae: 701.1236 - mse: 1561034.7500 - val_loss: 13.8399 - val_mae: 0.9335 - val_mse: 13.8399 - learning_rate: 1.0000e-04\n",
            "Epoch 840/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1560910.5000 - mae: 701.1072 - mse: 1560910.5000 - val_loss: 13.8398 - val_mae: 0.9335 - val_mse: 13.8398 - learning_rate: 1.0000e-04\n",
            "Epoch 841/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1560790.2500 - mae: 701.0927 - mse: 1560790.2500 - val_loss: 13.8393 - val_mae: 0.9335 - val_mse: 13.8393 - learning_rate: 1.0000e-04\n",
            "Epoch 842/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1560670.6250 - mae: 701.0751 - mse: 1560670.6250 - val_loss: 13.8386 - val_mae: 0.9335 - val_mse: 13.8386 - learning_rate: 1.0000e-04\n",
            "Epoch 843/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1560558.3750 - mae: 701.0586 - mse: 1560558.3750 - val_loss: 13.8381 - val_mae: 0.9336 - val_mse: 13.8381 - learning_rate: 1.0000e-04\n",
            "Epoch 844/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1560442.7500 - mae: 701.0461 - mse: 1560442.7500 - val_loss: 13.8378 - val_mae: 0.9336 - val_mse: 13.8378 - learning_rate: 1.0000e-04\n",
            "Epoch 845/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1560328.1250 - mae: 701.0338 - mse: 1560328.1250 - val_loss: 13.8378 - val_mae: 0.9335 - val_mse: 13.8378 - learning_rate: 1.0000e-04\n",
            "Epoch 846/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1560228.5000 - mae: 701.0202 - mse: 1560228.5000 - val_loss: 13.8370 - val_mae: 0.9336 - val_mse: 13.8370 - learning_rate: 1.0000e-04\n",
            "Epoch 847/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1560119.7500 - mae: 701.0070 - mse: 1560119.7500 - val_loss: 13.8363 - val_mae: 0.9336 - val_mse: 13.8363 - learning_rate: 1.0000e-04\n",
            "Epoch 848/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1560016.7500 - mae: 700.9906 - mse: 1560016.7500 - val_loss: 13.8359 - val_mae: 0.9336 - val_mse: 13.8359 - learning_rate: 1.0000e-04\n",
            "Epoch 849/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559907.5000 - mae: 700.9753 - mse: 1559907.5000 - val_loss: 13.8357 - val_mae: 0.9336 - val_mse: 13.8357 - learning_rate: 1.0000e-04\n",
            "Epoch 850/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559795.5000 - mae: 700.9607 - mse: 1559795.5000 - val_loss: 13.8349 - val_mae: 0.9337 - val_mse: 13.8349 - learning_rate: 1.0000e-04\n",
            "Epoch 851/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559675.5000 - mae: 700.9432 - mse: 1559675.5000 - val_loss: 13.8341 - val_mae: 0.9339 - val_mse: 13.8341 - learning_rate: 1.0000e-04\n",
            "Epoch 852/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559546.7500 - mae: 700.9235 - mse: 1559546.7500 - val_loss: 13.8333 - val_mae: 0.9340 - val_mse: 13.8333 - learning_rate: 1.0000e-04\n",
            "Epoch 853/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1559410.2500 - mae: 700.9041 - mse: 1559410.2500 - val_loss: 13.8330 - val_mae: 0.9340 - val_mse: 13.8330 - learning_rate: 1.0000e-04\n",
            "Epoch 854/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559265.7500 - mae: 700.8842 - mse: 1559265.7500 - val_loss: 13.8330 - val_mae: 0.9340 - val_mse: 13.8330 - learning_rate: 1.0000e-04\n",
            "Epoch 855/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1559126.2500 - mae: 700.8553 - mse: 1559126.2500 - val_loss: 13.8328 - val_mae: 0.9341 - val_mse: 13.8328 - learning_rate: 1.0000e-04\n",
            "Epoch 856/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1558975.1250 - mae: 700.8289 - mse: 1558975.1250 - val_loss: 13.8325 - val_mae: 0.9341 - val_mse: 13.8325 - learning_rate: 1.0000e-04\n",
            "Epoch 857/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1558817.6250 - mae: 700.7986 - mse: 1558817.6250 - val_loss: 13.8317 - val_mae: 0.9342 - val_mse: 13.8317 - learning_rate: 1.0000e-04\n",
            "Epoch 858/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1558658.7500 - mae: 700.7690 - mse: 1558658.7500 - val_loss: 13.8315 - val_mae: 0.9343 - val_mse: 13.8315 - learning_rate: 1.0000e-04\n",
            "Epoch 859/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1558504.3750 - mae: 700.7316 - mse: 1558504.3750 - val_loss: 13.8314 - val_mae: 0.9343 - val_mse: 13.8314 - learning_rate: 1.0000e-04\n",
            "Epoch 860/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1558350.1250 - mae: 700.6946 - mse: 1558350.1250 - val_loss: 13.8312 - val_mae: 0.9344 - val_mse: 13.8312 - learning_rate: 1.0000e-04\n",
            "Epoch 861/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1558200.7500 - mae: 700.6707 - mse: 1558200.7500 - val_loss: 13.8313 - val_mae: 0.9344 - val_mse: 13.8313 - learning_rate: 1.0000e-04\n",
            "Epoch 862/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1558064.3750 - mae: 700.6443 - mse: 1558064.3750 - val_loss: 13.8311 - val_mae: 0.9344 - val_mse: 13.8311 - learning_rate: 1.0000e-04\n",
            "Epoch 863/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1557926.5000 - mae: 700.6201 - mse: 1557926.5000 - val_loss: 13.8302 - val_mae: 0.9345 - val_mse: 13.8302 - learning_rate: 1.0000e-04\n",
            "Epoch 864/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1557777.8750 - mae: 700.6006 - mse: 1557777.8750 - val_loss: 13.8300 - val_mae: 0.9345 - val_mse: 13.8300 - learning_rate: 1.0000e-04\n",
            "Epoch 865/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1557629.2500 - mae: 700.5743 - mse: 1557629.2500 - val_loss: 13.8300 - val_mae: 0.9344 - val_mse: 13.8300 - learning_rate: 1.0000e-04\n",
            "Epoch 866/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1557506.7500 - mae: 700.5417 - mse: 1557506.7500 - val_loss: 13.8293 - val_mae: 0.9344 - val_mse: 13.8293 - learning_rate: 1.0000e-04\n",
            "Epoch 867/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1557367.0000 - mae: 700.5143 - mse: 1557367.0000 - val_loss: 13.8283 - val_mae: 0.9344 - val_mse: 13.8283 - learning_rate: 1.0000e-04\n",
            "Epoch 868/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1557224.0000 - mae: 700.4874 - mse: 1557224.0000 - val_loss: 13.8274 - val_mae: 0.9344 - val_mse: 13.8274 - learning_rate: 1.0000e-04\n",
            "Epoch 869/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1557082.3750 - mae: 700.4672 - mse: 1557082.3750 - val_loss: 13.8270 - val_mae: 0.9344 - val_mse: 13.8270 - learning_rate: 1.0000e-04\n",
            "Epoch 870/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1556941.6250 - mae: 700.4362 - mse: 1556941.6250 - val_loss: 13.8274 - val_mae: 0.9342 - val_mse: 13.8274 - learning_rate: 1.0000e-04\n",
            "Epoch 871/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1556813.7500 - mae: 700.4020 - mse: 1556813.7500 - val_loss: 13.8269 - val_mae: 0.9342 - val_mse: 13.8269 - learning_rate: 1.0000e-04\n",
            "Epoch 872/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1556684.3750 - mae: 700.3721 - mse: 1556684.3750 - val_loss: 13.8256 - val_mae: 0.9342 - val_mse: 13.8256 - learning_rate: 1.0000e-04\n",
            "Epoch 873/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1556550.8750 - mae: 700.3427 - mse: 1556550.8750 - val_loss: 13.8249 - val_mae: 0.9341 - val_mse: 13.8249 - learning_rate: 1.0000e-04\n",
            "Epoch 874/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1556403.0000 - mae: 700.3162 - mse: 1556403.0000 - val_loss: 13.8242 - val_mae: 0.9340 - val_mse: 13.8242 - learning_rate: 1.0000e-04\n",
            "Epoch 875/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1556251.1250 - mae: 700.2925 - mse: 1556251.1250 - val_loss: 13.8238 - val_mae: 0.9339 - val_mse: 13.8238 - learning_rate: 1.0000e-04\n",
            "Epoch 876/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1556072.5000 - mae: 700.2529 - mse: 1556072.5000 - val_loss: 13.8236 - val_mae: 0.9337 - val_mse: 13.8236 - learning_rate: 1.0000e-04\n",
            "Epoch 877/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1555883.1250 - mae: 700.2043 - mse: 1555883.1250 - val_loss: 13.8219 - val_mae: 0.9337 - val_mse: 13.8219 - learning_rate: 1.0000e-04\n",
            "Epoch 878/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1555685.8750 - mae: 700.1536 - mse: 1555685.8750 - val_loss: 13.8203 - val_mae: 0.9337 - val_mse: 13.8203 - learning_rate: 1.0000e-04\n",
            "Epoch 879/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1555499.8750 - mae: 700.1113 - mse: 1555499.8750 - val_loss: 13.8199 - val_mae: 0.9336 - val_mse: 13.8199 - learning_rate: 1.0000e-04\n",
            "Epoch 880/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1555319.0000 - mae: 700.0700 - mse: 1555319.0000 - val_loss: 13.8199 - val_mae: 0.9335 - val_mse: 13.8199 - learning_rate: 1.0000e-04\n",
            "Epoch 881/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1555128.6250 - mae: 700.0262 - mse: 1555128.6250 - val_loss: 13.8196 - val_mae: 0.9333 - val_mse: 13.8196 - learning_rate: 1.0000e-04\n",
            "Epoch 882/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1554941.7500 - mae: 699.9819 - mse: 1554941.7500 - val_loss: 13.8189 - val_mae: 0.9332 - val_mse: 13.8189 - learning_rate: 1.0000e-04\n",
            "Epoch 883/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1554753.7500 - mae: 699.9453 - mse: 1554753.7500 - val_loss: 13.8174 - val_mae: 0.9332 - val_mse: 13.8174 - learning_rate: 1.0000e-04\n",
            "Epoch 884/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1554580.1250 - mae: 699.9088 - mse: 1554580.1250 - val_loss: 13.8167 - val_mae: 0.9331 - val_mse: 13.8167 - learning_rate: 1.0000e-04\n",
            "Epoch 885/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1554400.8750 - mae: 699.8665 - mse: 1554400.8750 - val_loss: 13.8167 - val_mae: 0.9330 - val_mse: 13.8167 - learning_rate: 1.0000e-04\n",
            "Epoch 886/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1554213.3750 - mae: 699.8203 - mse: 1554213.3750 - val_loss: 13.8168 - val_mae: 0.9328 - val_mse: 13.8168 - learning_rate: 1.0000e-04\n",
            "Epoch 887/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1554027.8750 - mae: 699.7748 - mse: 1554027.8750 - val_loss: 13.8165 - val_mae: 0.9327 - val_mse: 13.8165 - learning_rate: 1.0000e-04\n",
            "Epoch 888/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1553843.7500 - mae: 699.7351 - mse: 1553843.7500 - val_loss: 13.8155 - val_mae: 0.9327 - val_mse: 13.8155 - learning_rate: 1.0000e-04\n",
            "Epoch 889/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1553673.7500 - mae: 699.6992 - mse: 1553673.7500 - val_loss: 13.8143 - val_mae: 0.9326 - val_mse: 13.8143 - learning_rate: 1.0000e-04\n",
            "Epoch 890/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1553510.1250 - mae: 699.6587 - mse: 1553510.1250 - val_loss: 13.8145 - val_mae: 0.9325 - val_mse: 13.8145 - learning_rate: 1.0000e-04\n",
            "Epoch 891/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1553337.3750 - mae: 699.6118 - mse: 1553337.3750 - val_loss: 13.8148 - val_mae: 0.9323 - val_mse: 13.8148 - learning_rate: 1.0000e-04\n",
            "Epoch 892/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1553178.7500 - mae: 699.5712 - mse: 1553178.7500 - val_loss: 13.8142 - val_mae: 0.9322 - val_mse: 13.8142 - learning_rate: 1.0000e-04\n",
            "Epoch 893/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1553003.7500 - mae: 699.5345 - mse: 1553003.7500 - val_loss: 13.8131 - val_mae: 0.9323 - val_mse: 13.8131 - learning_rate: 1.0000e-04\n",
            "Epoch 894/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1552847.7500 - mae: 699.4988 - mse: 1552847.7500 - val_loss: 13.8132 - val_mae: 0.9323 - val_mse: 13.8132 - learning_rate: 1.0000e-04\n",
            "Epoch 895/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1552696.6250 - mae: 699.4600 - mse: 1552696.6250 - val_loss: 13.8136 - val_mae: 0.9321 - val_mse: 13.8136 - learning_rate: 1.0000e-04\n",
            "Epoch 896/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1552542.7500 - mae: 699.4235 - mse: 1552542.7500 - val_loss: 13.8135 - val_mae: 0.9320 - val_mse: 13.8135 - learning_rate: 1.0000e-04\n",
            "Epoch 897/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1552405.5000 - mae: 699.3904 - mse: 1552405.5000 - val_loss: 13.8132 - val_mae: 0.9320 - val_mse: 13.8132 - learning_rate: 1.0000e-04\n",
            "Epoch 898/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1552261.5000 - mae: 699.3652 - mse: 1552261.5000 - val_loss: 13.8123 - val_mae: 0.9320 - val_mse: 13.8123 - learning_rate: 1.0000e-04\n",
            "Epoch 899/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1552115.1250 - mae: 699.3381 - mse: 1552115.1250 - val_loss: 13.8126 - val_mae: 0.9320 - val_mse: 13.8126 - learning_rate: 1.0000e-04\n",
            "Epoch 900/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1551974.5000 - mae: 699.3054 - mse: 1551974.5000 - val_loss: 13.8133 - val_mae: 0.9319 - val_mse: 13.8133 - learning_rate: 1.0000e-04\n",
            "Epoch 901/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1551830.2500 - mae: 699.2670 - mse: 1551830.2500 - val_loss: 13.8142 - val_mae: 0.9318 - val_mse: 13.8142 - learning_rate: 1.0000e-04\n",
            "Epoch 902/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1551712.6250 - mae: 699.2269 - mse: 1551712.6250 - val_loss: 13.8139 - val_mae: 0.9319 - val_mse: 13.8139 - learning_rate: 1.0000e-04\n",
            "Epoch 903/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1551590.0000 - mae: 699.1997 - mse: 1551590.0000 - val_loss: 13.8134 - val_mae: 0.9320 - val_mse: 13.8134 - learning_rate: 1.0000e-04\n",
            "Epoch 904/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1551474.6250 - mae: 699.1893 - mse: 1551474.6250 - val_loss: 13.8132 - val_mae: 0.9320 - val_mse: 13.8132 - learning_rate: 1.0000e-04\n",
            "Epoch 905/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1551385.5000 - mae: 699.1840 - mse: 1551385.5000 - val_loss: 13.8135 - val_mae: 0.9319 - val_mse: 13.8135 - learning_rate: 1.0000e-04\n",
            "Epoch 906/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1551298.2500 - mae: 699.1719 - mse: 1551298.2500 - val_loss: 13.8147 - val_mae: 0.9318 - val_mse: 13.8147 - learning_rate: 1.0000e-04\n",
            "Epoch 907/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1551229.1250 - mae: 699.1565 - mse: 1551229.1250 - val_loss: 13.8147 - val_mae: 0.9319 - val_mse: 13.8147 - learning_rate: 1.0000e-04\n",
            "Epoch 908/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1551156.0000 - mae: 699.1432 - mse: 1551156.0000 - val_loss: 13.8148 - val_mae: 0.9319 - val_mse: 13.8148 - learning_rate: 1.0000e-04\n",
            "Epoch 909/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1551085.0000 - mae: 699.1343 - mse: 1551085.0000 - val_loss: 13.8159 - val_mae: 0.9319 - val_mse: 13.8159 - learning_rate: 1.0000e-04\n",
            "Epoch 910/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1551024.3750 - mae: 699.1235 - mse: 1551024.3750 - val_loss: 13.8154 - val_mae: 0.9320 - val_mse: 13.8154 - learning_rate: 1.0000e-04\n",
            "Epoch 911/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1550952.0000 - mae: 699.1235 - mse: 1550952.0000 - val_loss: 13.8151 - val_mae: 0.9320 - val_mse: 13.8151 - learning_rate: 1.0000e-04\n",
            "Epoch 912/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1550874.0000 - mae: 699.1154 - mse: 1550874.0000 - val_loss: 13.8153 - val_mae: 0.9320 - val_mse: 13.8153 - learning_rate: 1.0000e-04\n",
            "Epoch 913/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1550813.0000 - mae: 699.0997 - mse: 1550813.0000 - val_loss: 13.8152 - val_mae: 0.9321 - val_mse: 13.8152 - learning_rate: 1.0000e-04\n",
            "Epoch 914/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1550745.7500 - mae: 699.0851 - mse: 1550745.7500 - val_loss: 13.8153 - val_mae: 0.9322 - val_mse: 13.8153 - learning_rate: 1.0000e-04\n",
            "Epoch 915/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1550687.6250 - mae: 699.0793 - mse: 1550687.6250 - val_loss: 13.8161 - val_mae: 0.9321 - val_mse: 13.8161 - learning_rate: 1.0000e-04\n",
            "Epoch 916/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1550616.5000 - mae: 699.0806 - mse: 1550616.5000 - val_loss: 13.8168 - val_mae: 0.9321 - val_mse: 13.8168 - learning_rate: 1.0000e-04\n",
            "Epoch 917/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1550546.0000 - mae: 699.0771 - mse: 1550546.0000 - val_loss: 13.8165 - val_mae: 0.9321 - val_mse: 13.8165 - learning_rate: 1.0000e-04\n",
            "Epoch 918/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1550485.5000 - mae: 699.0609 - mse: 1550485.5000 - val_loss: 13.8160 - val_mae: 0.9322 - val_mse: 13.8160 - learning_rate: 1.0000e-04\n",
            "Epoch 919/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1550424.5000 - mae: 699.0369 - mse: 1550424.5000 - val_loss: 13.8154 - val_mae: 0.9323 - val_mse: 13.8154 - learning_rate: 1.0000e-04\n",
            "Epoch 920/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1550364.6250 - mae: 699.0262 - mse: 1550364.6250 - val_loss: 13.8154 - val_mae: 0.9323 - val_mse: 13.8154 - learning_rate: 1.0000e-04\n",
            "Epoch 921/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1550305.2500 - mae: 699.0313 - mse: 1550305.2500 - val_loss: 13.8155 - val_mae: 0.9323 - val_mse: 13.8155 - learning_rate: 1.0000e-04\n",
            "Epoch 922/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1550239.2500 - mae: 699.0374 - mse: 1550239.2500 - val_loss: 13.8163 - val_mae: 0.9323 - val_mse: 13.8163 - learning_rate: 1.0000e-04\n",
            "Epoch 923/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1550182.0000 - mae: 699.0279 - mse: 1550182.0000 - val_loss: 13.8164 - val_mae: 0.9324 - val_mse: 13.8164 - learning_rate: 1.0000e-04\n",
            "Epoch 924/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1550129.1250 - mae: 699.0115 - mse: 1550129.1250 - val_loss: 13.8170 - val_mae: 0.9325 - val_mse: 13.8170 - learning_rate: 1.0000e-04\n",
            "Epoch 925/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1550080.8750 - mae: 699.0007 - mse: 1550080.8750 - val_loss: 13.8177 - val_mae: 0.9324 - val_mse: 13.8177 - learning_rate: 1.0000e-04\n",
            "Epoch 926/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1550040.5000 - mae: 699.0025 - mse: 1550040.5000 - val_loss: 13.8174 - val_mae: 0.9324 - val_mse: 13.8174 - learning_rate: 1.0000e-04\n",
            "Epoch 927/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1549975.7500 - mae: 699.0146 - mse: 1549975.7500 - val_loss: 13.8173 - val_mae: 0.9325 - val_mse: 13.8173 - learning_rate: 1.0000e-04\n",
            "Epoch 928/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549927.1250 - mae: 699.0098 - mse: 1549927.1250 - val_loss: 13.8170 - val_mae: 0.9326 - val_mse: 13.8170 - learning_rate: 1.0000e-04\n",
            "Epoch 929/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1549880.5000 - mae: 698.9985 - mse: 1549880.5000 - val_loss: 13.8164 - val_mae: 0.9326 - val_mse: 13.8164 - learning_rate: 1.0000e-04\n",
            "Epoch 930/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549838.8750 - mae: 698.9969 - mse: 1549838.8750 - val_loss: 13.8153 - val_mae: 0.9326 - val_mse: 13.8153 - learning_rate: 1.0000e-04\n",
            "Epoch 931/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1549794.0000 - mae: 699.0090 - mse: 1549794.0000 - val_loss: 13.8145 - val_mae: 0.9321 - val_mse: 13.8145 - learning_rate: 1.0000e-04\n",
            "Epoch 932/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1549741.8750 - mae: 699.0057 - mse: 1549741.8750 - val_loss: 13.8151 - val_mae: 0.9318 - val_mse: 13.8151 - learning_rate: 1.0000e-04\n",
            "Epoch 933/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1549703.3750 - mae: 698.9927 - mse: 1549703.3750 - val_loss: 13.8148 - val_mae: 0.9318 - val_mse: 13.8148 - learning_rate: 1.0000e-04\n",
            "Epoch 934/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549665.1250 - mae: 698.9921 - mse: 1549665.1250 - val_loss: 13.8148 - val_mae: 0.9317 - val_mse: 13.8148 - learning_rate: 1.0000e-04\n",
            "Epoch 935/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1549616.7500 - mae: 698.9922 - mse: 1549616.7500 - val_loss: 13.8155 - val_mae: 0.9317 - val_mse: 13.8155 - learning_rate: 1.0000e-04\n",
            "Epoch 936/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1549577.0000 - mae: 698.9943 - mse: 1549577.0000 - val_loss: 13.8154 - val_mae: 0.9318 - val_mse: 13.8154 - learning_rate: 1.0000e-04\n",
            "Epoch 937/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1549521.5000 - mae: 698.9961 - mse: 1549521.5000 - val_loss: 13.8153 - val_mae: 0.9320 - val_mse: 13.8153 - learning_rate: 1.0000e-04\n",
            "Epoch 938/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1549475.7500 - mae: 698.9946 - mse: 1549475.7500 - val_loss: 13.8159 - val_mae: 0.9321 - val_mse: 13.8159 - learning_rate: 1.0000e-04\n",
            "Epoch 939/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1549429.0000 - mae: 698.9914 - mse: 1549429.0000 - val_loss: 13.8163 - val_mae: 0.9321 - val_mse: 13.8163 - learning_rate: 1.0000e-04\n",
            "Epoch 940/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549373.5000 - mae: 698.9902 - mse: 1549373.5000 - val_loss: 13.8162 - val_mae: 0.9323 - val_mse: 13.8162 - learning_rate: 1.0000e-04\n",
            "Epoch 941/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1549324.0000 - mae: 698.9758 - mse: 1549324.0000 - val_loss: 13.8162 - val_mae: 0.9324 - val_mse: 13.8162 - learning_rate: 1.0000e-04\n",
            "Epoch 942/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1549276.6250 - mae: 698.9626 - mse: 1549276.6250 - val_loss: 13.8164 - val_mae: 0.9325 - val_mse: 13.8164 - learning_rate: 1.0000e-04\n",
            "Epoch 943/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1549223.1250 - mae: 698.9596 - mse: 1549223.1250 - val_loss: 13.8167 - val_mae: 0.9326 - val_mse: 13.8167 - learning_rate: 1.0000e-04\n",
            "Epoch 944/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549168.5000 - mae: 698.9608 - mse: 1549168.5000 - val_loss: 13.8175 - val_mae: 0.9326 - val_mse: 13.8175 - learning_rate: 1.0000e-04\n",
            "Epoch 945/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1549120.0000 - mae: 698.9579 - mse: 1549120.0000 - val_loss: 13.8175 - val_mae: 0.9328 - val_mse: 13.8175 - learning_rate: 1.0000e-04\n",
            "Epoch 946/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1549071.2500 - mae: 698.9570 - mse: 1549071.2500 - val_loss: 13.8175 - val_mae: 0.9329 - val_mse: 13.8175 - learning_rate: 1.0000e-04\n",
            "Epoch 947/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1549022.3750 - mae: 698.9471 - mse: 1549022.3750 - val_loss: 13.8183 - val_mae: 0.9329 - val_mse: 13.8183 - learning_rate: 1.0000e-04\n",
            "Epoch 948/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548983.5000 - mae: 698.9407 - mse: 1548983.5000 - val_loss: 13.8182 - val_mae: 0.9330 - val_mse: 13.8182 - learning_rate: 1.0000e-04\n",
            "Epoch 949/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548926.6250 - mae: 698.9392 - mse: 1548926.6250 - val_loss: 13.8182 - val_mae: 0.9331 - val_mse: 13.8182 - learning_rate: 1.0000e-04\n",
            "Epoch 950/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548879.0000 - mae: 698.9369 - mse: 1548879.0000 - val_loss: 13.8188 - val_mae: 0.9331 - val_mse: 13.8188 - learning_rate: 1.0000e-04\n",
            "Epoch 951/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548829.2500 - mae: 698.9294 - mse: 1548829.2500 - val_loss: 13.8194 - val_mae: 0.9331 - val_mse: 13.8194 - learning_rate: 1.0000e-04\n",
            "Epoch 952/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1548785.2500 - mae: 698.9220 - mse: 1548785.2500 - val_loss: 13.8185 - val_mae: 0.9332 - val_mse: 13.8185 - learning_rate: 1.0000e-04\n",
            "Epoch 953/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548739.3750 - mae: 698.9152 - mse: 1548739.3750 - val_loss: 13.8185 - val_mae: 0.9333 - val_mse: 13.8185 - learning_rate: 1.0000e-04\n",
            "Epoch 954/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1548693.5000 - mae: 698.9059 - mse: 1548693.5000 - val_loss: 13.8194 - val_mae: 0.9332 - val_mse: 13.8194 - learning_rate: 1.0000e-04\n",
            "Epoch 955/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548650.2500 - mae: 698.8973 - mse: 1548650.2500 - val_loss: 13.8183 - val_mae: 0.9333 - val_mse: 13.8183 - learning_rate: 1.0000e-04\n",
            "Epoch 956/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1548602.7500 - mae: 698.8944 - mse: 1548602.7500 - val_loss: 13.8182 - val_mae: 0.9333 - val_mse: 13.8182 - learning_rate: 1.0000e-04\n",
            "Epoch 957/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548556.2500 - mae: 698.8867 - mse: 1548556.2500 - val_loss: 13.8180 - val_mae: 0.9333 - val_mse: 13.8180 - learning_rate: 1.0000e-04\n",
            "Epoch 958/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1548514.3750 - mae: 698.8770 - mse: 1548514.3750 - val_loss: 13.8182 - val_mae: 0.9333 - val_mse: 13.8182 - learning_rate: 1.0000e-04\n",
            "Epoch 959/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548472.2500 - mae: 698.8707 - mse: 1548472.2500 - val_loss: 13.8187 - val_mae: 0.9333 - val_mse: 13.8187 - learning_rate: 1.0000e-04\n",
            "Epoch 960/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548426.5000 - mae: 698.8648 - mse: 1548426.5000 - val_loss: 13.8194 - val_mae: 0.9333 - val_mse: 13.8194 - learning_rate: 1.0000e-04\n",
            "Epoch 961/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548382.5000 - mae: 698.8595 - mse: 1548382.5000 - val_loss: 13.8202 - val_mae: 0.9333 - val_mse: 13.8202 - learning_rate: 1.0000e-04\n",
            "Epoch 962/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548338.0000 - mae: 698.8538 - mse: 1548338.0000 - val_loss: 13.8204 - val_mae: 0.9333 - val_mse: 13.8204 - learning_rate: 1.0000e-04\n",
            "Epoch 963/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548296.1250 - mae: 698.8458 - mse: 1548296.1250 - val_loss: 13.8215 - val_mae: 0.9332 - val_mse: 13.8215 - learning_rate: 1.0000e-04\n",
            "Epoch 964/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548259.0000 - mae: 698.8392 - mse: 1548259.0000 - val_loss: 13.8217 - val_mae: 0.9333 - val_mse: 13.8217 - learning_rate: 1.0000e-04\n",
            "Epoch 965/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1548211.3750 - mae: 698.8385 - mse: 1548211.3750 - val_loss: 13.8213 - val_mae: 0.9333 - val_mse: 13.8213 - learning_rate: 1.0000e-04\n",
            "Epoch 966/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548165.7500 - mae: 698.8330 - mse: 1548165.7500 - val_loss: 13.8214 - val_mae: 0.9333 - val_mse: 13.8214 - learning_rate: 1.0000e-04\n",
            "Epoch 967/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548124.6250 - mae: 698.8298 - mse: 1548124.6250 - val_loss: 13.8213 - val_mae: 0.9334 - val_mse: 13.8213 - learning_rate: 1.0000e-04\n",
            "Epoch 968/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1548082.0000 - mae: 698.8245 - mse: 1548082.0000 - val_loss: 13.8216 - val_mae: 0.9334 - val_mse: 13.8216 - learning_rate: 1.0000e-04\n",
            "Epoch 969/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1548041.3750 - mae: 698.8223 - mse: 1548041.3750 - val_loss: 13.8223 - val_mae: 0.9334 - val_mse: 13.8223 - learning_rate: 1.0000e-04\n",
            "Epoch 970/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547999.6250 - mae: 698.8190 - mse: 1547999.6250 - val_loss: 13.8231 - val_mae: 0.9334 - val_mse: 13.8231 - learning_rate: 1.0000e-04\n",
            "Epoch 971/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547957.2500 - mae: 698.8149 - mse: 1547957.2500 - val_loss: 13.8240 - val_mae: 0.9334 - val_mse: 13.8240 - learning_rate: 1.0000e-04\n",
            "Epoch 972/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547919.7500 - mae: 698.8120 - mse: 1547919.7500 - val_loss: 13.8249 - val_mae: 0.9334 - val_mse: 13.8249 - learning_rate: 1.0000e-04\n",
            "Epoch 973/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547884.0000 - mae: 698.8036 - mse: 1547884.0000 - val_loss: 13.8250 - val_mae: 0.9335 - val_mse: 13.8250 - learning_rate: 1.0000e-04\n",
            "Epoch 974/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1547842.0000 - mae: 698.8033 - mse: 1547842.0000 - val_loss: 13.8247 - val_mae: 0.9335 - val_mse: 13.8247 - learning_rate: 1.0000e-04\n",
            "Epoch 975/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1547798.8750 - mae: 698.7982 - mse: 1547798.8750 - val_loss: 13.8247 - val_mae: 0.9335 - val_mse: 13.8247 - learning_rate: 1.0000e-04\n",
            "Epoch 976/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547758.0000 - mae: 698.7947 - mse: 1547758.0000 - val_loss: 13.8252 - val_mae: 0.9336 - val_mse: 13.8252 - learning_rate: 1.0000e-04\n",
            "Epoch 977/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1547722.6250 - mae: 698.7922 - mse: 1547722.6250 - val_loss: 13.8254 - val_mae: 0.9336 - val_mse: 13.8254 - learning_rate: 1.0000e-04\n",
            "Epoch 978/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1547681.8750 - mae: 698.7860 - mse: 1547681.8750 - val_loss: 13.8260 - val_mae: 0.9336 - val_mse: 13.8260 - learning_rate: 1.0000e-04\n",
            "Epoch 979/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1547645.2500 - mae: 698.7830 - mse: 1547645.2500 - val_loss: 13.8268 - val_mae: 0.9337 - val_mse: 13.8268 - learning_rate: 1.0000e-04\n",
            "Epoch 980/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547604.8750 - mae: 698.7797 - mse: 1547604.8750 - val_loss: 13.8277 - val_mae: 0.9337 - val_mse: 13.8277 - learning_rate: 1.0000e-04\n",
            "Epoch 981/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547568.8750 - mae: 698.7761 - mse: 1547568.8750 - val_loss: 13.8288 - val_mae: 0.9337 - val_mse: 13.8288 - learning_rate: 1.0000e-04\n",
            "Epoch 982/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1547543.2500 - mae: 698.7677 - mse: 1547543.2500 - val_loss: 13.8277 - val_mae: 0.9338 - val_mse: 13.8277 - learning_rate: 1.0000e-04\n",
            "Epoch 983/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547498.7500 - mae: 698.7692 - mse: 1547498.7500 - val_loss: 13.8277 - val_mae: 0.9338 - val_mse: 13.8277 - learning_rate: 1.0000e-04\n",
            "Epoch 984/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1547461.3750 - mae: 698.7672 - mse: 1547461.3750 - val_loss: 13.8284 - val_mae: 0.9338 - val_mse: 13.8284 - learning_rate: 1.0000e-04\n",
            "Epoch 985/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547425.8750 - mae: 698.7626 - mse: 1547425.8750 - val_loss: 13.8294 - val_mae: 0.9338 - val_mse: 13.8294 - learning_rate: 1.0000e-04\n",
            "Epoch 986/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1547395.6250 - mae: 698.7573 - mse: 1547395.6250 - val_loss: 13.8299 - val_mae: 0.9338 - val_mse: 13.8299 - learning_rate: 1.0000e-04\n",
            "Epoch 987/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547358.5000 - mae: 698.7497 - mse: 1547358.5000 - val_loss: 13.8306 - val_mae: 0.9339 - val_mse: 13.8306 - learning_rate: 1.0000e-04\n",
            "Epoch 988/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1547323.0000 - mae: 698.7454 - mse: 1547323.0000 - val_loss: 13.8315 - val_mae: 0.9339 - val_mse: 13.8315 - learning_rate: 1.0000e-04\n",
            "Epoch 989/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1547286.1250 - mae: 698.7423 - mse: 1547286.1250 - val_loss: 13.8311 - val_mae: 0.9339 - val_mse: 13.8311 - learning_rate: 1.0000e-04\n",
            "Epoch 990/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547247.3750 - mae: 698.7307 - mse: 1547247.3750 - val_loss: 13.8306 - val_mae: 0.9340 - val_mse: 13.8306 - learning_rate: 1.0000e-04\n",
            "Epoch 991/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1547207.7500 - mae: 698.7144 - mse: 1547207.7500 - val_loss: 13.8315 - val_mae: 0.9339 - val_mse: 13.8315 - learning_rate: 1.0000e-04\n",
            "Epoch 992/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547176.8750 - mae: 698.7045 - mse: 1547176.8750 - val_loss: 13.8319 - val_mae: 0.9340 - val_mse: 13.8319 - learning_rate: 1.0000e-04\n",
            "Epoch 993/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1547133.8750 - mae: 698.7021 - mse: 1547133.8750 - val_loss: 13.8332 - val_mae: 0.9340 - val_mse: 13.8332 - learning_rate: 1.0000e-04\n",
            "Epoch 994/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1547100.6250 - mae: 698.6937 - mse: 1547100.6250 - val_loss: 13.8328 - val_mae: 0.9340 - val_mse: 13.8328 - learning_rate: 1.0000e-04\n",
            "Epoch 995/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1547062.6250 - mae: 698.6814 - mse: 1547062.6250 - val_loss: 13.8329 - val_mae: 0.9340 - val_mse: 13.8329 - learning_rate: 1.0000e-04\n",
            "Epoch 996/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1547026.2500 - mae: 698.6759 - mse: 1547026.2500 - val_loss: 13.8337 - val_mae: 0.9340 - val_mse: 13.8337 - learning_rate: 1.0000e-04\n",
            "Epoch 997/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1546988.3750 - mae: 698.6741 - mse: 1546988.3750 - val_loss: 13.8344 - val_mae: 0.9341 - val_mse: 13.8344 - learning_rate: 1.0000e-04\n",
            "Epoch 998/1000\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2492083.0000 - mae: 1038.9644 - mse: 2492083.0000\n",
            "Epoch 998: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1546959.1250 - mae: 698.6667 - mse: 1546959.1250 - val_loss: 13.8354 - val_mae: 0.9341 - val_mse: 13.8354 - learning_rate: 1.0000e-04\n",
            "Epoch 999/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1546919.2500 - mae: 698.6627 - mse: 1546919.2500 - val_loss: 13.8355 - val_mae: 0.9341 - val_mse: 13.8355 - learning_rate: 1.0000e-05\n",
            "Epoch 1000/1000\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1546916.0000 - mae: 698.6646 - mse: 1546916.0000 - val_loss: 13.8354 - val_mae: 0.9341 - val_mse: 13.8354 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with ensemble model\n",
        "\n",
        "def ensemble_predictions(ensemble_models, test_data):\n",
        "  ensemble_preds=[]\n",
        "  for model in ensemble_models:\n",
        "    preds=model.predict(test_data)\n",
        "    ensemble_preds.append(preds)\n",
        "  return tf.constant(tf.squeeze(ensemble_preds))"
      ],
      "metadata": {
        "id": "5hohO6B0Hqeg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds = ensemble_predictions(ensemble_models_bitcoin,test_data)\n",
        "ensemble_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJIsyBAAdOgO",
        "outputId": "c7d826c0-e718-4db7-9b1d-b23fc4357da1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1111), dtype=float32, numpy=\n",
              "array([[ 1.02117500e+02,  9.87457123e+01,  9.36247177e+01, ...,\n",
              "         3.29898894e-02,  1.84104443e-02,  9.91645455e-03],\n",
              "       [ 1.02895210e+02,  9.91981125e+01,  9.55162888e+01, ...,\n",
              "         1.66112319e-01,  1.46813810e-01,  1.42536551e-01],\n",
              "       [ 1.02377739e+02,  9.93990784e+01,  9.52153931e+01, ...,\n",
              "         8.85775536e-02,  7.69128650e-02,  7.07429796e-02],\n",
              "       ...,\n",
              "       [ 1.01974136e+02,  9.63740387e+01,  8.99469147e+01, ...,\n",
              "         1.12603024e-01,  1.02792665e-01,  8.85209963e-02],\n",
              "       [ 1.02282417e+02,  1.00382103e+02,  9.47600250e+01, ...,\n",
              "        -1.51541993e-01, -1.53989568e-01, -1.67446911e-01],\n",
              "       [ 1.01968544e+02,  9.94841232e+01,  9.37380371e+01, ...,\n",
              "         1.65794313e-01,  1.56528533e-01,  1.39217794e-01]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds=evaluate_preds(y_test, ensemble_preds)\n",
        "ensemble_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF-uF7LHeKCF",
        "outputId": "7a236706-f94c-4ec2-ed08-8a1bb3f03453"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 1.0465128421783447,\n",
              " 'mse': 19.136085510253906,\n",
              " 'rmse': 4.374481201171875,\n",
              " 'mape': 14.398977279663086}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: ARIMA"
      ],
      "metadata": {
        "id": "n_l6RKPmaNEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA, ARIMAResultsWrapper\n",
        "import statsmodels"
      ],
      "metadata": {
        "id": "Z-4h5CcVeqKP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_size=int(len(X)*0.8)\n",
        "X_train, y_train=X[:split_size], y[:split_size]\n",
        "X_test, y_test=X[split_size:], y[split_size:]"
      ],
      "metadata": {
        "id": "CUxeUFfDfnSr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arima_model = ARIMA(y_train, order=(5, 1, 0))\n",
        "arima_model_fit = arima_model.fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTVGZpQhfuH0",
        "outputId": "83e97138-93fa-435f-cb4f-b4ba36048050"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency -1D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency -1D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency -1D will be used.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arima_forecast = len(y_test)\n",
        "forecast = arima_model_fit.forecast(steps=arima_forecast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HnThjzFhPpf",
        "outputId": "e8907e9e-19fd-4382-ec39-5d420a626cb1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arima_preds=evaluate_preds(y_test, forecast)\n",
        "arima_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBIO-sbCiG-i",
        "outputId": "8d108a49-afb7-4af1-9e71-74548b8785d5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mae': 80.6503677368164,\n",
              " 'mse': 7047.10205078125,\n",
              " 'rmse': 83.947021484375,\n",
              " 'mape': 17801.955078125}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arima_model_fit.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "9MOw0lKabA-3",
        "outputId": "7710981e-473f-4eb9-8333-e91223afa905"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                               SARIMAX Results                                \n",
              "==============================================================================\n",
              "Dep. Variable:                  price   No. Observations:                 4448\n",
              "Model:                 ARIMA(5, 1, 0)   Log Likelihood              -37067.923\n",
              "Date:                Sat, 04 Oct 2025   AIC                          74147.847\n",
              "Time:                        23:22:52   BIC                          74186.247\n",
              "Sample:                             0   HQIC                         74161.386\n",
              "                               - 4448                                         \n",
              "Covariance Type:                  opg                                         \n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "ar.L1         -0.0043      0.004     -1.191      0.234      -0.011       0.003\n",
              "ar.L2         -0.0026      0.007     -0.358      0.721      -0.017       0.011\n",
              "ar.L3          0.0060      0.008      0.731      0.464      -0.010       0.022\n",
              "ar.L4          0.0315      0.007      4.426      0.000       0.018       0.045\n",
              "ar.L5          0.0054      0.007      0.737      0.461      -0.009       0.020\n",
              "sigma2      1.011e+06   8017.117    126.059      0.000    9.95e+05    1.03e+06\n",
              "===================================================================================\n",
              "Ljung-Box (L1) (Q):                  13.43   Jarque-Bera (JB):             29415.24\n",
              "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
              "Heteroskedasticity (H):               0.00   Skew:                            -0.30\n",
              "Prob(H) (two-sided):                  0.00   Kurtosis:                        15.59\n",
              "===================================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>SARIMAX Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>price</td>      <th>  No. Observations:  </th>    <td>4448</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>            <td>ARIMA(5, 1, 0)</td>  <th>  Log Likelihood     </th> <td>-37067.923</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Sat, 04 Oct 2025</td> <th>  AIC                </th>  <td>74147.847</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>23:22:52</td>     <th>  BIC                </th>  <td>74186.247</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th>  <td>74161.386</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th></th>                      <td> - 4448</td>     <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L1</th>  <td>   -0.0043</td> <td>    0.004</td> <td>   -1.191</td> <td> 0.234</td> <td>   -0.011</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L2</th>  <td>   -0.0026</td> <td>    0.007</td> <td>   -0.358</td> <td> 0.721</td> <td>   -0.017</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L3</th>  <td>    0.0060</td> <td>    0.008</td> <td>    0.731</td> <td> 0.464</td> <td>   -0.010</td> <td>    0.022</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L4</th>  <td>    0.0315</td> <td>    0.007</td> <td>    4.426</td> <td> 0.000</td> <td>    0.018</td> <td>    0.045</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>ar.L5</th>  <td>    0.0054</td> <td>    0.007</td> <td>    0.737</td> <td> 0.461</td> <td>   -0.009</td> <td>    0.020</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sigma2</th> <td> 1.011e+06</td> <td> 8017.117</td> <td>  126.059</td> <td> 0.000</td> <td> 9.95e+05</td> <td> 1.03e+06</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Ljung-Box (L1) (Q):</th>     <td>13.43</td> <th>  Jarque-Bera (JB):  </th> <td>29415.24</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Q):</th>                <td>0.00</td>  <th>  Prob(JB):          </th>   <td>0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Heteroskedasticity (H):</th> <td>0.00</td>  <th>  Skew:              </th>   <td>-0.30</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(H) (two-sided):</th>    <td>0.00</td>  <th>  Kurtosis:          </th>   <td>15.59</td> \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}          &      price       & \\textbf{  No. Observations:  } &    4448     \\\\\n\\textbf{Model:}                  &  ARIMA(5, 1, 0)  & \\textbf{  Log Likelihood     } & -37067.923  \\\\\n\\textbf{Date:}                   & Sat, 04 Oct 2025 & \\textbf{  AIC                } & 74147.847   \\\\\n\\textbf{Time:}                   &     23:22:52     & \\textbf{  BIC                } & 74186.247   \\\\\n\\textbf{Sample:}                 &        0         & \\textbf{  HQIC               } & 74161.386   \\\\\n\\textbf{}                        &      - 4448      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{ar.L1}  &      -0.0043  &        0.004     &    -1.191  &         0.234        &       -0.011    &        0.003     \\\\\n\\textbf{ar.L2}  &      -0.0026  &        0.007     &    -0.358  &         0.721        &       -0.017    &        0.011     \\\\\n\\textbf{ar.L3}  &       0.0060  &        0.008     &     0.731  &         0.464        &       -0.010    &        0.022     \\\\\n\\textbf{ar.L4}  &       0.0315  &        0.007     &     4.426  &         0.000        &        0.018    &        0.045     \\\\\n\\textbf{ar.L5}  &       0.0054  &        0.007     &     0.737  &         0.461        &       -0.009    &        0.020     \\\\\n\\textbf{sigma2} &    1.011e+06  &     8017.117     &   126.059  &         0.000        &     9.95e+05    &     1.03e+06     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Ljung-Box (L1) (Q):}     & 13.43 & \\textbf{  Jarque-Bera (JB):  } & 29415.24  \\\\\n\\textbf{Prob(Q):}                &  0.00 & \\textbf{  Prob(JB):          } &   0.00    \\\\\n\\textbf{Heteroskedasticity (H):} &  0.00 & \\textbf{  Skew:              } &  -0.30    \\\\\n\\textbf{Prob(H) (two-sided):}    &  0.00 & \\textbf{  Kurtosis:          } &  15.59    \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{SARIMAX Results}\n\\end{center}\n\nWarnings: \\newline\n [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metrics"
      ],
      "metadata": {
        "id": "G9F18Va1-JeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_metrics=pd.DataFrame([n_beats_evaluation, ensemble_preds, arima_preds], index=[\"N-Beats\", \"Ensemble\", \"ARIMA\"])\n",
        "evaluation_metrics.columns=[\"MAE\", \"MSE\", \"RMSE\", \"MAPE\"]\n",
        "display(evaluation_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VWxlZUVq-Y4N",
        "outputId": "a918021d-cfbd-426a-c267-769375dae5c6"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                MAE          MSE       RMSE          MAPE\n",
              "N-Beats    2.279007    44.006145   6.633713    260.181580\n",
              "Ensemble   1.046513    19.136086   4.374481     14.398977\n",
              "ARIMA     80.650368  7047.102051  83.947021  17801.955078"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76cc852a-ee13-47d8-9d2b-1a9be636df7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>N-Beats</th>\n",
              "      <td>2.279007</td>\n",
              "      <td>44.006145</td>\n",
              "      <td>6.633713</td>\n",
              "      <td>260.181580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble</th>\n",
              "      <td>1.046513</td>\n",
              "      <td>19.136086</td>\n",
              "      <td>4.374481</td>\n",
              "      <td>14.398977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ARIMA</th>\n",
              "      <td>80.650368</td>\n",
              "      <td>7047.102051</td>\n",
              "      <td>83.947021</td>\n",
              "      <td>17801.955078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76cc852a-ee13-47d8-9d2b-1a9be636df7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76cc852a-ee13-47d8-9d2b-1a9be636df7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76cc852a-ee13-47d8-9d2b-1a9be636df7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47920e02-f52c-4cd9-97dc-ceba9d4fb58b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47920e02-f52c-4cd9-97dc-ceba9d4fb58b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47920e02-f52c-4cd9-97dc-ceba9d4fb58b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b93d920d-2120-46b7-a064-aabaee27f0d5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('evaluation_metrics')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b93d920d-2120-46b7-a064-aabaee27f0d5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('evaluation_metrics');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "evaluation_metrics",
              "summary": "{\n  \"name\": \"evaluation_metrics\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.60768024309247,\n        \"min\": 1.0465128421783447,\n        \"max\": 80.6503677368164,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.2790067195892334,\n          1.0465128421783447,\n          80.6503677368164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4050.4377620979703,\n        \"min\": 19.136085510253906,\n        \"max\": 7047.10205078125,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          44.00614547729492,\n          19.136085510253906,\n          7047.10205078125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45.30312902913878,\n        \"min\": 4.374481201171875,\n        \"max\": 83.947021484375,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.6337127685546875,\n          4.374481201171875,\n          83.947021484375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10199.439352257137,\n        \"min\": 14.398977279663086,\n        \"max\": 17801.955078125,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          260.18157958984375,\n          14.398977279663086,\n          17801.955078125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}